{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca9284ff-91b2-453f-bfa7-8055e3bbc9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel is [25]\n",
      "saving to state & norm information to SF_Norm_files/debug_sample/runs07862-08069/07862\n",
      "Target is empty\n",
      "dataread from binary time: 0.9046587944030762\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import uproot\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import os\n",
    "from numba import njit\n",
    "import time\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "# from loguru import logger\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "# for arg in sys.argv:\n",
    "#     run_num=str(arg).zfill(5)\n",
    "#     # print(run_num)\n",
    "\n",
    "# # chan_enab = int(sys.argv[-1])\n",
    "# run_start=str(sys.argv[1]).zfill(5)\n",
    "# run_end=str(sys.argv[2]).zfill(5)\n",
    "# run_num=str(sys.argv[3]).zfill(5)\n",
    "\n",
    "# chan_enab = [25,26,27,28] ## normal\n",
    "chan_enab = [25] ## only 3He monitor\n",
    "\n",
    "# print(os.getcwd())\n",
    "\n",
    "# os.chdir('E:/LANL/')\n",
    "# run_num = \"12036\" \n",
    "# datadir = 'sample_data/'\n",
    "# runs_folder = 'runs12034-12363/'\n",
    "# uniquefolder = 'debug_sample/'+runs_folder\n",
    "# folder = uniquefolder\n",
    "# savefilename = 'SF_Norm_files/'+folder+run_num\n",
    "\n",
    "os.chdir('F:/LANL/')\n",
    "run_num = \"07862\" \n",
    "datadir = 'sample_data/'\n",
    "runs_folder = 'runs07862-08069/'\n",
    "uniquefolder = 'debug_sample/'+runs_folder\n",
    "folder = uniquefolder\n",
    "savefilename = 'SF_Norm_files/'+folder+run_num\n",
    "\n",
    "# datadir = 'D:/LANSCE_FP12_2023/data/' ## add directory of hard drive\n",
    "# uniquefolder = \"runs\" + str(run_start) + \"-\" + str(run_end) +\"/\"\n",
    "# savefilename = 'SF_Norm_files/'+uniquefolder+run_num\n",
    "\n",
    "\n",
    "# if not os.path.exists(os.getcwd() + '/' +'SF_Norm_files/'+uniquefolder):\n",
    "#     # Create the directory\n",
    "#     os.makedirs(os.getcwd() + '/' +'SF_Norm_files/'+uniquefolder)\n",
    "#     print(\"Directory created successfully!\")\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# logger.add(\"F:/LANL/SF_Norm_files/\" + uniquefolder + '0_ErrorLog.txt', delay = True)\n",
    "\n",
    "    # print(\"Directory already exists!\")\n",
    "# os.mkdir(os.getcwd() + '/' +'SF_Norm_files/'+uniquefolder)\n",
    "\n",
    "# print('processing data: ' + folder + 'run' + run_num)\n",
    "# print('processing data: ' + uniquefolder + 'run' + run_num)\n",
    "\n",
    "# print(os.getcwd() + folder)\n",
    "statefileloc = 'F:\\LANL\\SF_Norm_files\\TR_R_expected_avgs_stds_afterclip.csv'\n",
    "\n",
    "# get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "start = time.time()\n",
    "fullstart = time.time()\n",
    "\n",
    "read_data = []\n",
    "fileLength = []\n",
    "\n",
    "for el in chan_enab:\n",
    "    f = open(datadir + folder + 'run' + run_num + \"_ch\" + str(el) + \".bin\", 'rb')\n",
    "    # f = open(datadir+uniquefolder + 'run' + str(run_num) + \"_ch\" +str(el) + \".bin\", 'rb')\n",
    "    read_data.append(np.fromfile(file=f, dtype=np.uint16))\n",
    "    f.close()\n",
    "    fileLength.append(len(read_data[-1]))\n",
    "\n",
    "fileLength = np.asarray(fileLength)\n",
    "# read_data = np.asarray(read_data, dtype = object)  ## cannot do np array for sorting because He and SF are different sizes\n",
    "\n",
    "print(\"Channel is \" + str(chan_enab))\n",
    "# print(\"Run number is \" + run_num)\n",
    "print('saving to state & norm information to ' + savefilename)\n",
    "end = time.time()\n",
    "# print(end-start)\n",
    "# print(read_data)\n",
    "\n",
    "\n",
    "# Store the big header for each channel in arrays\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "BoardID = []\n",
    "recordLength = []\n",
    "numSamples = []\n",
    "eventCounter = []\n",
    "decFactor = []\n",
    "chanDec = []\n",
    "postTrig = []\n",
    "groupStart = []\n",
    "groupEnd = []\n",
    "timestamp= []\n",
    "sizeFirstEvent = []\n",
    "TTT = []\n",
    "\n",
    "targetDict = {0: \"La\", 1: \"Tb2O3\", 2: \"Yb2O3\", 3: \"Sm2O3\", 4: \"Er2O3\", 5: \"Ho2O3\", 6: \"other\"}\n",
    "foilDict = {0: \"TBD\", 1: \"TBD\", 2: \"TBD\", 3: \"TBD\", 4: \"TBD\", 5: \"TBD\", 6: \"other\"}\n",
    "\n",
    "target=(read_data[0][5]&0x00F0)>>4\n",
    "foil=read_data[0][5]&0x000F\n",
    "targetFlag = read_data[0][5]>>8&1\n",
    "foilFlag = read_data[0][5]>>9&1\n",
    "spinFiltFlag = read_data[0][5]>>10&1\n",
    "spinFlipFlag = read_data[0][5]>>11&1\n",
    "shutterFlag = read_data[0][5]>>12&1\n",
    "facilityTrigFlag = read_data[0][5]>>13&1\n",
    "\n",
    "if targetFlag:\n",
    "    target=targetDict[(read_data[0][5]&0x00F0)>>4]\n",
    "    \n",
    "else:\n",
    "    target = \"empty\"\n",
    "    \n",
    "    \n",
    "if foilFlag:\n",
    "    foil=foilDict[read_data[0][5]&0x000F]\n",
    "else:\n",
    "    foil = \"empty\"\n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    BoardID.append(read_data[i][9]>>8)\n",
    "    recordLength.append(((read_data[i][9]&0x00FF)<<16)+read_data[i][8])\n",
    "    numSamples.append(((read_data[i][11]&0x00FF)<<16)+read_data[i][10])\n",
    "    eventCounter.append(read_data[i][6]+(read_data[i][7]<<16))\n",
    "    BoardID.append(read_data[i][9]>>8)  \n",
    "    decFactor.append(read_data[i][11]>>8)\n",
    "    chanDec.append(read_data[i][13]>>8)\n",
    "    postTrig.append(read_data[i][15]>>8)\n",
    "    groupStart.append(((read_data[i][13]&0x00FF)<<16)+read_data[i][12])\n",
    "    groupEnd.append(((read_data[i][15]&0x00FF)<<16)+read_data[i][14])\n",
    "    \n",
    "    timestamp.append(read_data[i][16]+(read_data[i][17]<<16)+(read_data[i][18]<<32)+(read_data[i][19]<<40))  \n",
    "    sizeFirstEvent.append(read_data[i][0]+(read_data[i][1]<<16))\n",
    "    TTT.append(read_data[i][2]+(read_data[i][3]<<16)+(read_data[i][4]<<32))\n",
    "    \n",
    "#     print(\"For channel \" + str(chan_enab[i]) + \", BoardID is \" + str(BoardID[i])\n",
    "#           + \"; record length is \" + str(recordLength[i]) + \"; num Samples is \" \n",
    "#           + str(numSamples[i]) + \"; event counter is \" + str(eventCounter[i]) + \"; dec factor is \" + str(decFactor[i]) + \"; chan dec is \" \n",
    "#           + str(chanDec[i]) + \"; postTrig is \" + str(postTrig[i]) + \"; group start is \" + str(groupStart[i]) + \"; group end is \" + str(groupEnd[i])\n",
    "#           + \"; epoch time is \" + str(timestamp[i]) +  \"; first event size is \" + str(sizeFirstEvent[i]) + \"; and ETTT is \" + str(TTT[i]) + \"\\n\")\n",
    "\n",
    "numSamples = np.asarray(numSamples)\n",
    "\n",
    "eventCounter = np.asarray(eventCounter)\n",
    "TTT = np.asarray(TTT)\n",
    "\n",
    "print(\"Target is \" + target)\n",
    "# print(\"Foil is \" + foil)\n",
    "# print(\"Shutter is open: \" + str(bool(shutterFlag)))\n",
    "# print(\"Facility t0 is on: \" + str(bool(facilityTrigFlag)))\n",
    "# print(\"Spin flipper is on: \" + str(bool(spinFlipFlag)))\n",
    "# print(\"Spin filter is on: \" + str(bool(spinFiltFlag)))\n",
    "# print(\"Target is present: \" + str(bool(targetFlag)))\n",
    "# print(\"Foil is present: \" + str(bool(foilFlag)))\n",
    "\n",
    "\n",
    "# Determine the time axis for each channel\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "preTime = []\n",
    "startTime = []\n",
    "endTime = []\n",
    "resolution = []\n",
    "xs = [] \n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    preTime.append((100-postTrig[i])*recordLength[i]/100)\n",
    "    startTime.append((-1*preTime[i]*16*decFactor[i] + groupStart[i]*16*decFactor[i]))\n",
    "    endTime.append((-1*preTime[i]*16*decFactor[i] + groupEnd[i]*16*decFactor[i]))\n",
    "    resolution.append(16*chanDec[i]*decFactor[i])\n",
    "#     print(\"Pretime for channel\", chan_enab[i],\"is \" + str(preTime[i]) + \"; start time is \" + str(startTime[i]) + \"; end time is \" + str(endTime[i]) \n",
    "#           + \"; resolution is \" + str(resolution[i]) + \"ns\")\n",
    "    xs.append(np.arange(startTime[i],(numSamples[i])*resolution[i]+startTime[i], resolution[i]))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "if chan_enab[0] != 25:\n",
    "    #print('No 3He. Cannot normalize')\n",
    "    emessage = ('3He not in first channel loaded. Cannot normalize')\n",
    "    logger.error(run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "@njit\n",
    "def dataread(data, channels, fileLen, numSamps):\n",
    "    numRuns = int((fileLen[0]-20-numSamps[0])/(numSamps[0]+6)+1)\n",
    "    ys_arr = np.zeros((len(channels), numRuns,numSamps[0]), dtype=np.uint16)\n",
    "    ETTT_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    eventcount_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    for i in range(0,len(channels)):\n",
    "        eventCount = 0\n",
    "        byteCounter = 0\n",
    "            #byte counter is really 2bytecounter, lol\n",
    "        while byteCounter < fileLen[i]:\n",
    "            if byteCounter == 0:\n",
    "                ETTT_arr[i]=TTT[i]\n",
    "                #ETTT_arr[i].append(TTT[i])\n",
    "                eventcount_arr[i]=(eventCounter[i])\n",
    "                byteCounter = 20\n",
    "            else:\n",
    "                ETTT_arr[i]=(data[i][byteCounter]+(data[i][byteCounter+1]<<16)+(data[i][byteCounter+2]<<32))\n",
    "                eventcount_arr[i]=(data[i][byteCounter+4]+(data[i][byteCounter+5]<<16))\n",
    "                byteCounter += 6\n",
    "            for j in range(0, numSamps[i]):\n",
    "                ys_arr[i][eventCount][j]=data[i][byteCounter]\n",
    "                byteCounter += 1\n",
    "            eventCount += 1\n",
    "    return ys_arr, ETTT_arr, eventcount_arr\n",
    "\n",
    "############################### Normal, 3He and SF #####################################\n",
    "\n",
    "# ys_arrHe, ETTT_arrHe, eventcount_arrHe  = dataread(read_data, np.array([25]), fileLength, numSamples) ##hardcoded channel 25 for He\n",
    "# ys_arr, ETTT_arr, eventcount_arr  = dataread(read_data[1:], np.array([26,27,28]), fileLength[1:], numSamples[1:]) ##hardcoded channels for coils\n",
    "\n",
    "# ETTT_arr = np.vstack([ETTT_arrHe,ETTT_arr]) ## ordering makes sure that first array of new ETTT_arr is ETTT_arr of He\n",
    "# eventcount_arr = np.vstack([eventcount_arrHe,eventcount_arr])\n",
    "\n",
    "############################### for ONLY 3He, no SF channels #####################################\n",
    "\n",
    "ys_arrHe, ETTT_arr, eventcount_arr  = dataread(read_data, np.array([25]), fileLength, numSamples) ##hardcoded channel 25 for He\n",
    "# ys_arr, ETTT_arr, eventcount_arr  = dataread(read_data[1:], np.array([26,27,28]), fileLength[1:], numSamples[1:]) ##hardcoded channels for coils\n",
    "\n",
    "# ETTT_arr = np.vstack([ETTT_arrHe,ETTT_arr]) ## ordering makes sure that first array of new ETTT_arr is ETTT_arr of He\n",
    "# eventcount_arr = np.vstack([eventcount_arrHe,eventcount_arr])\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "end = time.time()\n",
    "print('dataread from binary time: ' + str(end-start))  \n",
    "\n",
    "# Put ADC values in arrays for each channel (one array per event, an array of events per channel) and put the miniheader information in an array\n",
    "\n",
    "# Calculate the time difference between each event within a file - used to check for dropping pulses. It seems that if we make the record window 49.152 ms long, we miss every other pulse (at 20 Hz). This is not that surprising - we presumably will not need a lot of data (or any) with the full 50 ms time window.\n",
    "\n",
    "timeDif=[]\n",
    "for i in range(0,len(chan_enab)):\n",
    "    timeDif.append([])\n",
    "    for j in range(len(ETTT_arr[i])-1):\n",
    "        timeDif[i].append((ETTT_arr[i][j+1]-ETTT_arr[i][j])*8)\n",
    "#     print(\"Min time difference for channel\", chan_enab[i], \"is\", min(timeDif[i]), \"ns\")\n",
    "#     print(\"Max time difference for channel\", chan_enab[i], \"is\", max(timeDif[i]), \"ns \\n\")\n",
    "#print(timeDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ddf0f99-0f04-4654-abf4-36e3a9f263d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#switchs = [31, 74, 117, 160, 203, 246, 289, 332]\n",
    "%matplotlib qt\n",
    "# %matplotlib inline\n",
    "\n",
    "baseL = 0\n",
    "# baseRCoil = int(((preTime[1]-groupStart[1])*0.70)/chanDec[1])\n",
    "baseRHe = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])\n",
    "numRuns = int((fileLength[0]-20-numSamples[0])/(numSamples[0]+6)+1)\n",
    "\n",
    "if numSamples[0] != 45000:\n",
    "    emessage = ('He channel wrong size')\n",
    "    logger.error(run_num + ' ' + emessage)\n",
    "    raise Exception(emessage)\n",
    "# elif numSamples[1] != 351:\n",
    "#     emessage = ('Coil channel wrong size')\n",
    "#     logger.error(run_num + ' ' + emessage)\n",
    "#     raise Exception(emessage)\n",
    "# elif numSamples[2] != 351:\n",
    "#     emessage = ('Coil channel wrong size')\n",
    "#     logger.error(run_num + ' ' + emessage)\n",
    "#     raise Exception(emessage)\n",
    "    \n",
    "#legend =  ['He']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## dont know why this is so slow ##\n",
    "def plotter(ys, xs, baseR, numpoints):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "    for i in range((len(ys))):\n",
    "        #tempys_basesub = []\n",
    "        #tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "        #tempsums =[]\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "        for j in range(s, t): ## plot only interested pulses\n",
    "            #ys_basesub.append(ys_arr[i][j] - np.mean(ys_arr[i][j][200:6000]))\n",
    "            #print(sum(ys_basesub[i][j])) \n",
    "#             plt.plot(xs[i], tempys_basesub[i][j] , label=legend[i]) #+str(sums[1][j])) ## sums[j] will not work for more than just TR   \n",
    "            plt.plot(xs[i], tempys_basesub[i][j])\n",
    "        if i == 0:\n",
    "            plt.axvline(xs[0][baseL], ls = '--')\n",
    "            plt.axvline(xs[0][baseR], ls = '--')\n",
    "            plt.axhline(875, ls = '--')\n",
    "            #plt.axvline(xs[0][int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])], ls = '--', c ='m')\n",
    "#             plt.axvline(xs[0][baseR+5], ls = '--', c ='r') ## BaseR+5 line marks the beginning of the integral, until the end of samples.\n",
    "#             plt.title('SF state transition at ' + str(s)) \n",
    "#             plt.xlabel(\"time from trigger (ns)\")\n",
    "#             plt.ylabel(\"ADC\")\n",
    "#             plt.legend()\n",
    "            \n",
    "plotter(ys_arrHe, xs, baseRHe,numSamples) ##plot 3He\n",
    "# plotter(ys_arr, xs[1:], baseRCoil, numSamples[1:]) ##plot coils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfb56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea62e5cd-1c87-4162-92ca-2c8854878e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting and/or base subtraction time: 21.89613914489746\n"
     ]
    }
   ],
   "source": [
    "#@njit(nopython = True) ## Actually JIT seems to be slower here!\n",
    "def basesub_sum(ys, baseR, numpoints): ## for coils, could be used for He but below does that\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=np.float64)\n",
    "    tempsums = np.zeros((len(ys), numRuns), dtype=np.float64)\n",
    "    for i in range((len(ys))):\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "            tempsums[i][pulse] = np.sum(tempys_basesub[i][pulse][baseR+5:-1])\n",
    "    return tempys_basesub, tempsums\n",
    "        \n",
    "# ys_basesub, sums = basesub_sum(ys_arr, baseRCoil, numSamples[1:])\n",
    "\n",
    "@njit ## separate function for He because this checks every point, can take a while\n",
    "def basesub_normHe(ys, baseRegion, intgrRegion):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,45000), dtype=np.float64) #hardcode numSamples[0] = 45000\n",
    "    tempsums = np.zeros((len(ys), numRuns), dtype=np.float64)\n",
    "    for i in range((len(ys))): ## i is pretty much always 0 for 3He. Left it general.\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            for j in range(intgrRegion[0]+1000, intgrRegion[1]): ## checking for saturation in He channel. restrict to slightly smaller range\n",
    "                if ys[i][pulse][j] > 4060:  ## cutoff adc value (real is 4092)\n",
    "                    err = ((('3He is saturating in normalization region at pulse,point: ' + str(pulse) + ', '+ str(j))))\n",
    "                    print(err)\n",
    "                else:\n",
    "                    err = ''\n",
    "                    pass\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseRegion[0]:baseRegion[1]]))\n",
    "            tempsums[i][pulse] = np.sum(tempys_basesub[i][pulse][intgrRegion[0]:intgrRegion[1]])\n",
    "            ## need to investigate adc saturation point\n",
    "    return tempys_basesub, tempsums, err\n",
    "\n",
    "baseRHe = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0]) #redefined for clarity\n",
    "\n",
    "HeBaseReg = np.array([0, baseRHe])\n",
    "HeIntgrReg = np.array([baseRHe+700, 15999]) ## hardcoded begin/end region for integral over NaI and 6Li regions\n",
    "ys_basesubHe, HeNorms, emessage = basesub_normHe(ys_arrHe, HeBaseReg, HeIntgrReg)\n",
    "## got rid of xs in basesub, don't think we need them as an input 06.10.24\n",
    "\n",
    "## can't use logger in JIT, so do it outside\n",
    "if len(emessage) >1 :\n",
    "    logger.error(emessage)\n",
    "    raise Exception(emessage)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "end = time.time()\n",
    "print('plotting and/or base subtraction time: ' + str(end-start))            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d5c2a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5743167.94984183 5838699.05761957 5920351.54460394 ... 5866771.14571463\n",
      "  5980894.85031802 5932612.22619075]]\n"
     ]
    }
   ],
   "source": [
    "print(HeNorms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d15a017c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x254670231f0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(HeNorms/1000000)\n",
    "print((np.where(HeNorms/1000000<2.0)))\n",
    "for i in range(len(ys_basesubHe)):\n",
    "    if np.max(ys_basesubHe[i])<2030:\n",
    "        print(i)\n",
    "#     print(np.where(np.max(ys_basesubHe[i])<2030))\n",
    "plt.plot(HeNorms[0]/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d33711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x253db0a2df0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = HeNorms[0]/1000000\n",
    "\n",
    "dx = x[1]-x[0]\n",
    "y = x**2 + 1\n",
    "dydx = np.gradient(y, dx)\n",
    "print(len(dydx))\n",
    "plt.plot(dydx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c20c51c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x253e074af40>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = dydx\n",
    "\n",
    "dx2 = x2[1]-x2[0]\n",
    "y2 = x2**2 + 1\n",
    "dydx2 = np.gradient(y2, dx2)\n",
    "print(len(dydx2))\n",
    "plt.plot(dydx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c98cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f57459f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bee4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84fec43f-21c0-43db-8df6-f245b1632085",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F:\\\\LANL\\\\SF_Norm_files\\\\TR_R_expected_avgs_stds_afterclip.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21020\\260775844.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstatefile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatefileloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtransitions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatefile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transition'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m## for some reasons \"averages\" and \"std dev\" need a space before them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mexpectedSumsTR_R\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatefile\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m' averages'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F:\\\\LANL\\\\SF_Norm_files\\\\TR_R_expected_avgs_stds_afterclip.csv'"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "statefile = pd.read_csv(statefileloc)\n",
    "transitions = statefile['transition'].to_numpy() ## for some reasons \"averages\" and \"std dev\" need a space before them\n",
    "expectedSumsTR_R = statefile[' averages'].to_numpy()\n",
    "expectedStdsTR_R = statefile[' standard dev'].to_numpy()\n",
    "\n",
    "AllSwitches = []\n",
    "tolerance = 6000 ## see comments below\n",
    "\n",
    "## can't use pre-existing np array because usually one array of unequal length\n",
    "for i in range(len(expectedSumsTR_R)):\n",
    "    diff_arr = np.absolute(np.add(sums[1],sums[2]) - expectedSumsTR_R[i])\n",
    "    found_sums =[]\n",
    "    for j in range(len(diff_arr)):\n",
    "#         if diff_arr[j] < expectedStdsTR_R[i]*3: ## within 3 standard deviations of its respective std\n",
    "## using std didn't work for La. Maybe just get rid of it and use a constant value...\n",
    "        if diff_arr[j] < tolerance: ## this uses a constant \"tolerance\"\n",
    "            found_sums.append(j)\n",
    "    AllSwitches.append(np.array(found_sums))\n",
    "\n",
    "for i in range(len(AllSwitches)):\n",
    "    print(len(AllSwitches[i]))\n",
    "end = time.time()\n",
    "# print('find switches time: ' + str(end-start)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123a7c8-aaa5-442e-8745-8d3f8a705a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## testing sorting with pandas dataframe\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "transitions = ['111->101', '101->100', '100->110', '110->101','101->110','110->111','111->100','100->111']\n",
    "\n",
    "transitionSumsTR = []\n",
    "transitionSumsR = []\n",
    "transitionTR_RAvgs = []\n",
    "transitionTR_Rstds = []\n",
    "transitionSumsTR_R = []\n",
    "\n",
    "for i in range(0,len(transitions)):\n",
    "    tempTR = []\n",
    "    tempR = []\n",
    "    for j in range(0,len(AllSwitches[i])):\n",
    "        tempTR.append(sums[1][AllSwitches[i][j]])\n",
    "        tempR.append(sums[2][AllSwitches[i][j]])\n",
    "    transitionSumsTR.append(tempTR)\n",
    "    transitionSumsR.append(tempR)\n",
    "    transitionSumsTR_R.append(np.add(tempTR,tempR))\n",
    "    transitionTR_RAvgs.append(np.average(np.add(tempTR,tempR)))\n",
    "    transitionTR_Rstds.append(np.std(np.add(tempTR,tempR)))\n",
    "\n",
    "cols = ['transition', 'transition_locations', 'sumsTR_R', 'TR_R_avgs', 'TR_R_stds']\n",
    "transSumsData = [transitions, AllSwitches, transitionSumsTR_R, transitionTR_RAvgs, transitionTR_Rstds]\n",
    "\n",
    "df_SF = pd.DataFrame({cols[0]: transSumsData[0],            \n",
    "                   cols[1]: transSumsData[1],\n",
    "                   cols[2]: transSumsData[2],\n",
    "                   cols[3]: transSumsData[3],\n",
    "                   cols[4]: transSumsData[4]})\n",
    "## 'original dataframe to work with, 7 transitions and their associated locations and sums:\n",
    "\n",
    "# with pd.option_context('display.max_rows', None,\n",
    "#                       'display.max_columns', None,\n",
    "#                       'display.precision', 3,\n",
    "#                       ):\n",
    "#    print(df_SF.explode(['transition_locations', 'sumsTR_R']))\n",
    "\n",
    "## original dataframe is exploded so that transition_locations and associated sum is unpacked. Indices of state are kept as \"nickname\" \n",
    "## save Averages and Stds for future use')\n",
    "\n",
    "df_SF = df_SF.explode(['transition_locations', 'sumsTR_R']).reset_index().rename(columns={'index' : 'nicknames'}) #turn the 'index' of the exploded df_SF into a column, then reassign indices\n",
    "\n",
    "## now sort by the transition location and rearrange dataframe indices, only matters for looping (??)\n",
    "df_SF = df_SF.sort_values(by=['transition_locations'])\n",
    "df_SF = df_SF.reset_index(drop=True)\n",
    "\n",
    "for ind in df_SF.index[:-1]:\n",
    "    print('transition: '+ str(df_SF['nicknames'][ind]) + ' location: ' + str(df_SF['transition_locations'][ind]))\n",
    "    if (df_SF['nicknames'][ind+1])-1 != df_SF['nicknames'][ind]: ## if next transition 'nickname' is not next in sequence, failure\n",
    "        if (df_SF['nicknames'][ind+1])-1 == -1: ## special condition for end of sequence where (0-1) != 7\n",
    "            if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) != 45: ## changed to 45 pulses!\n",
    "                emessage = '# pulses error: ' + str(df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind])\n",
    "                logger.error(run_num + ' ' + emessage)\n",
    "                raise Exception(emessage)\n",
    "            if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) == 45:\n",
    "                pass\n",
    "                print('# pulses correct, end of sequence')\n",
    "        else:\n",
    "            ## checks that the sequence follows 0-> 1-> 2-> 3... etc order\n",
    "            emessage = 'sorting failure, ' + str((df_SF['nicknames'][ind+1])-1) + '!=' + str(df_SF['nicknames'][ind])\n",
    "            logger.error(run_num + ' ' + emessage)\n",
    "            raise Exception(emessage)\n",
    "    elif (df_SF['nicknames'][ind+1])-1 == df_SF['nicknames'][ind]:\n",
    "        if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) != 45: ## error if =/= 45 pulses between each\n",
    "            print(df_SF['transition_locations'][ind])\n",
    "            print(df_SF['transition_locations'][ind+1])\n",
    "            emessage = ('# pulses error: ' + str(df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) +'. starting at pulse '+\n",
    "                        str(df_SF['transition_locations'][ind]))\n",
    "            # logger.error(run_num + ' ' + emessage)\n",
    "            raise Exception(emessage)\n",
    "        if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) == 45:\n",
    "            pass\n",
    "    else:\n",
    "        emessage = ('Unknown failure in sorting')\n",
    "        logger.error(run_num + ' ' + emessage)\n",
    "        raise Exception(emessage)\n",
    "        \n",
    "        \n",
    "print('SF # pulses and sequence success')\n",
    "end = time.time()\n",
    "\n",
    "# print('SF dataframe time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deecd8ea-29b7-4b83-91bd-fb2245972cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nicknames transition transition_locations  sumsTR_R      TR_R_avgs  \\\n",
      "0            5   110->111                   34 -176668.0 -176792.000000   \n",
      "1            6   111->100                   79  -65902.0  -65831.928571   \n",
      "2            7   100->111                  124  -26859.0  -27038.142857   \n",
      "3            0   111->101                  169  118351.0  118376.285714   \n",
      "4            1   101->100                  214 -116370.0 -116373.000000   \n",
      "..         ...        ...                  ...       ...            ...   \n",
      "106          7   100->111                 4804  -27058.0  -27038.142857   \n",
      "107          0   111->101                 4849  118365.0  118376.285714   \n",
      "108          1   101->100                 4894 -116366.0 -116373.000000   \n",
      "109          2   100->110                 4939  339828.0  339886.785714   \n",
      "110          3   110->101                 4984   65633.0   65682.857143   \n",
      "\n",
      "     TR_R_stds  \n",
      "0    88.216455  \n",
      "1    33.128461  \n",
      "2    65.543723  \n",
      "3    30.029577  \n",
      "4    10.085350  \n",
      "..         ...  \n",
      "106  65.543723  \n",
      "107  30.029577  \n",
      "108  10.085350  \n",
      "109  57.348781  \n",
      "110  40.735834  \n",
      "\n",
      "[111 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_SF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ae602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
