{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9284ff-91b2-453f-bfa7-8055e3bbc9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel is [25, 26, 27, 28]\n",
      "saving to state & norm information to SF_Norm_files/debug_sample/runs12034-12363/12036\n",
      "Target is La\n",
      "dataread from binary time: 1.9441463947296143\n"
     ]
    }
   ],
   "source": [
    "# In[1]:\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import uproot\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import os\n",
    "from numba import njit\n",
    "import time\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "# from loguru import logger\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "# for arg in sys.argv:\n",
    "#     run_num=str(arg).zfill(5)\n",
    "#     # print(run_num)\n",
    "\n",
    "# # chan_enab = int(sys.argv[-1])\n",
    "# run_start=str(sys.argv[1]).zfill(5)\n",
    "# run_end=str(sys.argv[2]).zfill(5)\n",
    "# run_num=str(sys.argv[3]).zfill(5)\n",
    "\n",
    "chan_enab = [25,26,27,28]\n",
    "\n",
    "# print(os.getcwd())\n",
    "os.chdir('F:/LANL/')\n",
    "run_num = \"12036\" \n",
    "datadir = 'sample_data/'\n",
    "runs_folder = 'runs12034-12363/'\n",
    "uniquefolder = 'debug_sample/'+runs_folder\n",
    "folder = uniquefolder\n",
    "savefilename = 'SF_Norm_files/'+folder+run_num\n",
    "# datadir = 'D:/LANSCE_FP12_2023/data/' ## add directory of hard drive\n",
    "# uniquefolder = \"runs\" + str(run_start) + \"-\" + str(run_end) +\"/\"\n",
    "# savefilename = 'SF_Norm_files/'+uniquefolder+run_num\n",
    "# if not os.path.exists(os.getcwd() + '/' +'SF_Norm_files/'+uniquefolder):\n",
    "#     # Create the directory\n",
    "#     os.makedirs(os.getcwd() + '/' +'SF_Norm_files/'+uniquefolder)\n",
    "#     print(\"Directory created successfully!\")\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# logger.add(\"F:/LANL/SF_Norm_files/\" + uniquefolder + '0_ErrorLog.txt', delay = True)\n",
    "\n",
    "    # print(\"Directory already exists!\")\n",
    "# os.mkdir(os.getcwd() + '/' +'SF_Norm_files/'+uniquefolder)\n",
    "\n",
    "# print('processing data: ' + folder + 'run' + run_num)\n",
    "# print('processing data: ' + uniquefolder + 'run' + run_num)\n",
    "\n",
    "# print(os.getcwd() + folder)\n",
    "statefileloc = 'F:\\LANL\\SF_Norm_files\\TR_R_expected_avgs_stds_afterclip.csv'\n",
    "\n",
    "# get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "start = time.time()\n",
    "fullstart = time.time()\n",
    "\n",
    "read_data = []\n",
    "fileLength = []\n",
    "\n",
    "for el in chan_enab:\n",
    "    f = open(datadir + folder + 'run' + run_num + \"_ch\" + str(el) + \".bin\", 'rb')\n",
    "    # f = open(datadir+uniquefolder + 'run' + str(run_num) + \"_ch\" +str(el) + \".bin\", 'rb')\n",
    "    read_data.append(np.fromfile(file=f, dtype=np.uint16))\n",
    "    f.close()\n",
    "    fileLength.append(len(read_data[-1]))\n",
    "\n",
    "fileLength = np.asarray(fileLength)\n",
    "# read_data = np.asarray(read_data, dtype = object)  ## cannot do np array for sorting because He and SF are different sizes\n",
    "\n",
    "print(\"Channel is \" + str(chan_enab))\n",
    "# print(\"Run number is \" + run_num)\n",
    "print('saving to state & norm information to ' + savefilename)\n",
    "end = time.time()\n",
    "# print(end-start)\n",
    "# print(read_data)\n",
    "\n",
    "\n",
    "# Store the big header for each channel in arrays\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "BoardID = []\n",
    "recordLength = []\n",
    "numSamples = []\n",
    "eventCounter = []\n",
    "decFactor = []\n",
    "chanDec = []\n",
    "postTrig = []\n",
    "groupStart = []\n",
    "groupEnd = []\n",
    "timestamp= []\n",
    "sizeFirstEvent = []\n",
    "TTT = []\n",
    "\n",
    "targetDict = {0: \"La\", 1: \"Tb2O3\", 2: \"Yb2O3\", 3: \"Sm2O3\", 4: \"Er2O3\", 5: \"Ho2O3\", 6: \"other\"}\n",
    "foilDict = {0: \"TBD\", 1: \"TBD\", 2: \"TBD\", 3: \"TBD\", 4: \"TBD\", 5: \"TBD\", 6: \"other\"}\n",
    "\n",
    "target=(read_data[0][5]&0x00F0)>>4\n",
    "foil=read_data[0][5]&0x000F\n",
    "targetFlag = read_data[0][5]>>8&1\n",
    "foilFlag = read_data[0][5]>>9&1\n",
    "spinFiltFlag = read_data[0][5]>>10&1\n",
    "spinFlipFlag = read_data[0][5]>>11&1\n",
    "shutterFlag = read_data[0][5]>>12&1\n",
    "facilityTrigFlag = read_data[0][5]>>13&1\n",
    "\n",
    "if targetFlag:\n",
    "    target=targetDict[(read_data[0][5]&0x00F0)>>4]\n",
    "    \n",
    "else:\n",
    "    target = \"empty\"\n",
    "    \n",
    "    \n",
    "if foilFlag:\n",
    "    foil=foilDict[read_data[0][5]&0x000F]\n",
    "else:\n",
    "    foil = \"empty\"\n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    BoardID.append(read_data[i][9]>>8)\n",
    "    recordLength.append(((read_data[i][9]&0x00FF)<<16)+read_data[i][8])\n",
    "    numSamples.append(((read_data[i][11]&0x00FF)<<16)+read_data[i][10])\n",
    "    eventCounter.append(read_data[i][6]+(read_data[i][7]<<16))\n",
    "    BoardID.append(read_data[i][9]>>8)  \n",
    "    decFactor.append(read_data[i][11]>>8)\n",
    "    chanDec.append(read_data[i][13]>>8)\n",
    "    postTrig.append(read_data[i][15]>>8)\n",
    "    groupStart.append(((read_data[i][13]&0x00FF)<<16)+read_data[i][12])\n",
    "    groupEnd.append(((read_data[i][15]&0x00FF)<<16)+read_data[i][14])\n",
    "    \n",
    "    timestamp.append(read_data[i][16]+(read_data[i][17]<<16)+(read_data[i][18]<<32)+(read_data[i][19]<<40))  \n",
    "    sizeFirstEvent.append(read_data[i][0]+(read_data[i][1]<<16))\n",
    "    TTT.append(read_data[i][2]+(read_data[i][3]<<16)+(read_data[i][4]<<32))\n",
    "    \n",
    "#     print(\"For channel \" + str(chan_enab[i]) + \", BoardID is \" + str(BoardID[i])\n",
    "#           + \"; record length is \" + str(recordLength[i]) + \"; num Samples is \" \n",
    "#           + str(numSamples[i]) + \"; event counter is \" + str(eventCounter[i]) + \"; dec factor is \" + str(decFactor[i]) + \"; chan dec is \" \n",
    "#           + str(chanDec[i]) + \"; postTrig is \" + str(postTrig[i]) + \"; group start is \" + str(groupStart[i]) + \"; group end is \" + str(groupEnd[i])\n",
    "#           + \"; epoch time is \" + str(timestamp[i]) +  \"; first event size is \" + str(sizeFirstEvent[i]) + \"; and ETTT is \" + str(TTT[i]) + \"\\n\")\n",
    "\n",
    "numSamples = np.asarray(numSamples)\n",
    "\n",
    "eventCounter = np.asarray(eventCounter)\n",
    "TTT = np.asarray(TTT)\n",
    "\n",
    "print(\"Target is \" + target)\n",
    "# print(\"Foil is \" + foil)\n",
    "# print(\"Shutter is open: \" + str(bool(shutterFlag)))\n",
    "# print(\"Facility t0 is on: \" + str(bool(facilityTrigFlag)))\n",
    "# print(\"Spin flipper is on: \" + str(bool(spinFlipFlag)))\n",
    "# print(\"Spin filter is on: \" + str(bool(spinFiltFlag)))\n",
    "# print(\"Target is present: \" + str(bool(targetFlag)))\n",
    "# print(\"Foil is present: \" + str(bool(foilFlag)))\n",
    "\n",
    "\n",
    "# Determine the time axis for each channel\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "preTime = []\n",
    "startTime = []\n",
    "endTime = []\n",
    "resolution = []\n",
    "xs = [] \n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    preTime.append((100-postTrig[i])*recordLength[i]/100)\n",
    "    startTime.append((-1*preTime[i]*16*decFactor[i] + groupStart[i]*16*decFactor[i]))\n",
    "    endTime.append((-1*preTime[i]*16*decFactor[i] + groupEnd[i]*16*decFactor[i]))\n",
    "    resolution.append(16*chanDec[i]*decFactor[i])\n",
    "#     print(\"Pretime for channel\", chan_enab[i],\"is \" + str(preTime[i]) + \"; start time is \" + str(startTime[i]) + \"; end time is \" + str(endTime[i]) \n",
    "#           + \"; resolution is \" + str(resolution[i]) + \"ns\")\n",
    "    xs.append(np.arange(startTime[i],(numSamples[i])*resolution[i]+startTime[i], resolution[i]))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "if chan_enab[0] != 25:\n",
    "    #print('No 3He. Cannot normalize')\n",
    "    emessage = ('3He not in first channel loaded. Cannot normalize')\n",
    "    logger.error(run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "@njit\n",
    "def dataread(data, channels, fileLen, numSamps):\n",
    "    numRuns = int((fileLen[0]-20-numSamps[0])/(numSamps[0]+6)+1)\n",
    "    ys_arr = np.zeros((len(channels), numRuns,numSamps[0]), dtype=np.uint16)\n",
    "    ETTT_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    eventcount_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    for i in range(0,len(channels)):\n",
    "        eventCount = 0\n",
    "        byteCounter = 0\n",
    "            #byte counter is really 2bytecounter, lol\n",
    "        while byteCounter < fileLen[i]:\n",
    "            if byteCounter == 0:\n",
    "                ETTT_arr[i]=TTT[i]\n",
    "                #ETTT_arr[i].append(TTT[i])\n",
    "                eventcount_arr[i]=(eventCounter[i])\n",
    "                byteCounter = 20\n",
    "            else:\n",
    "                ETTT_arr[i]=(data[i][byteCounter]+(data[i][byteCounter+1]<<16)+(data[i][byteCounter+2]<<32))\n",
    "                eventcount_arr[i]=(data[i][byteCounter+4]+(data[i][byteCounter+5]<<16))\n",
    "                byteCounter += 6\n",
    "            for j in range(0, numSamps[i]):\n",
    "                ys_arr[i][eventCount][j]=data[i][byteCounter]\n",
    "                byteCounter += 1\n",
    "            eventCount += 1\n",
    "    return ys_arr, ETTT_arr, eventcount_arr\n",
    "\n",
    "ys_arrHe, ETTT_arrHe, eventcount_arrHe  = dataread(read_data, np.array([25]), fileLength, numSamples) ##hardcoded channel 25 for He\n",
    "ys_arr, ETTT_arr, eventcount_arr  = dataread(read_data[1:], np.array([26,27,28]), fileLength[1:], numSamples[1:]) ##hardcoded channels for coils\n",
    "\n",
    "ETTT_arr = np.vstack([ETTT_arrHe,ETTT_arr]) ## ordering makes sure that first array of new ETTT_arr is ETTT_arr of He\n",
    "eventcount_arr = np.vstack([eventcount_arrHe,eventcount_arr])\n",
    "\n",
    "end = time.time()\n",
    "print('dataread from binary time: ' + str(end-start))  \n",
    "\n",
    "# Put ADC values in arrays for each channel (one array per event, an array of events per channel) and put the miniheader information in an array\n",
    "\n",
    "# Calculate the time difference between each event within a file - used to check for dropping pulses. It seems that if we make the record window 49.152 ms long, we miss every other pulse (at 20 Hz). This is not that surprising - we presumably will not need a lot of data (or any) with the full 50 ms time window.\n",
    "\n",
    "timeDif=[]\n",
    "for i in range(0,len(chan_enab)):\n",
    "    timeDif.append([])\n",
    "    for j in range(len(ETTT_arr[i])-1):\n",
    "        timeDif[i].append((ETTT_arr[i][j+1]-ETTT_arr[i][j])*8)\n",
    "#     print(\"Min time difference for channel\", chan_enab[i], \"is\", min(timeDif[i]), \"ns\")\n",
    "#     print(\"Max time difference for channel\", chan_enab[i], \"is\", max(timeDif[i]), \"ns \\n\")\n",
    "#print(timeDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ddf0f99-0f04-4654-abf4-36e3a9f263d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#switchs = [31, 74, 117, 160, 203, 246, 289, 332]\n",
    "%matplotlib qt\n",
    "baseL = 0\n",
    "baseRCoil = int(((preTime[1]-groupStart[1])*0.70)/chanDec[1])\n",
    "baseRHe = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])\n",
    "numRuns = int((fileLength[0]-20-numSamples[0])/(numSamples[0]+6)+1)\n",
    "\n",
    "if numSamples[0] != 45000:\n",
    "    emessage = ('He channel wrong size')\n",
    "    logger.error(run_num + ' ' + emessage)\n",
    "    raise Exception(emessage)\n",
    "elif numSamples[1] != 351:\n",
    "    emessage = ('Coil channel wrong size')\n",
    "    logger.error(run_num + ' ' + emessage)\n",
    "    raise Exception(emessage)\n",
    "elif numSamples[2] != 351:\n",
    "    emessage = ('Coil channel wrong size')\n",
    "    logger.error(run_num + ' ' + emessage)\n",
    "    raise Exception(emessage)\n",
    "    \n",
    "#legend =  ['He']\n",
    "legend =  ['LO', 'TR', 'R']\n",
    "#statesID = ['111', '101', '100', '110','101','110','111','100','111']\n",
    "transitions = ['111->101', '101->100', '100->110', '110->101','101->110','110->111','111->100','100->111']\n",
    "switchpulses = np.arange(39,400,45) ##found these pulses which correspond to states 0-8. Change p to plot them\n",
    "#print(switchpulses)\n",
    "p=1\n",
    "\n",
    "# s = switchpulses[p]\n",
    "s = 759-5\n",
    "t=s+1\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## dont know why this is so slow ##\n",
    "def plotter(ys, xs, baseR, numpoints):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "    for i in range((len(ys))):\n",
    "        #tempys_basesub = []\n",
    "        #tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "        #tempsums =[]\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "        for j in range(s, t): ## plot only interested pulses\n",
    "            #ys_basesub.append(ys_arr[i][j] - np.mean(ys_arr[i][j][200:6000]))\n",
    "            #print(sum(ys_basesub[i][j])) \n",
    "            plt.plot(xs[i], tempys_basesub[i][j] , label=legend[i]) #+str(sums[1][j])) ## sums[j] will not work for more than just TR   \n",
    "            plt.axvline(xs[0][baseL], ls = '--')\n",
    "            plt.axvline(xs[0][baseR], ls = '--')\n",
    "            #plt.axvline(xs[0][int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])], ls = '--', c ='m')\n",
    "            plt.axvline(xs[0][baseR+5], ls = '--', c ='r') ## BaseR+5 line marks the beginning of the integral, until the end of samples.\n",
    "            plt.title('SF state transition at ' + str(s)) \n",
    "#             plt.xlabel(\"time from trigger (ns)\")\n",
    "#             plt.ylabel(\"ADC\")\n",
    "            plt.legend()\n",
    "            \n",
    "#plotter(ys_arrHe, xs, baseRHe,numSamples) ##plot 3He\n",
    "plotter(ys_arr, xs[1:], baseRCoil, numSamples[1:]) ##plot coils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfb56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea62e5cd-1c87-4162-92ca-2c8854878e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting and/or base subtraction time: 3.229422092437744\n"
     ]
    }
   ],
   "source": [
    "#@njit(nopython = True) ## Actually JIT seems to be slower here!\n",
    "def basesub_sum(ys, baseR, numpoints): ## for coils, could be used for He but below does that\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=np.float64)\n",
    "    tempsums = np.zeros((len(ys), numRuns), dtype=np.float64)\n",
    "    for i in range((len(ys))):\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "            tempsums[i][pulse] = np.sum(tempys_basesub[i][pulse][baseR+5:-1])\n",
    "    return tempys_basesub, tempsums\n",
    "        \n",
    "ys_basesub, sums = basesub_sum(ys_arr, baseRCoil, numSamples[1:])\n",
    "\n",
    "@njit ## separate function for He because this checks every point, can take a while\n",
    "def basesub_normHe(ys, baseRegion, intgrRegion):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,45000), dtype=np.float64) #hardcode numSamples[0] = 45000\n",
    "    tempsums = np.zeros((len(ys), numRuns), dtype=np.float64)\n",
    "    for i in range((len(ys))): ## i is pretty much always 0 for 3He. Left it general.\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            for j in range(intgrRegion[0]+1000, intgrRegion[1]): ## checking for saturation in He channel. restrict to slightly smaller range\n",
    "                if ys[i][pulse][j] > 4060:  ## cutoff adc value (real is 4092)\n",
    "                    err = ((('3He is saturating in normalization region at pulse,point: ' + str(pulse) + ', '+ str(j))))\n",
    "                    print(err)\n",
    "                else:\n",
    "                    err = ''\n",
    "                    pass\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseRegion[0]:baseRegion[1]]))\n",
    "            tempsums[i][pulse] = np.sum(tempys_basesub[i][pulse][intgrRegion[0]:intgrRegion[1]])\n",
    "            ## need to investigate adc saturation point\n",
    "    return tempys_basesub, tempsums, err\n",
    "\n",
    "baseRHe = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0]) #redefined for clarity\n",
    "\n",
    "HeBaseReg = np.array([0, baseRHe])\n",
    "HeIntgrReg = np.array([baseRHe+700, 15999]) ## hardcoded begin/end region for integral over NaI and 6Li regions\n",
    "ys_basesubHe, HeNorms, emessage = basesub_normHe(ys_arrHe, HeBaseReg, HeIntgrReg)\n",
    "## got rid of xs in basesub, don't think we need them as an input 06.10.24\n",
    "\n",
    "## can't use logger in JIT, so do it outside\n",
    "if len(emessage) >1 :\n",
    "    logger.error(emessage)\n",
    "    raise Exception(emessage)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "end = time.time()\n",
    "print('plotting and/or base subtraction time: ' + str(end-start))            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a017c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fec43f-21c0-43db-8df6-f245b1632085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "statefile = pd.read_csv(statefileloc)\n",
    "transitions = statefile['transition'].to_numpy() ## for some reasons \"averages\" and \"std dev\" need a space before them\n",
    "expectedSumsTR_R = statefile[' averages'].to_numpy()\n",
    "expectedStdsTR_R = statefile[' standard dev'].to_numpy()\n",
    "\n",
    "AllSwitches = []\n",
    "tolerance = 6000 ## see comments below\n",
    "\n",
    "## can't use pre-existing np array because usually one array of unequal length\n",
    "for i in range(len(expectedSumsTR_R)):\n",
    "    diff_arr = np.absolute(np.add(sums[1],sums[2]) - expectedSumsTR_R[i])\n",
    "    found_sums =[]\n",
    "    for j in range(len(diff_arr)):\n",
    "#         if diff_arr[j] < expectedStdsTR_R[i]*3: ## within 3 standard deviations of its respective std\n",
    "## using std didn't work for La. Maybe just get rid of it and use a constant value...\n",
    "        if diff_arr[j] < tolerance: ## this uses a constant \"tolerance\"\n",
    "            found_sums.append(j)\n",
    "    AllSwitches.append(np.array(found_sums))\n",
    "\n",
    "for i in range(len(AllSwitches)):\n",
    "    print(len(AllSwitches[i]))\n",
    "end = time.time()\n",
    "# print('find switches time: ' + str(end-start)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c123a7c8-aaa5-442e-8745-8d3f8a705a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transition: 5 location: 34\n",
      "transition: 6 location: 79\n",
      "transition: 7 location: 124\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 169\n",
      "transition: 1 location: 214\n",
      "transition: 2 location: 259\n",
      "transition: 3 location: 304\n",
      "transition: 4 location: 349\n",
      "transition: 5 location: 394\n",
      "transition: 6 location: 439\n",
      "transition: 7 location: 484\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 529\n",
      "transition: 1 location: 574\n",
      "transition: 2 location: 619\n",
      "transition: 3 location: 664\n",
      "transition: 4 location: 709\n",
      "transition: 5 location: 754\n",
      "transition: 6 location: 799\n",
      "transition: 7 location: 844\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 889\n",
      "transition: 1 location: 934\n",
      "transition: 2 location: 979\n",
      "transition: 3 location: 1024\n",
      "transition: 4 location: 1069\n",
      "transition: 5 location: 1114\n",
      "transition: 6 location: 1159\n",
      "transition: 7 location: 1204\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 1249\n",
      "transition: 1 location: 1294\n",
      "transition: 2 location: 1339\n",
      "transition: 3 location: 1384\n",
      "transition: 4 location: 1429\n",
      "transition: 5 location: 1474\n",
      "transition: 6 location: 1519\n",
      "transition: 7 location: 1564\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 1609\n",
      "transition: 1 location: 1654\n",
      "transition: 2 location: 1699\n",
      "transition: 3 location: 1744\n",
      "transition: 4 location: 1789\n",
      "transition: 5 location: 1834\n",
      "transition: 6 location: 1879\n",
      "transition: 7 location: 1924\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 1969\n",
      "transition: 1 location: 2014\n",
      "transition: 2 location: 2059\n",
      "transition: 3 location: 2104\n",
      "transition: 4 location: 2149\n",
      "transition: 5 location: 2194\n",
      "transition: 6 location: 2239\n",
      "transition: 7 location: 2284\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 2329\n",
      "transition: 1 location: 2374\n",
      "transition: 2 location: 2419\n",
      "transition: 3 location: 2464\n",
      "transition: 4 location: 2509\n",
      "transition: 5 location: 2554\n",
      "transition: 6 location: 2599\n",
      "transition: 7 location: 2644\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 2689\n",
      "transition: 1 location: 2734\n",
      "transition: 2 location: 2779\n",
      "transition: 3 location: 2824\n",
      "transition: 4 location: 2869\n",
      "transition: 5 location: 2914\n",
      "transition: 6 location: 2959\n",
      "transition: 7 location: 3004\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 3049\n",
      "transition: 1 location: 3094\n",
      "transition: 2 location: 3139\n",
      "transition: 3 location: 3184\n",
      "transition: 4 location: 3229\n",
      "transition: 5 location: 3274\n",
      "transition: 6 location: 3319\n",
      "transition: 7 location: 3364\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 3409\n",
      "transition: 1 location: 3454\n",
      "transition: 2 location: 3499\n",
      "transition: 3 location: 3544\n",
      "transition: 4 location: 3589\n",
      "transition: 5 location: 3634\n",
      "transition: 6 location: 3679\n",
      "transition: 7 location: 3724\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 3769\n",
      "transition: 1 location: 3814\n",
      "transition: 2 location: 3859\n",
      "transition: 3 location: 3904\n",
      "transition: 4 location: 3949\n",
      "transition: 5 location: 3994\n",
      "transition: 6 location: 4039\n",
      "transition: 7 location: 4084\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 4129\n",
      "transition: 1 location: 4174\n",
      "transition: 2 location: 4219\n",
      "transition: 3 location: 4264\n",
      "transition: 4 location: 4309\n",
      "transition: 5 location: 4354\n",
      "transition: 6 location: 4399\n",
      "transition: 7 location: 4444\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 4489\n",
      "transition: 1 location: 4534\n",
      "transition: 2 location: 4579\n",
      "transition: 3 location: 4624\n",
      "transition: 4 location: 4669\n",
      "transition: 5 location: 4714\n",
      "transition: 6 location: 4759\n",
      "transition: 7 location: 4804\n",
      "# pulses correct, end of sequence\n",
      "transition: 0 location: 4849\n",
      "transition: 1 location: 4894\n",
      "transition: 2 location: 4939\n",
      "SF # pulses and sequence success\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## testing sorting with pandas dataframe\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "transitions = ['111->101', '101->100', '100->110', '110->101','101->110','110->111','111->100','100->111']\n",
    "\n",
    "transitionSumsTR = []\n",
    "transitionSumsR = []\n",
    "transitionTR_RAvgs = []\n",
    "transitionTR_Rstds = []\n",
    "transitionSumsTR_R = []\n",
    "\n",
    "for i in range(0,len(transitions)):\n",
    "    tempTR = []\n",
    "    tempR = []\n",
    "    for j in range(0,len(AllSwitches[i])):\n",
    "        tempTR.append(sums[1][AllSwitches[i][j]])\n",
    "        tempR.append(sums[2][AllSwitches[i][j]])\n",
    "    transitionSumsTR.append(tempTR)\n",
    "    transitionSumsR.append(tempR)\n",
    "    transitionSumsTR_R.append(np.add(tempTR,tempR))\n",
    "    transitionTR_RAvgs.append(np.average(np.add(tempTR,tempR)))\n",
    "    transitionTR_Rstds.append(np.std(np.add(tempTR,tempR)))\n",
    "\n",
    "cols = ['transition', 'transition_locations', 'sumsTR_R', 'TR_R_avgs', 'TR_R_stds']\n",
    "transSumsData = [transitions, AllSwitches, transitionSumsTR_R, transitionTR_RAvgs, transitionTR_Rstds]\n",
    "\n",
    "df_SF = pd.DataFrame({cols[0]: transSumsData[0],            \n",
    "                   cols[1]: transSumsData[1],\n",
    "                   cols[2]: transSumsData[2],\n",
    "                   cols[3]: transSumsData[3],\n",
    "                   cols[4]: transSumsData[4]})\n",
    "## 'original dataframe to work with, 7 transitions and their associated locations and sums:\n",
    "\n",
    "# with pd.option_context('display.max_rows', None,\n",
    "#                       'display.max_columns', None,\n",
    "#                       'display.precision', 3,\n",
    "#                       ):\n",
    "#    print(df_SF.explode(['transition_locations', 'sumsTR_R']))\n",
    "\n",
    "## original dataframe is exploded so that transition_locations and associated sum is unpacked. Indices of state are kept as \"nickname\" \n",
    "## save Averages and Stds for future use')\n",
    "\n",
    "df_SF = df_SF.explode(['transition_locations', 'sumsTR_R']).reset_index().rename(columns={'index' : 'nicknames'}) #turn the 'index' of the exploded df_SF into a column, then reassign indices\n",
    "\n",
    "## now sort by the transition location and rearrange dataframe indices, only matters for looping (??)\n",
    "df_SF = df_SF.sort_values(by=['transition_locations'])\n",
    "df_SF = df_SF.reset_index(drop=True)\n",
    "\n",
    "for ind in df_SF.index[:-1]:\n",
    "    print('transition: '+ str(df_SF['nicknames'][ind]) + ' location: ' + str(df_SF['transition_locations'][ind]))\n",
    "    if (df_SF['nicknames'][ind+1])-1 != df_SF['nicknames'][ind]: ## if next transition 'nickname' is not next in sequence, failure\n",
    "        if (df_SF['nicknames'][ind+1])-1 == -1: ## special condition for end of sequence where (0-1) != 7\n",
    "            if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) != 45: ## changed to 45 pulses!\n",
    "                emessage = '# pulses error: ' + str(df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind])\n",
    "                logger.error(run_num + ' ' + emessage)\n",
    "                raise Exception(emessage)\n",
    "            if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) == 45:\n",
    "                pass\n",
    "                print('# pulses correct, end of sequence')\n",
    "        else:\n",
    "            ## checks that the sequence follows 0-> 1-> 2-> 3... etc order\n",
    "            emessage = 'sorting failure, ' + str((df_SF['nicknames'][ind+1])-1) + '!=' + str(df_SF['nicknames'][ind])\n",
    "            logger.error(run_num + ' ' + emessage)\n",
    "            raise Exception(emessage)\n",
    "    elif (df_SF['nicknames'][ind+1])-1 == df_SF['nicknames'][ind]:\n",
    "        if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) != 45: ## error if =/= 45 pulses between each\n",
    "            print(df_SF['transition_locations'][ind])\n",
    "            print(df_SF['transition_locations'][ind+1])\n",
    "            emessage = ('# pulses error: ' + str(df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) +'. starting at pulse '+\n",
    "                        str(df_SF['transition_locations'][ind]))\n",
    "            # logger.error(run_num + ' ' + emessage)\n",
    "            raise Exception(emessage)\n",
    "        if (df_SF['transition_locations'][ind+1]-df_SF['transition_locations'][ind]) == 45:\n",
    "            pass\n",
    "    else:\n",
    "        emessage = ('Unknown failure in sorting')\n",
    "        logger.error(run_num + ' ' + emessage)\n",
    "        raise Exception(emessage)\n",
    "        \n",
    "        \n",
    "print('SF # pulses and sequence success')\n",
    "end = time.time()\n",
    "\n",
    "# print('SF dataframe time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deecd8ea-29b7-4b83-91bd-fb2245972cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nicknames transition transition_locations  sumsTR_R      TR_R_avgs  \\\n",
      "0            5   110->111                   34 -176668.0 -176792.000000   \n",
      "1            6   111->100                   79  -65902.0  -65831.928571   \n",
      "2            7   100->111                  124  -26859.0  -27038.142857   \n",
      "3            0   111->101                  169  118351.0  118376.285714   \n",
      "4            1   101->100                  214 -116370.0 -116373.000000   \n",
      "..         ...        ...                  ...       ...            ...   \n",
      "106          7   100->111                 4804  -27058.0  -27038.142857   \n",
      "107          0   111->101                 4849  118365.0  118376.285714   \n",
      "108          1   101->100                 4894 -116366.0 -116373.000000   \n",
      "109          2   100->110                 4939  339828.0  339886.785714   \n",
      "110          3   110->101                 4984   65633.0   65682.857143   \n",
      "\n",
      "     TR_R_stds  \n",
      "0    88.216455  \n",
      "1    33.128461  \n",
      "2    65.543723  \n",
      "3    30.029577  \n",
      "4    10.085350  \n",
      "..         ...  \n",
      "106  65.543723  \n",
      "107  30.029577  \n",
      "108  10.085350  \n",
      "109  57.348781  \n",
      "110  40.735834  \n",
      "\n",
      "[111 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_SF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ae602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
