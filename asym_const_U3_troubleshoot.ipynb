{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4b0024-9303-4a5f-a4ee-8c1b3d7c99c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locations set\n",
      "F:\\LANL/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import os\n",
    "from numba import njit\n",
    "import time\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "import h5py\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "warnings.filterwarnings(action='ignore', message='RuntimeWarning: overflow encountered in multiply')\n",
    "\n",
    "analysisdir = os.getcwd()\n",
    "basedir = os.path.dirname(os.getcwd())+'/'\n",
    "# print(basedir)\n",
    "os.chdir(basedir)\n",
    "\n",
    "# cannot handle all 24 detectors at once, memory issue... can look into np.empty and deleting variables if needed ##\n",
    "# chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]) ## all\n",
    "# chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,24]) ## downstream _D\n",
    "chan_enab = np.array([12,13,14,15,16,17,18,19,20,21,22,23,24]) ## upstream _U\n",
    "\n",
    "############## real running ##############\n",
    "\n",
    "# for arg in sys.argv:\n",
    "#     run_num=str(arg).zfill(5)\n",
    "#     # print(run_num)\n",
    "\n",
    "# chan_enab = int(sys.argv[-1])\n",
    "# run_start=str(sys.argv[1]).zfill(5)\n",
    "# run_end=str(sys.argv[2]).zfill(5)\n",
    "# run_num=str(sys.argv[3]).zfill(5)\n",
    "\n",
    "# datadir = 'D:/LANSCE_FP12_2023/data/' ## add directory of hard drive\n",
    "# uniquefolder = \"runs\" + str(run_start) + \"-\" + str(run_end) +\"/\"\n",
    "# SFNormFile = 'SF_Norm_files/'+uniquefolder+run_num\n",
    "\n",
    "# # statefileloc = basedir+'\\SF_Norm_files\\TR_R_expected_avgs_stds_afterclip.csv'\n",
    "# # processedONOFFfolder = '/processed_data/'+uniquefolder+'ONOFF_U/'\n",
    "# processedasymfolder = '/processed_data/'+uniquefolder+'asym_U/'\n",
    "# # processedasymfolder_bg = '/processed_data/'+uniquefolder+'asym_bg_U/'\n",
    "# # ONOFFSavename = os.getcwd()+processedONOFFfolder+run_num+'_ONOFF_U'\n",
    "# AsymSavename = os.getcwd()+processedasymfolder+run_num+'_U'\n",
    "# # AsymSavename_bg = os.getcwd()+processedasymfolder_bg+run_num+'_asym_bg_U' ## maybe canget rid of this\n",
    "# logger.add(basedir+\"/processed_data/\" + uniquefolder + '0_ErrorLog_'+run_start+'_'+run_end+'_U.txt', delay = False)\n",
    "\n",
    "# # if not os.path.exists(os.getcwd()+processedONOFFfolder) or not os.path.exists(os.getcwd()+processedasymfolder) or not os.path.exists(os.getcwd()+processedasymfolder_bg):\n",
    "# if not os.path.exists(os.getcwd()+processedasymfolder):\n",
    "#     # Create the directory\n",
    "#     # os.makedirs(os.getcwd()+processedONOFFfolder)\n",
    "#     os.makedirs(os.getcwd()+processedasymfolder)\n",
    "#     # os.makedirs(os.getcwd()+processedasymfolder_bg)\n",
    "#     print(\"Directory created successfully\")\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "############## test running ##############\n",
    "\n",
    "run_num = '13564'\n",
    "os.chdir('F:/LANL/')\n",
    "datadir = 'sample_data/'\n",
    "runs_folder = 'runs13564-13604/'\n",
    "uniquefolder = 'debug_sample/'+runs_folder\n",
    "# uniquefolder = 'La_sample/'\n",
    "# SFNormFile = 'SF_Norm_files/'+uniquefolder+run_num\n",
    "SFNormFile = 'SF_Norm_files/'+runs_folder+run_num\n",
    "# AsymSavename = '****testing testing testing'\n",
    "ONOFFSavename = 'F:/LANL/testing_ONOFF'\n",
    "AsymSavename = 'F:/LANL/testing_asyms'\n",
    "\n",
    "##########################################\n",
    "\n",
    "# print(os.getcwd() + folder)\n",
    "print('locations set')\n",
    "print(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26846b9f-5b6f-46be-8dc0-635898f94753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving processed data to F:/LANL/testing_asyms\n",
      "Channel is [12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fullstart = time.time()\n",
    "\n",
    "read_data = []\n",
    "fileLength = []\n",
    "\n",
    "def open_file():\n",
    "    for el in chan_enab:\n",
    "        # f = open(datadir + folder + 'run' + run_num + \"_ch\" + str(el) + \".bin\", 'rb')\n",
    "        f = open(datadir+uniquefolder + 'run' + str(run_num) + \"_ch\" +str(el) + \".bin\", 'rb')\n",
    "        read_data.append(np.fromfile(file=f, dtype=np.uint16))\n",
    "        f.close()\n",
    "        fileLength.append(len(read_data[-1]))\n",
    "    return read_data, fileLength\n",
    "\n",
    "open_file()\n",
    "\n",
    "fileLength = np.asarray(fileLength)\n",
    "read_data = np.asarray(read_data) ## in detector's case, all are the same size samples, so can do read_data as np array\n",
    "\n",
    "if chan_enab[-1] != 24:\n",
    "    emessage = ('last channel is not 6Li detector')\n",
    "    logger.error('run '+run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# print('file open time: ' + str(end-start))            \n",
    "print('saving processed data to ' + AsymSavename)\n",
    "print(\"Channel is \" + str(chan_enab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42981d32-4deb-40a5-b201-fc921b9b01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15616\n",
      "13564\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "print(read_data[0][5])\n",
    "print(runs_folder[4:9])\n",
    "if runs_folder[4:9] in ('12686', '13280', '13564'):\n",
    "    print('yay')\n",
    "else:\n",
    "    print('nay')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23be70fa-1ea6-464e-8148-ec77444f0f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f2e3881-d759-44aa-beaa-0e3228b6fa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31), np.uint16(31)]\n",
      "[np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000), np.uint16(45000)]\n",
      "[np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000), np.uint16(9000)]\n",
      "[np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0), np.uint16(0)]\n",
      "[np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32), np.uint16(32)]\n",
      "[np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1), np.uint16(1)]\n",
      "[np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80), np.uint16(80)]\n",
      "[np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000), np.uint16(7000)]\n",
      "[np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000), np.uint16(16000)]\n",
      "[np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772), np.uint16(29772)]\n",
      "[np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040), np.uint16(18040)]\n",
      "[np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797), np.uint16(8797)]\n",
      "\n",
      "<class 'numpy.uint16'>\n",
      "[31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31]\n",
      "[45000 45000 45000 45000 45000 45000 45000 45000 45000 45000 45000 45000\n",
      " 45000]\n",
      "[9000 9000 9000 9000 9000 9000 9000 9000 9000 9000 9000 9000 9000]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[32 32 32 32 32 32 32 32 32 32 32 32 32]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[80 80 80 80 80 80 80 80 80 80 80 80 80]\n",
      "[7000 7000 7000 7000 7000 7000 7000 7000 7000 7000 7000 7000 7000]\n",
      "[16000 16000 16000 16000 16000 16000 16000 16000 16000 16000 16000 16000\n",
      " 16000]\n",
      "[29772 29772 29772 29772 29772 29772 29772 29772 29772 29772 29772 29772\n",
      " 29772]\n",
      "[18040 18040 18040 18040 18040 18040 18040 18040 18040 18040 18040 18040\n",
      " 18040]\n",
      "[8797 8797 8797 8797 8797 8797 8797 8797 8797 8797 8797 8797 8797]\n",
      "<class 'numpy.uint32'>\n",
      "Target is Pr, voigt fit params: F:\\LANL//processed_data/1_vparams_Pr.h5\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "\n",
    "# Store the big header for each channel in arrays\n",
    "BoardID = []\n",
    "recordLength = []\n",
    "numSamples = []\n",
    "eventCounter = []\n",
    "decFactor = []\n",
    "chanDec = []\n",
    "postTrig = []\n",
    "groupStart = []\n",
    "groupEnd = []\n",
    "timestamp= []\n",
    "sizeFirstEvent = []\n",
    "TTT = []\n",
    "\n",
    "### CHANGED TARGET DICT!! 08.20.25\n",
    "targetDict = {0: \"La\", 1: \"Tb2O3\", 2: \"Yb2O3\", 3: \"Sm2O3\", 4: \"Er2O3\", 5: \"Ho2O3\", 6: \"Pr\", 7: \"other\"}\n",
    "foilDict = {0: \"TBD\", 1: \"TBD\", 2: \"TBD\", 3: \"TBD\", 4: \"TBD\", 5: \"TBD\", 6: \"TBD\", 7: \"other\"}\n",
    "\n",
    "target=(read_data[0][5]&0x00F0)>>4\n",
    "foil=read_data[0][5]&0x000F\n",
    "targetFlag = read_data[0][5]>>8&1\n",
    "foilFlag = read_data[0][5]>>9&1\n",
    "spinFiltFlag = read_data[0][5]>>10&1\n",
    "spinFlipFlag = read_data[0][5]>>11&1\n",
    "shutterFlag = read_data[0][5]>>12&1\n",
    "facilityTrigFlag = read_data[0][5]>>13&1\n",
    "\n",
    "if targetFlag:\n",
    "    ## CATCHES MISLABELED PR RUNS 08.20.25\n",
    "    if runs_folder[4:9] in ('12686', '13280', '13564'): ## Pr run #s for 2023 LANSCE run\n",
    "    # if unique_folder[4:9] in ('12686', '13280', '13564'): ## Pr run #s for 2023 LANSCE run\n",
    "        target = targetDict[6] ## corresponds to Pr after change\n",
    "    else:\n",
    "        target=targetDict[(read_data[0][5]&0x00F0)>>4]\n",
    "else:\n",
    "    target = \"empty\"\n",
    "if foilFlag:\n",
    "    foil=foilDict[read_data[0][5]&0x000F]\n",
    "else:\n",
    "    foil = \"empty\"\n",
    "for i in range(0,len(chan_enab)):\n",
    "    BoardID.append(read_data[i][9]>>8)\n",
    "    recordLength.append(((read_data[i][9]&0x00FF)<<16)+read_data[i][8])\n",
    "    numSamples.append(((read_data[i][11]&0x00FF)<<16)+read_data[i][10])\n",
    "    eventCounter.append(read_data[i][6]+(read_data[i][7]<<16))\n",
    "    BoardID.append(read_data[i][9]>>8)  \n",
    "    decFactor.append(read_data[i][11]>>8)\n",
    "    chanDec.append(read_data[i][13]>>8)\n",
    "    postTrig.append(read_data[i][15]>>8)\n",
    "    groupStart.append(((read_data[i][13]&0x00FF)<<16)+read_data[i][12])\n",
    "    groupEnd.append(((read_data[i][15]&0x00FF)<<16)+read_data[i][14])\n",
    "    \n",
    "    timestamp.append(read_data[i][16]+(read_data[i][17]<<16)+(read_data[i][18]<<32)+(read_data[i][19]<<40))  \n",
    "    sizeFirstEvent.append(read_data[i][0]+(read_data[i][1]<<16))\n",
    "    TTT.append(read_data[i][2]+(read_data[i][3]<<16)+(read_data[i][4]<<32))\n",
    "    \n",
    "#     print(\"For channel \" + str(chan_enab[i]) + \", BoardID is \" + str(BoardID[i])\n",
    "#           + \"; record length is \" + str(recordLength[i]) + \"; num Samples is \" \n",
    "#           + str(numSamples[i]) + \"; event counter is \" + str(eventCounter[i]) + \"; dec factor is \" + str(decFactor[i]) + \"; chan dec is \" \n",
    "#           + str(chanDec[i]) + \"; postTrig is \" + str(postTrig[i]) + \"; group start is \" + str(groupStart[i]) + \"; group end is \" + str(groupEnd[i])\n",
    "#           + \"; epoch time is \" + str(timestamp[i]) +  \"; first event size is \" + str(sizeFirstEvent[i]) + \"; and ETTT is \" + str(TTT[i]) + \"\\n\")\n",
    "print(BoardID)\n",
    "print(recordLength)\n",
    "print(numSamples)\n",
    "print(eventCounter)\n",
    "print(decFactor)\n",
    "print(chanDec)\n",
    "print(postTrig)\n",
    "print(groupStart)\n",
    "print(groupEnd)\n",
    "print(timestamp)\n",
    "print(sizeFirstEvent)\n",
    "print(TTT)\n",
    "print()\n",
    "print(type(groupEnd[0]))\n",
    "\n",
    "BoardID      = np.asarray(BoardID,dtype =np.uint32) ## after changing to Numpy ver >2.0, dtype should be explicit. uint32 is the smallest size that does not ruin the xs below\n",
    "recordLength = np.asarray(recordLength,dtype =np.uint32)\n",
    "numSamples   = np.asarray(numSamples,dtype =np.uint32)\n",
    "eventCounter = np.asarray(eventCounter,dtype =np.uint32)\n",
    "decFactor    = np.asarray(decFactor,dtype =np.uint32)\n",
    "chanDec      = np.asarray(chanDec, dtype=np.uint32)\n",
    "postTrig     = np.asarray(postTrig,dtype =np.uint32)\n",
    "groupStart   = np.asarray(groupStart, dtype=np.uint32)\n",
    "groupEnd     = np.asarray(groupEnd, dtype=np.uint32)\n",
    "timestamp    = np.asarray(timestamp, dtype=np.uint32)\n",
    "sizeFirstEvent = np.asarray(sizeFirstEvent, dtype=np.uint32)\n",
    "TTT = np.asarray(TTT, dtype=np.uint32)\n",
    "\n",
    "print(BoardID)\n",
    "print(recordLength)\n",
    "print(numSamples)\n",
    "print(eventCounter)\n",
    "print(decFactor)\n",
    "print(chanDec)\n",
    "print(postTrig)\n",
    "print(groupStart)\n",
    "print(groupEnd)\n",
    "print(timestamp)\n",
    "print(sizeFirstEvent)\n",
    "print(TTT)\n",
    "\n",
    "print(type(groupEnd[0]))\n",
    "# print(\"Target is \" + target)\n",
    "# print(\"Foil is \" + foil)\n",
    "# print(\"Shutter is open: \" + str(bool(shutterFlag)))\n",
    "# print(\"Facility t0 is on: \" + str(bool(facilityTrigFlag)))\n",
    "# print(\"Spin flipper is on: \" + str(bool(spinFlipFlag)))\n",
    "# print(\"Spin filter is on: \" + str(bool(spinFiltFlag)))\n",
    "# print(\"Target is present: \" + str(bool(targetFlag)))\n",
    "# print(\"Foil is present: \" + str(bool(foilFlag)))\n",
    "\n",
    "if target == 'La':\n",
    "    vparamsfileloc = basedir+'/processed_data/'+'0_vparams_La.h5'\n",
    "elif target == 'Pr':\n",
    "    vparamsfileloc = basedir+'/processed_data/'+'1_vparams_Pr.h5'\n",
    "elif target == 'Tb203':\n",
    "    vparamsfileloc = basedir+'/processed_data/'+'2_vparams_Tb.h5'\n",
    "elif target == 'Ho203':\n",
    "    vparamsfileloc = basedir+'/processed_data/'+'3_vparams_Ho.h5'\n",
    "elif target == 'Tm203':\n",
    "    vparamsfileloc = basedir+'/processed_data/'+'4_vparams_Tm.h5'\n",
    "elif target == 'Yb203':\n",
    "    vparamsfileloc = basedir+'/processed_data/'+'5_vparams_Yb.h5'\n",
    "else:\n",
    "    vparamsfileloc = 'missing'\n",
    "    \n",
    "print(\"Target is \" + target + ', voigt fit params: ' + vparamsfileloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a965b07d-bb2e-4efa-a6a3-5ddec4a70988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'La', 1: 'Tb2O3', 2: 'Yb2O3', 3: 'Sm2O3', 4: 'Er2O3', 5: 'Ho2O3', 6: 'Pr', 7: 'other'}\n",
      "Pr\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(targetDict)\n",
    "print(target)\n",
    "print(targetFlag)\n",
    "print((read_data[0][5]&0x00F0)>>4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a3e87c-b28d-49ac-8dee-9dd7050ab051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31]\n",
      "[45000 45000 45000 45000 45000 45000 45000 45000 45000 45000 45000 45000\n",
      " 45000]\n",
      "[9000 9000 9000 9000 9000 9000 9000 9000 9000 9000 9000 9000 9000]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[32 32 32 32 32 32 32 32 32 32 32 32 32]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[80 80 80 80 80 80 80 80 80 80 80 80 80]\n",
      "[7000 7000 7000 7000 7000 7000 7000 7000 7000 7000 7000 7000 7000]\n",
      "[16000 16000 16000 16000 16000 16000 16000 16000 16000 16000 16000 16000\n",
      " 16000]\n",
      "[29772 29772 29772 29772 29772 29772 29772 29772 29772 29772 29772 29772\n",
      " 29772]\n",
      "[18040 18040 18040 18040 18040 18040 18040 18040 18040 18040 18040 18040\n",
      " 18040]\n",
      "[8797 8797 8797 8797 8797 8797 8797 8797 8797 8797 8797 8797 8797]\n"
     ]
    }
   ],
   "source": [
    "print(BoardID)\n",
    "print(recordLength)\n",
    "print(numSamples)\n",
    "print(eventCounter)\n",
    "print(decFactor)\n",
    "print(chanDec)\n",
    "print(postTrig)\n",
    "print(groupStart)\n",
    "print(groupEnd)\n",
    "print(timestamp)\n",
    "print(sizeFirstEvent)\n",
    "print(TTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c263987-d7c0-4e5c-ac12-6ebf3b75e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(recordLength)\n",
    "# print(postTrig)\n",
    "\n",
    "# rl = np.int64(recordLength[0])\n",
    "# print(rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9960c294-b9f3-4af0-a2b9-8ec7a0853b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the time axis for each channel\n",
    "############## OG ################\n",
    "\n",
    "preTime = []\n",
    "startTime = []\n",
    "endTime = []\n",
    "resolution = []\n",
    "xs = [] \n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    preTime.append((100-postTrig[i])*recordLength[i]/100)\n",
    "    startTime.append((-1*preTime[i]*16*decFactor[i] + groupStart[i]*16*decFactor[i]))\n",
    "    endTime.append((-1*preTime[i]*16*decFactor[i] + groupEnd[i]*16*decFactor[i]))\n",
    "    resolution.append(16*chanDec[i]*decFactor[i])\n",
    "#     print(\"Pretime for channel\", chan_enab[i],\"is \" + str(preTime[i]) + \"; start time is \" + str(startTime[i]) + \"; end time is \" + str(endTime[i]) \n",
    "#           + \"; resolution is \" + str(resolution[i]) + \"ns\")\n",
    "    xs.append(np.arange(startTime[i],(numSamples[i])*resolution[i]+startTime[i], resolution[i]))\n",
    "\n",
    "np.asarray(preTime)\n",
    "np.asarray(startTime)\n",
    "np.asarray(endTime)\n",
    "np.asarray(resolution)\n",
    "\n",
    "xs = np.asarray(xs) ## can convert xs to np array here because all detectors same numsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d60eda-bf0e-4fd8-a4ac-604ea6bbc7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 9000)\n",
      "[-1024000. -1023488. -1022976. ...  3582464.  3582976.  3583488.]\n"
     ]
    }
   ],
   "source": [
    "print(xs.shape)\n",
    "print(xs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267d815-0378-42be-bb58-11558825e078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a688df0e-6a6c-4219-a32e-5ae1e9f60d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(len(chan_enab)):\n",
    "#     # Cast to float64 to avoid overflow\n",
    "#     rl = np.int64(recordLength[i])\n",
    "#     pt = np.float64(postTrig[i])\n",
    "#     df = np.int64(decFactor[i])\n",
    "#     gs = np.int64(groupStart[i])\n",
    "#     ge = np.int64(groupEnd[i])\n",
    "#     cd = np.float64(chanDec[i])\n",
    "#     ns = np.float64(numSamples[i])\n",
    "\n",
    "#     preTime.append((100 - pt) * rl / 100)\n",
    "#     startTime.append((-1 * preTime[i] * 16 * df + gs * 16 * df))\n",
    "#     endTime.append((-1 * preTime[i] * 16 * df + ge * 16 * df))\n",
    "#     resolution.append(16 * cd * df)\n",
    "\n",
    "#     xs.append(np.arange(startTime[i], ns * resolution[i] + startTime[i], resolution[i]))\n",
    "\n",
    "# np.asarray(preTime)\n",
    "# np.asarray(startTime)\n",
    "# np.asarray(endTime)\n",
    "# np.asarray(resolution)\n",
    "\n",
    "# xs = np.asarray(xs) ## can convert xs to np array here because all detectors same numsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d9ec64b-464e-4d35-b5a6-0cc0ccc7648e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45000 45000 45000 45000 45000 45000 45000 45000 45000 45000 45000 45000\n",
      " 45000]\n",
      "45000\n"
     ]
    }
   ],
   "source": [
    "print(recordLength)\n",
    "print(recordLength[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61cfb8c1-a709-48c5-b5c8-13b704571ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine the time axis for each channel\n",
    "# ############## CHANGED ################\n",
    "\n",
    "# preTime = []\n",
    "# startTime = []\n",
    "# endTime = []\n",
    "# resolution = []\n",
    "# xs = [] \n",
    "\n",
    "# for i in range(0,len(chan_enab)):\n",
    "#     preTime.append((100-postTrig[i])*recordLength[i]/100)\n",
    "#     print(recordLength[i])\n",
    "#     print(type(preTime[0]))\n",
    "#     startTime.append((-1*preTime[i]*16*decFactor[i] + groupStart[i]*16*decFactor[i]))\n",
    "#     endTime.append((-1*preTime[i]*16*decFactor[i] + groupEnd[i]*16*decFactor[i]))\n",
    "#     resolution.append(16*chanDec[i]*decFactor[i])\n",
    "# #     print(\"Pretime for channel\", chan_enab[i],\"is \" + str(preTime[i]) + \"; start time is \" + str(startTime[i]) + \"; end time is \" + str(endTime[i]) \n",
    "# #           + \"; resolution is \" + str(resolution[i]) + \"ns\")\n",
    "#     xs.append(np.arange(startTime[i],(numSamples[i])*resolution[i]+startTime[i], resolution[i]))\n",
    "\n",
    "# np.asarray(preTime)\n",
    "# np.asarray(startTime)\n",
    "# np.asarray(endTime)\n",
    "# np.asarray(resolution)\n",
    "\n",
    "# xs = np.asarray(xs) ## can convert xs to np array here because all detectors same numsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b21f5c-1bfb-4609-99b7-6b7160020202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 9000)\n"
     ]
    }
   ],
   "source": [
    "print(xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06edf1af-27de-425a-a1a3-88e2a520e1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataread from binary time: 1.9867591857910156\n"
     ]
    }
   ],
   "source": [
    "# In[4]:\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "@njit\n",
    "def dataread(data, channels, fileLen, numSamps):\n",
    "    numRuns = int((fileLen[0]-20-numSamps[0])/(numSamps[0]+6)+1)\n",
    "    ys_arr = np.zeros((len(channels), numRuns,numSamps[0]), dtype=np.uint16)\n",
    "    ETTT_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    eventcount_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    for i in range(0,len(channels)):\n",
    "        eventCount = 0\n",
    "        byteCounter = 0\n",
    "            #byte counter is really 2bytecounter, lol\n",
    "        while byteCounter < fileLen[i]:\n",
    "            if byteCounter == 0:\n",
    "                ETTT_arr[i]=TTT[i]\n",
    "                #ETTT_arr[i].append(TTT[i])\n",
    "                eventcount_arr[i]=(eventCounter[i])\n",
    "                byteCounter = 20\n",
    "            else:\n",
    "                ETTT_arr[i]=(data[i][byteCounter]+(data[i][byteCounter+1]<<16)+(data[i][byteCounter+2]<<32))\n",
    "                eventcount_arr[i]=(data[i][byteCounter+4]+(data[i][byteCounter+5]<<16))\n",
    "                byteCounter += 6\n",
    "            for j in range(0, numSamps[i]):\n",
    "                #if j == 0:\n",
    "                    #ys_arr[i].append([])\n",
    "                #print(byteCounter)\n",
    "                ys_arr[i][eventCount][j]=data[i][byteCounter]\n",
    "                byteCounter += 1\n",
    "            eventCount += 1\n",
    "    return ys_arr, ETTT_arr, eventcount_arr\n",
    "\n",
    "start=time.time()\n",
    "# ys_arrHe, ETTT_arrHe, eventcount_arrHe  = dataread(read_data, [25], fileLength, numSamples) ##hardcoded channel 25 for He\n",
    "ys_arr, ETTT_arr, eventcount_arr  = dataread(read_data, chan_enab, fileLength, numSamples) ##hardcoded channels for coils\n",
    "\n",
    "end = time.time()\n",
    "print('dataread from binary time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e2872e-26c1-4e74-88ad-e22fbd29e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "\n",
    "timeDif=[]\n",
    "for i in range(0,len(chan_enab)):\n",
    "    timeDif.append([])\n",
    "    for j in range(len(ETTT_arr[i])-1):\n",
    "        timeDif[i].append((ETTT_arr[i][j+1]-ETTT_arr[i][j])*8)\n",
    "#     print(\"Min time difference for channel\", chan_enab[i], \"is\", min(timeDif[i]), \"ns\")\n",
    "#     print(\"Max time difference for channel\", chan_enab[i], \"is\", max(timeDif[i]), \"ns \\n\")\n",
    "#print(timeDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f3553cd-86e9-4edc-b758-2928b06ee35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[6]:\n",
    "\n",
    "# Load in SF and He normalization information ##\n",
    "\n",
    "try:\n",
    "    df_SF = pd.read_hdf(SFNormFile + '.h5', key='df_0')\n",
    "    df_HE = pd.read_hdf(SFNormFile + '.h5', key='df_1')\n",
    "except Exception as e:\n",
    "    logger.error('run '+run_num + ' failed during SFNormFile load')\n",
    "    logger.exception(e)\n",
    "\n",
    "SF_Sort_arr = df_SF[['nicknames', 'transition_locations']].to_numpy().T\n",
    "He_Norm_arr = df_HE[['pulse', 'norms','puckval']].to_numpy().T\n",
    "\n",
    "if shutterFlag == 0:\n",
    "    print('Shutter closed. NormFactor set to 1')\n",
    "    NormFactor = 1\n",
    "if shutterFlag == 1:\n",
    "    NormFactor = 1000000 ## He integrals are huge, this normalizes all of those by a constant value for ease of use\n",
    "\n",
    "HeNorms= (He_Norm_arr[1])/NormFactor\n",
    "\n",
    "# print(SF_Sort_arr)\n",
    "# print(He_Norm_arr[1]/NormFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d01196-53c4-4dee-9b7e-bde4eb5d1c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2044. 2044. 2044. ... 2043. 2044. 2044.]\n"
     ]
    }
   ],
   "source": [
    "print(He_Norm_arr[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64e6685f-062b-4dae-ac68-40f9e29f4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "# basesub and plotting ##\n",
    "start = time.time()\n",
    "\n",
    "baseL = 0\n",
    "baseR = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])  ##70% before the trigger\n",
    "numRuns = int((fileLength[0]-20-numSamples[0])/(numSamples[0]+6)+1)\n",
    "legend =  ['NaI', 'R']\n",
    "\n",
    "s = 20 ## pulse to look at\n",
    "t=s+1\n",
    "\n",
    "#  dont know why this is so slow ##\n",
    "def plotter(ys, xs, baseR, numpoints):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "    for i in range((len(ys))):\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "        for j in range(s, t): ## plot only interested pulses\n",
    "            plt.plot(xs[i], tempys_basesub[i][j]) #label=legend[i]) #+str(sums[1][j])) ## sums[j] will not work for more than just TR   \n",
    "            plt.axvline(xs[0][baseL], ls = '--')\n",
    "            plt.axvline(xs[0][baseR], ls = '--')\n",
    "            #plt.axvline(xs[0][int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])], ls = '--', c ='m')\n",
    "            plt.axvline(xs[0][baseR+5], ls = '--', c ='r') ## BaseR+5 line marks the beginning of the integral, until the end of samples.\n",
    "#             plt.title('SF state transition' + transitions[p]) \n",
    "#             plt.xlabel(\"time from trigger (ns)\")\n",
    "#             plt.ylabel(\"ADC\")\n",
    "            plt.legend()\n",
    "            \n",
    "# plotter(ys_arr[9:], xs[9:], baseR, numSamples) ##plot coils\n",
    "\n",
    "@njit ## jit is faster for large # channels, slower for small # channels\n",
    "def basesub(ys, baseRight, numpoints): \n",
    "    tempys_basesub = np.zeros((numRuns,numpoints[0]), dtype=np.float64)\n",
    "    for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "        tempys_basesub[pulse]=np.subtract(ys[pulse], np.mean(ys[pulse][baseL:baseRight]))\n",
    "    return tempys_basesub\n",
    "\n",
    "@njit ## jit is faster for large # channels, slower for small # channels\n",
    "def basesub_norm(ys, baseRight, numpoints): \n",
    "    tempys_basesub = np.zeros((numRuns,numpoints[0]), dtype=np.float64)\n",
    "    for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "        tempys_basesub[pulse]=np.subtract(ys[pulse], np.mean(ys[pulse][baseL:baseRight]))\n",
    "        tempys_basesub[pulse]=tempys_basesub[pulse]/HeNorms[pulse] \n",
    "    return tempys_basesub\n",
    "\n",
    "ys_basesub = np.zeros((len(ys_arr), numRuns,numSamples[0]), dtype=np.float64)\n",
    "# ys_basesub_norm = np.zeros((len(ys_arr), numRuns,numSamples[0]), dtype=np.float64)\n",
    "\n",
    "for i in range(len(ys_basesub)): ## feeding y arrays into function 1 channel at  a time is faster than all at once\n",
    "    ys_basesub[i] = basesub(ys_arr[i], baseR, numSamples)\n",
    "# for i in range(len(ys_basesub)): ## feeding y arrays into function 1 channel at  a time is faster than all at once\n",
    "#     ys_basesub[i] = basesub_norm(ys_arr[i], baseR, numSamples)\n",
    "\n",
    "ys_basesub[-1] = ys_basesub[-1]*-1 ## invert 6Li to positive signal. Comment out if not using\n",
    "# ys_basesub_norm[-1] = ys_basesub_norm[-1]*-1 ## invert 6Li to positive signal. Comment out if not using\n",
    "\n",
    "end = time.time()\n",
    "# print('plotting and/or base subtraction time: ' + str(end-start))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53e8b5ff-dc2f-4fc4-b305-8f39a2c51bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[8]:\n",
    "\n",
    "# use 6Li t0 for all instead of for themselves individually ##\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "NaIthresh=2000\n",
    "Li6thresh=1000\n",
    "threshold_array = (np.full(len(ys_basesub), NaIthresh))\n",
    "threshold_array[-1] = Li6thresh\n",
    "\n",
    "# njit ## numba does not support reversed, but this could be changed if it's slow\n",
    "def find_offset(ys, thresharr):\n",
    "    xCrosses = np.zeros((len(ys), numRuns)) #outer array is crossing arrays for given channel, inner array is crossing for each event\n",
    "    offset = np.zeros((len(ys), numRuns), dtype=np.int32) ##offset in bins for each channel, each pulse\n",
    "    modeCrosses = np.zeros((len(ys)), dtype=np.float64)\n",
    "    for i in reversed(range(len(ys))):\n",
    "        #xValues.append([])\n",
    "        for p in range(len(ys[i])):\n",
    "            xing = np.argmax(ys[i][p] > thresharr[i])\n",
    "            #print(xing)\n",
    "            xCrosses[i][p] = xing\n",
    "        modeCrosses[i] = (st.mode(xCrosses[i])) #find the most typical crossing value for each channel\n",
    "        for p in range(len(xCrosses[i])):\n",
    "            offset[i][p] = (modeCrosses[-1] - xCrosses[i][p]) ## make sure this is the correct sign!!! \n",
    "    if (np.all(xCrosses[-1])) == False:\n",
    "        emessage = ('ERROR: 6Li threshold was not reached for at least one pulse')\n",
    "        logger.error('run '+run_num + emessage)\n",
    "        raise Exception(emessage)\n",
    "    return offset, xCrosses, modeCrosses\n",
    "                           \n",
    "offset, xCrosses, modeCrosses = find_offset(ys_basesub, threshold_array)\n",
    "\n",
    "end = time.time()\n",
    "# print('finding offset time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "091b88d3-767c-4e05-8a46-5d88bacda536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[9]:\n",
    "## new numba versions for array shifting\n",
    "@njit\n",
    "def pad_numba(array, pad_width, constant_value=0.0):\n",
    "    padded = np.empty(len(array) + 2 * pad_width, dtype=array.dtype)\n",
    "    for i in range(pad_width):\n",
    "        padded[i] = constant_value\n",
    "    for i in range(len(array)):\n",
    "        padded[i + pad_width] = array[i]\n",
    "    for i in range(pad_width):\n",
    "        padded[len(array) + pad_width + i] = constant_value\n",
    "    return padded\n",
    "\n",
    "@njit\n",
    "def roll_numba(array, shift):\n",
    "    n = len(array)\n",
    "    result = np.empty_like(array)\n",
    "    for i in range(n):\n",
    "        result[(i + shift) % n] = array[i]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cafb6f0-5208-4a82-bdb8-edc0b0d11cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend all arrays by a value, check that the max number of offset on 6Li is less than that value ##\n",
    "del read_data ## don't believe this is used anymore, make up some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e10fa18c-30f1-432c-a4e6-b61fab887e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "n_channels, n_pulses, og_length =  ys_basesub.shape[0], ys_basesub.shape[1], ys_basesub.shape[2]\n",
    "extendedRange = 3 ## must be a positive value which to extend ys_arr\n",
    "if abs(max(offset[-1], key = abs)) > extendedRange: ## if the max offset of 6Li is >extendedRange, something is wrong\n",
    "    emessage = ('ERROR: largest offset greater than extended range')\n",
    "    logger.error('run '+run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "new_length = og_length - 2*extendedRange - 2  ##should be the new length of the array\n",
    "\n",
    "try:\n",
    "    # ys_ext = np.zeros((len(ys_basesub), len(ys_basesub[0]), len(ys_basesub[0][0])+extendedRange*2), dtype=np.float64)\n",
    "    ys_cut = np.zeros((n_channels, n_pulses, new_length))\n",
    "    xs_cut = np.zeros((len(ys_cut), len(ys_cut[0][0])))\n",
    "except Exception as e:\n",
    "    logger.error('run '+run_num + ' failed during ys_cut array creation')\n",
    "    logger.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86cf1ce1-23a9-4fe7-8f71-ddbc6ac5f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning and cutting time: 9.295430421829224\n"
     ]
    }
   ],
   "source": [
    "# change np.pad and .roll to be numba applicable##\n",
    "@njit\n",
    "def align_cut_numba(ys, xs_arr, extendedr):\n",
    "    tempys_ext = np.zeros((len(ys), len(ys[0])+extendedr*2), dtype=np.float64)\n",
    "    tempys_cut = np.zeros((len(ys), (len(tempys_ext[0])-((extendedr*2)+1)*2)))\n",
    "    tempxs_cut = np.zeros(len(tempys_cut[0]))\n",
    "    for p in range(len(ys)):\n",
    "#         tempys_ext[p] = np.pad(ys[p], extendedr, 'constant', constant_values=(0)) # these 2 are from older align_cut\n",
    "#         tempys_ext[p] = np.roll(tempys_ext[p],offset[-1][p]) ## assumes 6Li at -1 position\n",
    "        tempys_ext[p] = pad_numba(ys[p], extendedr) ## asumes constant fill = 0\n",
    "        tempys_ext[p] = roll_numba(tempys_ext[p],offset[-1][p]) ## assumes 6Li at -1 position\n",
    "        tempys_cut[p] = tempys_ext[p][((extendedr*2)+1):-((extendedr*2)+1)].copy() ## cut by 7 (if extRange == 3)\n",
    "        tempys_cut[p] = tempys_cut[p]/HeNorms[p] ## normalize by 3He integral  ## comment out if using basesub_norm\n",
    "    x_cut_amt = int((len(ys[0]) - len(tempys_cut[0]))/2)\n",
    "    tempxs_cut = xs_arr[x_cut_amt:-x_cut_amt].copy()\n",
    "    return tempys_cut, tempxs_cut\n",
    "\n",
    "# looping every channel through function is 5x faster ##\n",
    "try:\n",
    "    for i in range(len(ys_basesub)):\n",
    "        ys_cut[i], xs_cut[i] = align_cut_numba(ys_basesub[i], xs[i], extendedRange)\n",
    "except Exception as e:\n",
    "    logger.error('run '+run_num + ' failed aligning and cutting')\n",
    "    logger.exception(e)\n",
    "    \n",
    "# checkp = 2053\n",
    "# print(offset[-1][checkp]) ## checking offset for one example checkpulse\n",
    "# print('original index for checkpulse: '+str(np.argmax(ys_basesub[0][checkp]> 2000))) ## we can follow the index as it changes with extension/cut\n",
    "# #print('extended range index for checkpulse: '+str(np.argmax(ys_ext[0][checkp]> 2000)))\n",
    "# print('cut array index for checkpulse: '+str(np.argmax((ys_cut[0][checkp]*HeNorms[checkp])> 2000)))\n",
    "\n",
    "del ys_basesub  ## might help with mem issues\n",
    "\n",
    "end = time.time()\n",
    "print('aligning and cutting time: ' + str(end-start))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7de17422-be00-476f-9eaf-78b1255b2baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# begin SF organization ##\n",
    "# In[11]:\n",
    "\n",
    "def organize_SF(SFsort_info): ## sometimes pulse 0 has the state switch. In that case, need to account by if clauses below\n",
    "    counter = 0\n",
    "    seq = 0\n",
    "    seq_arr = ([[],[],[]])\n",
    "    smallerseq = []\n",
    "    smallerstateis = []\n",
    "    for i in range(len(SFsort_info[1])-(np.mod((len(SFsort_info[1])), 8))):  ##111 mod 8 = 7, so essentially 111-7 = 104\n",
    "        counter = counter+1\n",
    "        if counter < 8:\n",
    "            if (SF_Sort_arr[1][i]) == 0: ## catches state switches at pulse 0\n",
    "                smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "                smallerseq.append(SFsort_info[0][i+1])\n",
    "                seq = seq+1\n",
    "                continue\n",
    "            smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "            smallerseq.append(SFsort_info[0][i+1])\n",
    "        elif counter == 8:\n",
    "            if ((SF_Sort_arr[1][i])+45) >= 5000: ## breaks for state switches at pulse 0\n",
    "                print(((SF_Sort_arr[1][i])+5))\n",
    "                seq = seq+1\n",
    "                seq_arr[0].append(seq)\n",
    "                seq_arr[1].append(smallerseq)   \n",
    "                seq_arr[2].append(smallerstateis)\n",
    "                seq_arr[0] = [x-1 for x in seq_arr[0]] ## reset so sequences are 1-14 instead of 2-15\n",
    "                break\n",
    "            seq = seq+1 ## otherwise continue regular sorting\n",
    "            smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "            smallerseq.append(SFsort_info[0][i+1])\n",
    "            seq_arr[0].append(seq)\n",
    "            seq_arr[1].append(smallerseq)   \n",
    "            seq_arr[2].append(smallerstateis)\n",
    "            smallerseq = []\n",
    "            smallerstateis = []\n",
    "            counter  = 0\n",
    "    return seq_arr\n",
    "\n",
    "def find_leftover(SFsort_info, seq_arr): ## in case we want to use the other 6 states left over\n",
    "    left = [[seq_arr[0][-1]+1],[],[]]\n",
    "    counter = 0\n",
    "    for i in range((len(SFsort_info[1])-(np.mod((len(SFsort_info[1])), 8))), len(SFsort_info[1])-1):\n",
    "        counter = counter+1\n",
    "        if counter < 8:\n",
    "            left[1].append(SFsort_info[0][i+1])\n",
    "            left[2].append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "    return left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c5d6b68-e481-4586-a94c-2bd7149a6827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 sequences with sequence order: [2, 3, 4, 5, 6, 7, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sequence = organize_SF(SF_Sort_arr)\n",
    "    if len(sequence[0]) == 14: ## catches state switches at pulse 0, leftovers are at the end of the regular sequence\n",
    "        leftovers = [[sequence[0][-1]],[sequence[1][-1]],[sequence[2][-1]]]\n",
    "        for i in range(len(sequence)):\n",
    "            sequence[i].pop(-1) ## deletes the leftovers sequence for state switches at pulse 0\n",
    "    else:\n",
    "        leftovers = find_leftover(SF_Sort_arr, sequence) ## otherwise can use normal function\n",
    "except Exception as e:\n",
    "    logger.error('run '+run_num + ' failed during sequencing')\n",
    "    logger.exception(e)\n",
    "\n",
    "# print('sequences '+str(sequence[0]))\n",
    "print(str(len(sequence[0]))+' sequences with sequence order: '+str(sequence[1][0]))\n",
    "# print(leftovers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a8f6881-822f-403d-9407-49200dec7a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 5000, 8992)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19aca2bdbd0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "print(ys_cut.shape)\n",
    "plt.plot(ys_cut[-1][20])\n",
    "plt.plot(ys_cut[-2][20])\n",
    "plt.plot(ys_cut[-3][20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "524de4b6-6131-439c-b209-2af13a2e8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  add up pulses for their respective state, in each 8 step sequence ##\n",
    "#  turning into a by-channel function 06.13.24 ##\n",
    "\n",
    "start = time.time()\n",
    "sequence = np.asarray(sequence, dtype = object)\n",
    "\n",
    "ON_sums = np.zeros((len(ys_cut), len(sequence[0]), len(ys_cut[0][0])), dtype=np.float64) ## 13 channels, 13 sequences, added pulses for ON\n",
    "OFF_sums = np.zeros((len(ys_cut), len(sequence[0]), len(ys_cut[0][0])), dtype=np.float64) ## 13 channels, 13 sequences, added pulses for OFF\n",
    "\n",
    "# @njit\n",
    "def add_pulse(ys, SFarr):\n",
    "    temp_ON = np.zeros((len(SFarr[0]), len(ys[0])), dtype=np.float64)\n",
    "    temp_OFF = np.zeros((len(SFarr[0]), len(ys[0])), dtype=np.float64)\n",
    "    for seq in range(0, len(SFarr[0])): ## for every sequence\n",
    "    #         print('seq:' +str(SFarr[0][seq]))\n",
    "#         print('seq:' +str(seq))\n",
    "        for state in range(0, len(SFarr[1][0])): ## for every state in the sequence\n",
    "    #         print(\"states loop \" + str(range(0, len(SFarr[1][0]))[0]) + ' - ' +  str(range(0, len(SFarr[1][0]))[-1]))\n",
    "            s = SFarr[1][seq][state] ## try this to condense code. Basically, the state currently at\n",
    "            if s==0 or s==3 or s==5 or s==6: ## these are ON states\n",
    "#                 print('ON \"s\" state '+str(s))\n",
    "#                 print('\"state\" ' +str(state) + ' from ' + str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))))\n",
    "#                 print('sums from '+str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[0]) +\n",
    "#                 ' - ' +str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[-1]) + '\\n')\n",
    "                for p in range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1])): ##From 20-60 for example. SFarr[2] is the array of start to end pulses to sum\n",
    "                    temp_ON[seq] = np.add(temp_ON[seq],ys[p]) ## start with zeros, add to each iteratively\n",
    "            if s==1 or s==2 or s==4 or s==7: ## these are OFF states\n",
    "#                 print('OFF \"s\" state '+str(s))\n",
    "#                 print('\"state\" ' +str(state) + ' from ' + str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))))\n",
    "#                 print('sums from '+str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[0]) +\n",
    "#                 ' - ' +str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[-1]) + '\\n')\n",
    "                for p in range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1])):\n",
    "                    temp_OFF[seq] = np.add(temp_OFF[seq],ys[p])\n",
    "    return temp_ON, temp_OFF\n",
    "\n",
    "for i in range(len(ys_cut)):\n",
    "#     print('#################### channel: ' + str(i) + ' ##########################')\n",
    "    ON_sums[i], OFF_sums[i] = add_pulse(ys_cut[i], sequence)\n",
    "    \n",
    "# for i in range(len(ys_basesub)-12):\n",
    "#     print('#################### channel: ' + str(i) + ' ##########################')\n",
    "#     ON_sums[i], OFF_sums[i], ON_minus_sums[i], ON_plus_sums[i] = add_pulse(ys_basesub[i], sequence)\n",
    "\n",
    "end = time.time()\n",
    "# print('summing pulses into their states time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a13849b2-a786-43b3-ac6d-bf4f209143c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporating new polyfit functions\n",
    "@njit\n",
    "def polyN_fit_errors(x, y, degree):\n",
    "    \"\"\"Fit y = a0*x^n + a1*x^(n-1) + ... + an using least squares and return errors.\n",
    "Returns:\n",
    "        coeffs : array of fitted coefficients [a0, a1, ..., an]\n",
    "        stderr : array of standard errors (1-sigma) for each coefficient\"\"\"\n",
    "    n = x.shape[0]\n",
    "    A = np.empty((n, degree + 1))\n",
    "    for i in range(n):\n",
    "        xi = x[i]\n",
    "        A[i, degree] = 1.0\n",
    "        for j in range(degree - 1, -1, -1):\n",
    "            A[i, j] = A[i, j + 1] * xi\n",
    "\n",
    "    ATA = A.T @ A\n",
    "    ATy = A.T @ y\n",
    "    coeffs = np.linalg.solve(ATA, ATy)\n",
    "\n",
    "    # Calculate residuals and variance\n",
    "    y_fit = A @ coeffs\n",
    "    residuals = y - y_fit\n",
    "    dof = n - (degree + 1)\n",
    "    residual_variance = np.sum(residuals**2) / dof\n",
    "\n",
    "    # Covariance matrix and standard errors\n",
    "    cov_matrix = np.linalg.inv(ATA) * residual_variance\n",
    "    stderr = np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "    return coeffs, stderr\n",
    "\n",
    "def polyN_predict(x, coeffs):\n",
    "    '''Evaluate polynomial at x using Horner's method.\n",
    "Parameters:\n",
    "        x : 1D array of input data\n",
    "        coeffs : 1D array of coefficients [a0, a1, ..., an]'''\n",
    "    n = x.shape[0]\n",
    "    y = np.empty(n)\n",
    "    degree = coeffs.shape[0]\n",
    "    for i in range(n):\n",
    "        xi = x[i]\n",
    "        yi = coeffs[0]\n",
    "        for j in range(1, degree):\n",
    "            yi = yi * xi + coeffs[j]\n",
    "        y[i] = yi\n",
    "    return y\n",
    "\n",
    "## don't need the below version, but keeping it for \"posterity\"\n",
    "@njit\n",
    "def polyN_fit_chi2_w2(x, y, sigma, degree): \n",
    "    '''need to input an error array sigma. First pass can be sigma = np.full_like(x, 1), \n",
    "    get new sigmas with sigma_from_resid = np.full_like(y_scaled, np.std(residuals))\n",
    "    Weighted least squares polynomial fit of any degree.\n",
    "    Returns: coeffs=poly coeff stderr=1-sigma error for each coefficient, red_chi2=reduced chi-squared, residuals=y - y_fit (unweighted)'''\n",
    "    n = x.shape[0]\n",
    "    A = np.empty((n, degree + 1))\n",
    "    for i in range(n):\n",
    "        xi = x[i]\n",
    "        A[i, degree] = 1.0\n",
    "        for j in range(degree - 1, -1, -1):\n",
    "            A[i, j] = A[i, j + 1] * xi\n",
    "\n",
    "    # Apply weights\n",
    "    for i in range(n):\n",
    "        for j in range(degree + 1):\n",
    "            A[i, j] /= sigma[i]\n",
    "    y_weighted = y / sigma\n",
    "\n",
    "    ATA = A.T @ A\n",
    "    ATy = A.T @ y_weighted\n",
    "    coeffs = np.linalg.solve(ATA, ATy)\n",
    "\n",
    "    # Compute fitted values and residuals\n",
    "    y_fit = A @ coeffs\n",
    "    residuals = y_weighted - y_fit\n",
    "\n",
    "    chi2 = np.sum(residuals**2)\n",
    "    dof = n - (degree + 1)\n",
    "    red_chi2 = chi2 / dof\n",
    "\n",
    "    cov_matrix = np.linalg.inv(ATA) * red_chi2\n",
    "    stderr = np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "    # Convert residuals back to original units\n",
    "    res_unweighted = (y_weighted - y_fit) * sigma\n",
    "\n",
    "    return coeffs, stderr, red_chi2, res_unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f13076-93f0-48f1-ace8-7a202b07ef8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "837a2ddc-ea8f-407f-b3a9-61aca1e0cfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13, 8992)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19aca579f90>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ON_sums.shape)\n",
    "plt.plot(ON_sums[-1][1])\n",
    "plt.plot(ON_sums[-2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7676b4a5-3345-437b-a2e8-a18b2e3c751e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00437470-9466-4bca-be28-8b2e2d51f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bg fitting\n",
    "\n",
    "### load in voigt values and regions\n",
    "v_sigmas = []\n",
    "v_gammas = []\n",
    "v_reslocs = []\n",
    "with h5py.File(vparamsfileloc, 'r') as f: ## new arr_sizer\n",
    "    channels_all = list(f.keys())\n",
    "    # print(np.asarray(f.attrs))\n",
    "    # print(np.asarray(f[channels_all[0]].attrs))\n",
    "    bg_reg1 = f.attrs.get('bg_reg_bef')\n",
    "    bg_reg2 = f.attrs.get('bg_reg_aft')\n",
    "    res_reg = f.attrs.get('res_reg')\n",
    "    for i in range(chan_enab[0], chan_enab[-1]):\n",
    "#         print(i)\n",
    "        v_sigmas.append(f[channels_all[i]].attrs.get('sigma_[mean,mode,std]')) ## each of these for each channel\n",
    "        v_gammas.append(f[channels_all[i]].attrs.get('gamma_[mean,mode,std]'))\n",
    "        v_reslocs.append(f[channels_all[i]].attrs.get('res_loc_[mean,mode,std]')) ## in ms, not bins\n",
    "    f.close()\n",
    "\n",
    "v_sigmas = np.asarray(v_sigmas)\n",
    "v_gammas = np.asarray(v_gammas)\n",
    "v_reslocs = np.asarray(v_reslocs)\n",
    "fullrange = bg_reg2[1]-bg_reg1[0]\n",
    "\n",
    "## one f_g/l/v for each channel\n",
    "f_g = 2*(v_sigmas[:,0])*np.sqrt(2*np.log(2)) ## Gaussian FWHM\n",
    "f_l = 2*(v_gammas[:,0]) ##Lorentzian FWHM\n",
    "f_v = 0.5343*f_l + np.sqrt(0.2169*f_l**2+f_g**2)  ## this is the FWHM from wikipedia. # one FWHM value for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e282e2c4-bcdb-4954-8c8c-cd043c983879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import voigt_profile\n",
    "from scipy.optimize import curve_fit\n",
    "## change to 2nd order poly in cleaned up version\n",
    "start = time.time()\n",
    "\n",
    "def bg_fitsubtract(bef_res_reg, aft_res_reg, ys, order): ## before/after resonance region [start:end] respectively, ys[ch] to fit\n",
    "    binstot = aft_res_reg[1]-bef_res_reg[0]  ## total number of bins in whole region\n",
    "    x1 = np.arange(bef_res_reg[0], bef_res_reg[1],1)\n",
    "    x2 = np.arange(aft_res_reg[0], aft_res_reg[1],1)\n",
    "    x = np.append(x1,x2)\n",
    "    fullx = np.arange(bef_res_reg[0], aft_res_reg[1],1) ## an array of every x bin in entire region\n",
    "    ys_bgsub = []\n",
    "    for seq in range(0, len(ys)): ## number of sequences, usually 13\n",
    "        fitdata1 = ys[seq][bef_res_reg[0]: bef_res_reg[1]]\n",
    "        fitdata2 = ys[seq][aft_res_reg[0]: aft_res_reg[1]]\n",
    "        datasplice = np.append(fitdata1, fitdata2)\n",
    "        y = datasplice\n",
    "        \n",
    "        coeffs, errs = polyN_fit_errors(x, y,order) # use new fit functions \n",
    "    #     print(\"Fitted Coefficients:\", coeffs)\n",
    "    #     print('Uncertainty ', errs)\n",
    "        y_fit = polyN_predict(x, coeffs) ## run the function with the coeff you just found\n",
    "        fullpoly_y2 = polyN_predict(fullx, coeffs)\n",
    "\n",
    "        bgsubtracted = ys[seq][bef_res_reg[0]:aft_res_reg[1]] - fullpoly_y2  ## subtracts RealData-BackgroundFit\n",
    "        ys_bgsub.append(bgsubtracted)\n",
    "    return ys_bgsub\n",
    "\n",
    "# background subtraction currently only for NaI detectors\n",
    "num_fittingchs = len(ON_sums)-1  ## removes the Li detector, assumes it is there\n",
    "ON_bgsub = np.zeros((num_fittingchs,len(ON_sums[0]),fullrange), dtype = np.float64) ## channels, sequences, range of bg_ subtraction\n",
    "OFF_bgsub = np.zeros((num_fittingchs,len(ON_sums[0]),fullrange), dtype = np.float64) ## channels, sequences, range of bg_ subtraction\n",
    "fitorder = 4\n",
    "for i in range(0, len(ON_sums)-1):\n",
    "    if chan_enab[i] == 24:\n",
    "        emessage = ('bg_ fit does not work for 6Li yet')\n",
    "        logger.error('run '+run_num + emessage)\n",
    "        raise Exception(emessage)\n",
    "    ON_bgsub[i]  = bg_fitsubtract(bg_reg1,bg_reg2, ON_sums[i], fitorder)\n",
    "    OFF_bgsub[i] = bg_fitsubtract(bg_reg1,bg_reg2, OFF_sums[i], fitorder)\n",
    "\n",
    "# end = time.time()\n",
    "# print('bg_ fitting time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "088c2e0d-b0ea-4884-bfea-f9fd096845fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 13, 2100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19aedc25a90>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ON_bgsub.shape)\n",
    "plt.plot(ON_bgsub[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cf35a-fefa-45cc-b4d7-a0dc46ecb037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a46e606-39aa-41d6-a07d-8fb18442afd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now new voigt, with constants\n",
    "\n",
    "## define new voigt functions using constants loaded in\n",
    "def voigt_c(x, amp): ## takes sig, gamma, res_loc as constants from file\n",
    "    fit = voigt_profile(x-xloc[0], sig[0], gam[0])*amp ## [0] indicates the mean value of param, not mode or std\n",
    "    return fit\n",
    "\n",
    "def voigt_fitting_c(ogbin_res_reg, aftrebin_res_reg,xs,ys): ## currently xdata which uses ogbin_res_reg is defined outside of function. But keeping it as an input for now.\n",
    "    fit_curves = [] ## now this function uses the res region as opposed to the not-background-region\n",
    "    parameters = []\n",
    "    for seq in range(0, len(ys)): ## number of sequences, usually 13\n",
    "        ydata = ys[seq][aftrebin_res_reg[0]:aftrebin_res_reg[1]]\n",
    "        popt, pcov = curve_fit(voigt_c, xs, ydata,p0=[np.max(ydata)], bounds = ([-np.inf], [np.inf]))\n",
    "        fitted_curve = voigt_c(xs, popt[0],) ## sigma, gamma, xshift (res. center), amp. related thing \n",
    "        # popt, pcov = curve_fit(voigt2, xs, ydata, bounds = ([0,0,0,-np.inf], [np.inf,np.inf,np.inf, np.inf]))  ## these are from the old function\n",
    "        # fitted_curve = voigt2(xs, popt[0],popt[1],popt[2],popt[3],) ## sigma, gamma, xshift (res. center), amp. related thing\n",
    "        fit_curves.append(fitted_curve)\n",
    "        fit_params = popt[0]\n",
    "        fit_errs = np.diagonal(pcov)[0]\n",
    "        parameters.append([fit_params,fit_errs])  ## only return the amplitude parameter now\n",
    "    return fit_curves, parameters\n",
    "\n",
    "## go back to original voigt fitting but this time with suggested guesses and bounds on possible param\n",
    "\n",
    "def voigt2(x, s, g, amp):\n",
    "    fit = voigt_profile(x-xloc[0], s, g)*amp\n",
    "    return fit\n",
    "\n",
    "def voigt_fitting(ogbin_res_reg, aftrebin_res_reg,xs,ys):\n",
    "    fit_curves = []\n",
    "    parameters = []\n",
    "    for seq in range(0, len(ys)): ## number of sequences, usually 13\n",
    "        ydata = ys[seq][aftrebin_res_reg[0]:aftrebin_res_reg[1]]\n",
    "        a_guess, s_guess, g_guess = np.max(ydata), sig[0], gam[0]\n",
    "        s_1std, g_1std = sig[2]/2, gam[2]/2  ## allow for half of the std\n",
    "        ## set the guesses as the loaded values, and the bounds on sigma,gamma as +/- 1 std\n",
    "        popt, pcov = curve_fit(voigt2, xs, ydata,p0=[s_guess,g_guess,a_guess], bounds = ([s_guess-s_1std,g_guess-g_1std,-np.inf], [s_guess+s_1std,g_guess+g_1std,np.inf]))\n",
    "        fitted_curve = voigt2(xs, popt[0],popt[1],popt[2]) ## sigma, gamma, amp. related thing\n",
    "        fit_curves.append(fitted_curve)\n",
    "        fit_params = popt\n",
    "        fit_errs = np.diagonal(pcov)\n",
    "        parameters.append([fit_params,fit_errs])\n",
    "    return fit_curves, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f20f7b40-07af-4f25-9458-f288d6f3ddd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg_ fitting time: 8.273010969161987\n"
     ]
    }
   ],
   "source": [
    "if res_reg[0] < bg_reg1[1] or res_reg[1]>bg_reg2[0]:\n",
    "    emessage = ('Declared Background region and Resonance region have overlapping fitting regions')\n",
    "    logger.error('run '+run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "    \n",
    "# start = time.time()\n",
    "\n",
    "res_size    = res_reg[1]-res_reg[0] \n",
    "newresstart = res_reg[0]-bg_reg1[0]\n",
    "newresend   = (res_reg[1]-res_reg[0])+newresstart\n",
    "new_res_reg = [newresstart, newresend]  ## this just realigns in terms of bins. Probably a nicer way to do it.\n",
    "\n",
    "xdata = xs_cut[0][res_reg[0]:res_reg[1]]*1e-6  ## just change all xs to ms and one array\n",
    "\n",
    "ON_vfit = np.zeros((len(ON_bgsub),len(ON_bgsub[0]),res_size), dtype = np.float64) ## channels, sequences, range of V_ subtraction\n",
    "OFF_vfit = np.zeros((len(ON_bgsub),len(ON_bgsub[0]),res_size), dtype = np.float64) ## channels, sequences, range of V_ subtraction\n",
    "ON_vfit_params  = np.zeros((len(ON_bgsub),len(ON_bgsub[0]),2), dtype = np.float64) ## channels, sequences, [amp thing, amp thing err]\n",
    "OFF_vfit_params = np.zeros((len(ON_bgsub),len(ON_bgsub[0]),2), dtype = np.float64)\n",
    "\n",
    "sig_ch = np.zeros((len(ON_vfit),2), dtype=np.float64) ## 1 sigma +/- error for each channel\n",
    "gam_ch = np.zeros((len(ON_vfit),2), dtype=np.float64) ## 1 gamma +/- error for each channel\n",
    "ON_vfit_params_varied  = np.zeros((len(ON_bgsub),len(ON_bgsub[0]),2,3), dtype = np.float64) ## channels, sequences,[params, param_errs], [sigma, gamma, amp thing] NO xSHIFT\n",
    "OFF_vfit_params_varied = np.zeros((len(ON_bgsub),len(ON_bgsub[0]),2,3), dtype = np.float64)\n",
    "\n",
    "for ch in range(0, len(ON_bgsub)):\n",
    "    sig  = v_sigmas[ch] ## the definitions of these changes per channel for func voigt_c\n",
    "    gam  = v_gammas[ch]\n",
    "    xloc = v_reslocs[ch]\n",
    "    if chan_enab[ch] == 24:\n",
    "        emessage = ('bg_ fit does not work for 6Li yet')\n",
    "        logger.error('run '+run_num + emessage)\n",
    "        raise Exception(emessage)\n",
    "    try:\n",
    "        ON_vfit[ch],  ON_vfit_params[ch]  = voigt_fitting_c(res_reg,new_res_reg,xdata, ON_bgsub[ch])\n",
    "        OFF_vfit[ch], OFF_vfit_params[ch] = voigt_fitting_c(res_reg,new_res_reg,xdata, OFF_bgsub[ch])\n",
    "        trash, ON_vfit_params_varied[ch]  = voigt_fitting(res_reg,new_res_reg,xdata, ON_bgsub[ch])  ## these 2 are the original w varying sig,gam\n",
    "        trash, OFF_vfit_params_varied[ch] = voigt_fitting(res_reg,new_res_reg,xdata, OFF_bgsub[ch])\n",
    "    except Exception as e:\n",
    "        logger.error('run '+run_num +' ch '+ str(chan_enab[ch])+' failed during Voigt fitting')\n",
    "        logger.exception(e)\n",
    "\n",
    "end = time.time()\n",
    "print('bg_ fitting time: ' + str(end-start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8471706b-cf37-4144-8405-1b22a1bd0999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3553 3632] [np.int64(653), np.int64(732)]\n",
      "(12, 13, 79)\n",
      "[807424. 807936. 808448. 808960. 809472. 809984. 810496. 811008. 811520.\n",
      " 812032. 812544. 813056. 813568. 814080. 814592.]\n",
      "[0.807424 0.807936 0.808448 0.80896  0.809472 0.809984 0.810496 0.811008\n",
      " 0.81152  0.812032 0.812544 0.813056 0.813568 0.81408  0.814592]\n"
     ]
    }
   ],
   "source": [
    "print(res_reg, new_res_reg)\n",
    "print(ON_vfit.shape)\n",
    "plt.plot(xs_cut[0][res_reg[0]:res_reg[1]],ON_vfit[0][0])\n",
    "print(xs_cut[0][res_reg[0]:res_reg[1]][20:35])\n",
    "print(xdata[20:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "673b483b-961e-4034-bc25-844a1b9baa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum up all pulses, and then calculate asymmetry using \"amplitude\"\n",
    "\n",
    "# ## dont think need this now that there is addpulses program\n",
    "# all_ONOFF = np.zeros((len(ON_sums),2, len(ON_sums[0][0])), dtype=np.float64) ## all summed ON[0] and OFF[1] pulses for each channel, not each sequence\n",
    "\n",
    "# def all_onoff(ON_arr, OFF_arr):\n",
    "#     tempallON = np.zeros((len(ON_arr[0])), dtype=np.float64)\n",
    "#     tempallOFF = np.zeros((len(ON_arr[0])), dtype=np.float64)\n",
    "#     for seq in range(0, len(ON_arr)): ## number of sequences\n",
    "#         tempallON = np.add(ON_arr[seq],tempallON)\n",
    "#         tempallOFF = np.add(OFF_arr[seq],tempallOFF)\n",
    "#     return tempallON, tempallOFF\n",
    "\n",
    "# for i in range(len(ON_sums)):\n",
    "#     all_ONOFF[i][0], all_ONOFF[i][1] = all_onoff(ON_sums[i], OFF_sums[i]) ## channel, ON[0] or OFF[1], summed wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "003cc363-8f58-45c8-87df-be2f70894904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79,)\n",
      "(2100,)\n"
     ]
    }
   ],
   "source": [
    "## old\n",
    "# new asym integrating over a curve and using FWHM of voigt function\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xs_full_res = xs_cut[0][bg_reg1[0]:bg_reg2[1]]*1e-6 ## because this is in ms an not bins, shouldn't matter if it is [bg bin1, bg bin2] or [res bin1, res bin2]\n",
    "fwhm_bins = []\n",
    "for ch in range(0, len(f_v)):\n",
    "    fwhm_bin_left = np.where(xs_full_res>=v_reslocs[ch][0]-f_v[ch]/2)[0][0]\n",
    "    fwhm_bin_right = np.where(xs_full_res>=v_reslocs[ch][0]+f_v[ch]/2)[0][0]\n",
    "    fwhm_bins.append([fwhm_bin_left, fwhm_bin_right])\n",
    "# print(fwhm_bins)\n",
    "print(xdata.shape)\n",
    "print(xs_full_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51a33e3a-5e43-4206-9da6-698cbe55a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[np.int64(678), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(678), np.int64(707)], [np.int64(678), np.int64(707)], [np.int64(679), np.int64(707)], [np.int64(679), np.int64(707)]]\n"
     ]
    }
   ],
   "source": [
    "print(fwhm_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02c7899e-0966-4869-9520-fb73365d84a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 13, 2100)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.plot(ON_sums[0][0])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(ON_bgsub[0][0])\n",
    "plt.show()\n",
    "print(ON_bgsub.shape)\n",
    "plt.figure()\n",
    "plt.plot(xs_full_res,ON_bgsub[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a2094316-b168-4839-8186-d3d96c1c8b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79,)\n",
      "[np.int64(653), np.int64(732)]\n"
     ]
    }
   ],
   "source": [
    "print(xdata.shape)\n",
    "print(new_res_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98ffd8f5-fbae-4567-9934-d1b3b90a396a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[678 707]\n",
      " [679 707]\n",
      " [679 707]\n",
      " [679 707]\n",
      " [679 707]\n",
      " [679 707]\n",
      " [679 707]\n",
      " [679 707]\n",
      " [678 707]\n",
      " [678 707]\n",
      " [679 707]\n",
      " [679 707]]\n",
      "[[25 54]\n",
      " [26 54]\n",
      " [26 54]\n",
      " [26 54]\n",
      " [26 54]\n",
      " [26 54]\n",
      " [26 54]\n",
      " [26 54]\n",
      " [25 54]\n",
      " [25 54]\n",
      " [26 54]\n",
      " [26 54]]\n"
     ]
    }
   ],
   "source": [
    "# new after changing resonance binds\n",
    "# new asym integrating over a curve and using FWHM of voigt function\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xs_full_res = xs_cut[0][bg_reg1[0]:bg_reg2[1]]*1e-6 ## because this is in ms an not bins, shouldn't matter if it is [bg bin1, bg bin2] or [res bin1, res bin2] but output bins will change accordingly\n",
    "testxs_full_res = xs_cut[0][res_reg[0]:res_reg[1]]*1e-6  ## because this is in ms an not bins, shouldn't matter if it is [bg bin1, bg bin2] or [res bin1, res bin2] but output bins will change accordingly\n",
    "# print(xs_full_res)\n",
    "\n",
    "fwhm_bins = []\n",
    "fwhm_binstest = []\n",
    "\n",
    "for ch in range(0, len(f_v)):\n",
    "    fwhm_bin_left = np.where(xs_full_res>=v_reslocs[ch][0]-f_v[ch]/2)[0][0]\n",
    "    fwhm_bin_right = np.where(xs_full_res>=v_reslocs[ch][0]+f_v[ch]/2)[0][0]\n",
    "    fwhm_bins.append([fwhm_bin_left, fwhm_bin_right])\n",
    "    \n",
    "for ch in range(0, len(f_v)): ## testing\n",
    "    fwhm_bin_lefttest = np.where(testxs_full_res>=v_reslocs[ch][0]-f_v[ch]/2)[0][0]\n",
    "    fwhm_bin_righttest = np.where(testxs_full_res>=v_reslocs[ch][0]+f_v[ch]/2)[0][0]\n",
    "    fwhm_binstest.append([fwhm_bin_lefttest, fwhm_bin_righttest])\n",
    "    \n",
    "fwhm_bins = np.asarray(fwhm_bins)\n",
    "fwhm_binstest = np.asarray(fwhm_binstest)\n",
    "\n",
    "print(fwhm_bins)\n",
    "print(fwhm_binstest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af517a6-6670-472c-87a8-f454211db908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc72a0a8-9083-4f73-8522-302a9b654be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n",
      "(12, 2)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.int64'>\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "## comparison of 2 methods, bg res reg or res reg\n",
    "\n",
    "print(fwhm_bins.shape)\n",
    "print(fwhm_binstest.shape)\n",
    "print(type(fwhm_bins), type(fwhm_bins[0]), type(fwhm_bins[0][0]))\n",
    "plt.plot(xs_full_res,ON_bgsub[0][0])\n",
    "plt.plot(testxs_full_res,ON_bgsub[0][0][new_res_reg[0]:new_res_reg[1]])\n",
    "\n",
    "plt.axvline(x = xs_full_res[fwhm_bins[0][0]], ls='--', c='r')\n",
    "plt.axvline(x = xs_full_res[fwhm_bins[0][1]], ls='--', c='r')\n",
    "plt.axvline(x = testxs_full_res[fwhm_binstest[0][0]], ls='-.', c='g')\n",
    "plt.axvline(x = testxs_full_res[fwhm_binstest[0][1]], ls='-.', c='g')\n",
    "\n",
    "print(fwhm_bins[0][1]-fwhm_bins[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "525a8f9e-ff62-456c-a849-4561af73dd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabeo\\AppData\\Local\\Temp\\ipykernel_59592\\3504886444.py:11: RuntimeWarning: invalid value encountered in sqrt\n",
      "  ON_err = 1/np.sqrt(A_plus) ## don't do hard version of error for now 05.02.25\n"
     ]
    }
   ],
   "source": [
    "asym_int = np.zeros((len(ON_vfit)), dtype=np.float64) ## 1 Asym for each channel, and its error\n",
    "def asym_integral(ON_data, OFF_data, integral_bins):  ## currently does not do errors...\n",
    "    tempasym = 0\n",
    "    temperr  = []\n",
    "    fwhm_l = integral_bins[0] # easier to read\n",
    "    fwhm_r = integral_bins[1]\n",
    "    for seq in range(0, len(ON_data)): ## number of sequences\n",
    "        A_plus = np.sum(ON_data[seq][fwhm_l:fwhm_r]) ## just makes things cleaner\n",
    "        A_min  = np.sum(OFF_data[seq][fwhm_l:fwhm_r])\n",
    "        seqasym = ((A_plus-A_min) / (A_plus+A_min))\n",
    "        ON_err = 1/np.sqrt(A_plus) ## don't do hard version of error for now 05.02.25\n",
    "        OFF_err = 1/np.sqrt(A_min)\n",
    "        tempasym = np.add(seqasym,tempasym)\n",
    "    return tempasym  ## don't normalize asymON_vfit_params this time...\n",
    "\n",
    "for i in range(len(ON_vfit)):\n",
    "    asym_int[i] = asym_integral(ON_bgsub[i], OFF_bgsub[i], fwhm_bins[i])  ## because sig,gam,xloc are the same for ON/OFF, using vfit curves gives same asymm as just using amp factor\n",
    "\n",
    "asym_raw = np.zeros((len(ON_sums), len(ON_sums[0][0])), dtype=np.float64) ## 1 Asym for each channel, not for each sequence (can change?)\n",
    "def asymraw(ON_arr, OFF_arr):\n",
    "    tempasym = np.zeros((len(ON_arr[0])), dtype=np.float64)\n",
    "    for seq in range(0, len(ON_arr)): ## number of sequences\n",
    "        seqasym = ((ON_arr[seq]-OFF_arr[seq]) / (ON_arr[seq]+OFF_arr[seq]))\n",
    "#         if ON_arr[seq]+OFF_arr[seq] == 0: ## add an exception for sum being == 0 that causes div by 0    \n",
    "        tempasym = np.add(seqasym,tempasym)\n",
    "    normedasym = tempasym #/len(ON_arr) ## took out norm. Normalize later by # sequences\n",
    "    return normedasym\n",
    "\n",
    "for i in range(len(ON_sums)):\n",
    "    asym_raw[i] = asymraw(ON_sums[i], OFF_sums[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a8deae6-2c6d-4f9a-ac8a-ab74e4fd2a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 8992)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19ad2c96350>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(asym_raw.shape)\n",
    "plt.plot(asym_raw[-2])\n",
    "plt.plot(asym_raw[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b4dc3-88b6-429d-8702-339c40b4e7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da3af5-deae-4adf-8a8e-d31f95e6f6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3dc4a6d-5004-48e1-bb97-bbaeab99fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[25]:\n",
    "\n",
    "## Don't think it's necessary 05.03.24\n",
    "# all_Vfitcurve_ON = np.zeros((len(ON_vfit), len(ON_vfit[0][0])), dtype=np.float64) ## all summed ON or OFF pulses for each channel, not each sequence\n",
    "# all_Vfitcurve_OFF = np.zeros((len(ON_vfit), len(ON_vfit[0][0])), dtype=np.float64) ## all summed ON or OFF pulses for each channel, not each sequence\n",
    "\n",
    "# def all_vfits(vfit_arrs):\n",
    "#     tempall_vfits = np.zeros((len(vfit_arrs[0])), dtype=np.float64)\n",
    "#     for seq in range(0, len(vfit_arrs)): ## number of sequences\n",
    "#         tempall_vfits = np.add(vfit_arrs[seq],tempall_vfits)\n",
    "#     return tempall_vfits\n",
    "\n",
    "# for i in range(len(ON_vfit)):\n",
    "#     all_Vfitcurve_ON[i]  = all_vfits(ON_vfit[i]) ## all added vfits for each channel\n",
    "#     all_Vfitcurve_OFF[i] = all_vfits(OFF_vfit[i]) \n",
    "\n",
    "## add and avg all sigma/gamma/xloc for ON and OFF per channel. Should not be dpendent on spin state. New as of 05.23.25\n",
    "def sum_param(ON_params_arr, OFF_params_arr, key):  ## key choose between sigma gamma NOT xloc\n",
    "    if key != 'sigma' and key != 'gamma':\n",
    "        emessage = ('not a valid Voigt fit parameter to sum')\n",
    "        logger.error('run '+run_num + emessage)\n",
    "        raise Exception(emessage)\n",
    "    if key == 'sigma':\n",
    "        param = 0\n",
    "    if key == 'gamma':\n",
    "        param = 1\n",
    "#     if key == 'xloc':\n",
    "#         param = 2\n",
    "    tempsum = 0\n",
    "    temperr  = []\n",
    "    for seq in range(0, len(ON_params_arr)): ## number of sequences\n",
    "        seqsum = (ON_params_arr[seq][0][param]+OFF_params_arr[seq][0][param])/2  # \"normalize\" with /2 but not for #sequences\n",
    "        ## [0] above corresponds to the real values of the paramters, as opposed to their errors\n",
    "        ON_err = ON_params_arr[seq][1][param]\n",
    "        OFF_err = OFF_params_arr[seq][1][param]\n",
    "        ## above [1] is used which corresponds to the error in \"parameter\"\n",
    "        ON_deriv  =  1  ## left over from asym error to keep error prop consistent\n",
    "        OFF_deriv =  1\n",
    "        ## use err prop to get below\n",
    "        seq_err = np.sqrt((ON_deriv**2)*(ON_err**2)+(OFF_deriv**2)*(OFF_err**2))/2\n",
    "        temperr.append(seq_err) ## collect all errors for each sequence\n",
    "        tempsum = np.add(seqsum,tempsum)\n",
    "    ## add error or each sequence in quad.\n",
    "    toterr = np.sqrt(sum([i**2 for i in temperr]))  ## use list comprehension for sum of squares\n",
    "    out = [tempsum,toterr]\n",
    "    return out\n",
    "\n",
    "for i in range(len(ON_vfit)):\n",
    "    sig_ch[i] = sum_param(ON_vfit_params_varied[i], OFF_vfit_params_varied[i], key='sigma')\n",
    "    gam_ch[i] = sum_param(ON_vfit_params_varied[i], OFF_vfit_params_varied[i], key='gamma') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a52a6ec-0eff-44df-bbf2-1fe4d274ad4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc asyms: 329.1369562149048\n"
     ]
    }
   ],
   "source": [
    "# new asym using \"amplitude\" parameter, with error prop\n",
    "\n",
    "asym_ch_err = np.zeros((len(ON_vfit),2), dtype=np.float64) ## 1 Asym for each channel, and its error\n",
    "asym_ch_err_varied = np.zeros((len(ON_vfit),2), dtype=np.float64) ## 1 Asym for each channel, and its error\n",
    "\n",
    "def asym3_err2(ON_params_arr, OFF_params_arr):\n",
    "    tempasym = 0\n",
    "    temperr  = []\n",
    "    for seq in range(0, len(ON_params_arr)): ## number of sequences\n",
    "        A_plus = ON_params_arr[seq][0] ## just makes things cleaner\n",
    "        A_min  = OFF_params_arr[seq][0]\n",
    "        ## [0] corresponds to the real values of the paramters, as opposed to their errors.\n",
    "        seqasym = ((A_plus-A_min) / (A_plus+A_min))\n",
    "        ON_err = ON_params_arr[seq][1]\n",
    "        OFF_err = OFF_params_arr[seq][1]\n",
    "        ## above [1] is used which corresponds to the error in \"amplitude\"\n",
    "        ON_deriv  =  2*A_min/ ((A_plus+A_min)**2)\n",
    "        OFF_deriv = -2*A_plus/((A_plus+A_min)**2)\n",
    "        ## use err prop to get below\n",
    "        seq_err = np.sqrt((ON_deriv**2)*(ON_err**2)+(OFF_deriv**2)*(OFF_err**2))\n",
    "#         seq_err = (1/(A_plus+A_min**2))*np.sqrt(4*(A_min**2)(ON_err)**2+4*(A_plus**2)(OFF_err)**2) ## alternate form\n",
    "        temperr.append(seq_err) ## collect all errors for each sequence\n",
    "        tempasym = np.add(seqasym,tempasym)\n",
    "#         print(temperr)\n",
    "    ## add error or each sequence asym in quad.\n",
    "    toterr = np.sqrt(sum([i**2 for i in temperr]))  ## use list comprehension for sum of squares\n",
    "    out = [tempasym,toterr]\n",
    "    return out  ## don't normalize asymON_vfit_params this time...\n",
    "\n",
    "for i in range(len(ON_vfit)):\n",
    "    asym_ch_err[i] = asym3_err2(ON_vfit_params[i], OFF_vfit_params[i]) ## error is really high...\n",
    "    asym_ch_err_varied[i] = asym3_err2(ON_vfit_params_varied[i,:,:,2], OFF_vfit_params_varied[i,:,:,2]) ## 2 here is amplitude [ch, all sequences, parameter & error, amplitude]\n",
    "\n",
    "    \n",
    "end = time.time()\n",
    "print('calc asyms: ' + str(end-start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4bf887b3-c2dc-4907-9280-06b4a9084145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n"
     ]
    }
   ],
   "source": [
    "print(asym_ch_err.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852ce39-9762-45b5-b399-56c3087ff767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "73d7833f-77ae-4d5a-bb41-b934b2f5bab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "puck_thresh = 2500\n",
    "\n",
    "if np.mean(He_Norm_arr[2])==0: ## catches runs with no ch. 29. 0/1 for True/False key\n",
    "    puck_in = -1  ## to differentiate from the other 2 true/false states, because these don't have any information, but the puck could have been in\n",
    "    puck_in_pulses = ['No ch.29 or no puck information'] ## need to keep track of what runs don't have a ch.29. Puck was in, but with no ch29 to tell.\n",
    "else:\n",
    "    puck_in_pulses = np.where(He_Norm_arr[2]>=puck_thresh)[0] ## empty array for runs w/out puck\n",
    "    if len(puck_in_pulses) == 0: ## puck_in state is false for empty array\n",
    "        puck_in = 0\n",
    "    else:\n",
    "        puck_in = 1 ## if any pulse crosses threshold. Could be that the very last or first pulse has the puck in...\n",
    "print(puck_in)\n",
    "# print((puck_in_pulses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8124dfc-c8d7-4b9d-920a-d446ff8d727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2043.9054\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(puck_thresh)\n",
    "print(np.mean(He_Norm_arr[2]))\n",
    "print(np.where(He_Norm_arr[2]>=puck_thresh)[0])\n",
    "print(len(np.where(He_Norm_arr[2]>=puck_thresh)[0]))\n",
    "# print(np.where(He_Norm_arr[2]>=puck_thresh).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6031eb7-efec-4d59-9393-055f222206e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8dd5e-4195-4006-9c82-ea568fb64ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34386e1-2a76-4d32-85ab-dc3ba05f6c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f2568-8975-4089-9d24-fad75c7922e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b11d26-e342-4bab-b9c4-b57fcecfde93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24491deb-a59a-42df-a5fe-9fd1f19d17a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce70f6-5766-44bd-9b61-a21105343cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ff80e-fee9-41b8-9d80-de3cdd5d45f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5e6049f-7833-4682-90c5-9d54262cf87b",
   "metadata": {},
   "source": [
    "## Below for real running!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448f0c4-3d94-4381-b419-23dc0d98083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## new version adds vfit curves\n",
    "# save all on and off values and asymm + paramters. save out.\n",
    "# start = time.time()\n",
    "\n",
    "# with h5py.File(ONOFFSavename+'.h5', 'w') as hdf5_file:\n",
    "#     hdf5_file.create_dataset('xs ', data=xs_cut[0]) ## all xs are the same, even though they are per channel...\n",
    "#     hdf5_file.attrs['puck_state'] = puck_in ## adding the puck information\n",
    "#     hdf5_file.attrs['puck_pulses'] = puck_in_pulses ## will be empty if puck is not in (usually)\n",
    "#     hdf5_file.attrs['num_pulses'] = numRuns ## some runs do not have 5000 pulses! Usually the ones at the end\n",
    "#     hdf5_file.attrs['sequences'] = len(sequence[0])\n",
    "#     for i in range(0,len(ys_cut)):\n",
    "#         Ch_grp = hdf5_file.create_group('ch_'+str(np.char.zfill(str(chan_enab[i]), 2)))\n",
    "#         added_pulses_subgrp = Ch_grp.create_group('added_pulses')\n",
    "#         added_vfits_subgrp = Ch_grp.create_group('added_vfits')\n",
    "#         added_pulses_subgrp.attrs['rownames'] = ['ON_Row0', 'OFF_Row1']\n",
    "#         added_pulses_subgrp.create_dataset('ch_'+str(np.char.zfill(str(chan_enab[i]), 2)), data=all_ONOFF[i])\n",
    "#         if chan_enab[i] == 24:\n",
    "#             pass\n",
    "#         else:\n",
    "#             added_vfits_subgrp.attrs['resonance_region'] = res_reg\n",
    "#             added_vfits_subgrp.attrs['note'] = 'added all Voigt fits for each ON or OFF state, per ch.'\n",
    "#             added_vfits_subgrp.create_dataset('Vfit_curve_ON',data=all_Vfitcurve_ON[i])\n",
    "#             added_vfits_subgrp.create_dataset('Vfit_curve_OFF',data=all_Vfitcurve_OFF[i])\n",
    "        \n",
    "# end = time.time()\n",
    "# print('saving hdf5: ' + str(end-start))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00464395-d28e-4323-94fe-3e45378410a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2)\n"
     ]
    }
   ],
   "source": [
    "print(asym_ch_err.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d289f958-3a87-4752-86f3-b1d1c8865c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full processing time: 1026.950406551361\n",
      "finished 2025-08-27 12:15:48.587627\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# AsymSavename_raw = AsymSavename  ## maybe can get rid of this\n",
    "with h5py.File(AsymSavename+'.h5', 'w') as hdf5_file:\n",
    "    hdf5_file.create_dataset('xs ', data=xs_cut[0]) ## all xs are the same, even though they are per channel...\n",
    "    hdf5_file.attrs['puck_state'] = puck_in ## adding the puck information\n",
    "    hdf5_file.attrs['puck_pulses'] = puck_in_pulses ## will be empty if puck is not in (usually)\n",
    "    hdf5_file.attrs['num_pulses'] = numRuns ## some runs do not have 5000 pulses! Usually the ones at the end\n",
    "    hdf5_file.attrs['sequences'] = len(sequence[0])\n",
    "    for i in range(0,len(asym_ch_err)): \n",
    "        Ch_grp = hdf5_file.create_group('ch_'+str(np.char.zfill(str(chan_enab[i]), 2)))\n",
    "        Ch_grp.attrs['asym_amp'] = asym_ch_err[i]\n",
    "        Ch_grp.attrs['asym_amp_varied'] = asym_ch_err_varied[i]\n",
    "        Ch_grp.attrs['used_xloc']  = v_reslocs[i]\n",
    "        Ch_grp.attrs['used_sigma'] = v_sigmas[i]\n",
    "        Ch_grp.attrs['used_gamma'] = v_gammas[i]\n",
    "        Ch_grp.attrs['FWHM_bins'] = fwhm_bins[i]\n",
    "        Ch_grp.create_dataset('asym_raw', data=asym_raw[i]) ## 04.28.25 reintroduced raw asym for plotting etc \n",
    "        ON_subgrp = Ch_grp.create_group('ON')\n",
    "        OFF_subgrp = Ch_grp.create_group('OFF')\n",
    "        ON_subgrp.attrs['for_each_sequence'] = ['parameter (\"amplitude\")', 'and its error']\n",
    "        OFF_subgrp.attrs['for_each_sequence'] = ['parameter (\"amplitude\")', 'and its error']\n",
    "        ON_subgrp.create_dataset('parameters',data=ON_vfit_params[i])\n",
    "        OFF_subgrp.create_dataset('parameters',data=OFF_vfit_params[i])\n",
    "        ON_subgrp.create_dataset('Vfit_curves',data=ON_vfit[i])\n",
    "        OFF_subgrp.create_dataset('Vfit_curves',data=OFF_vfit[i])\n",
    "    Ch_grp = hdf5_file.create_group('ch_'+str(np.char.zfill(str(chan_enab[-1]), 2))) ## this is for 6Li data\n",
    "    Ch_grp.create_dataset('asym_raw', data=asym_raw[-1]) \n",
    "\n",
    "end = time.time()\n",
    "# print('saving hdf5: ' + str(end-start))     \n",
    "\n",
    "# In[31]:\n",
    "\n",
    "fullend = time.time()\n",
    "print('full processing time: ' + str(fullend-fullstart))  \n",
    "print('finished ' + str(datetime.now())) \n",
    "print('\\n')\n",
    "\n",
    "# ## end of data processing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440dbb66-9da0-4d8e-aa54-7854cfd43921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
