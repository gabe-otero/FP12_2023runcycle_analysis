{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data: debug_sample/runs12034-12363//run12036\n",
      "saving processed data to F:\\LANL/processed_data/debug_sample/runs12034-12363/asym_D/12036_asym_D\n",
      "Channel is [ 0  1  2  3  4  5  6  7  8  9 10 11 24]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import uproot\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import os\n",
    "from numba import njit\n",
    "import time\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "import h5py\n",
    "import gzip\n",
    "from scipy import odr\n",
    "\n",
    "# warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "# warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "# warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# for arg in sys.argv:\n",
    "#     run_num=str(arg).zfill(5)\n",
    "#     # print(run_num)\n",
    "\n",
    "# chan_enab = int(sys.argv[-1])\n",
    "# run_start=str(sys.argv[1]).zfill(5)\n",
    "# run_end=str(sys.argv[2]).zfill(5)\n",
    "# run_num=str(sys.argv[3]).zfill(5)\n",
    "\n",
    "run_num = '12036'\n",
    "os.chdir('F:/LANL/')\n",
    "datadir = 'sample_data/'\n",
    "runs_folder = 'runs12034-12363/'\n",
    "uniquefolder = 'debug_sample/'+runs_folder\n",
    "# uniquefolder = 'La_sample/'\n",
    "# SFNormFile = 'SF_Norm_files/'+uniquefolder+run_num\n",
    "SFNormFile = 'SF_Norm_files/'+runs_folder+run_num\n",
    "# AsymSavename = '****testing testing testing'\n",
    "\n",
    "# print(os.getcwd())\n",
    "\n",
    "# os.chdir('F:/LANL/')\n",
    "# datadir = 'D:/LANSCE_FP12_2023/data/' ## add directory of hard drive\n",
    "# uniquefolder = \"runs\" + str(run_start) + \"-\" + str(run_end) +\"/\"\n",
    "# SFNormFile = 'SF_Norm_files/'+uniquefolder+run_num\n",
    "\n",
    "statefileloc = 'F:\\LANL\\SF_Norm_files\\TR_R_expected_avgs_stds_afterclip.csv'\n",
    "processedONOFFfolder = '/processed_data/'+uniquefolder+'ONOFF_D/'\n",
    "processedasymfolder = '/processed_data/'+uniquefolder+'asym_D/'\n",
    "processedasymfolder_bg = '/processed_data/'+uniquefolder+'asym_bg_D/'\n",
    "ONOFFSavename = os.getcwd()+processedONOFFfolder+run_num+'_ONOFF_D'\n",
    "AsymSavename = os.getcwd()+processedasymfolder+run_num+'_asym_D'\n",
    "AsymSavename_bg = os.getcwd()+processedasymfolder_bg+run_num+'_asym_bg_D'\n",
    "# logger.add(\"F:/LANL/processed_data/\" + uniquefolder + '0_ErrorLog_'+run_start+'_'+run_end+'_D.txt', delay = False)\n",
    "\n",
    "# cannot handle all 24 detectors at once, memory issue... can look into np.empty and deleting variables if needed ##\n",
    "# chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]) ## all\n",
    "chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,24]) ## downstream\n",
    "# chan_enab = np.array([12,13,14,15,16,17,18,19,20,21,22,23,24]) ## upstream\n",
    "\n",
    "print('processing data: ' + uniquefolder + '/run' + run_num)\n",
    "\n",
    "# print(os.getcwd()+processedpulsefolder)\n",
    "# if not os.path.exists(os.getcwd()+processedONOFFfolder) or not os.path.exists(os.getcwd()+processedasymfolder) or not os.path.exists(os.getcwd()+processedasymfolder_bg):\n",
    "#     # Create the directory\n",
    "#     os.makedirs(os.getcwd()+processedONOFFfolder)\n",
    "#     os.makedirs(os.getcwd()+processedasymfolder)\n",
    "#     os.makedirs(os.getcwd()+processedasym_bgfolder)\n",
    "#     print(\"Directory created successfully\")\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# print(os.getcwd() + folder)\n",
    "\n",
    "# get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "start = time.time()\n",
    "fullstart = time.time()\n",
    "\n",
    "read_data = []\n",
    "fileLength = []\n",
    "\n",
    "def open_file():\n",
    "    for el in chan_enab:\n",
    "        # f = open(datadir + folder + 'run' + run_num + \"_ch\" + str(el) + \".bin\", 'rb')\n",
    "        f = open(datadir+uniquefolder + 'run' + str(run_num) + \"_ch\" +str(el) + \".bin\", 'rb')\n",
    "        read_data.append(np.fromfile(file=f, dtype=np.uint16))\n",
    "        f.close()\n",
    "        fileLength.append(len(read_data[-1]))\n",
    "    return read_data, fileLength\n",
    "\n",
    "open_file()\n",
    "\n",
    "fileLength = np.asarray(fileLength)\n",
    "read_data = np.asarray(read_data) ## in detector's case, all are the same size samples, so can do read_data as np array\n",
    "\n",
    "if chan_enab[-1] != 24:\n",
    "    emessage = ('last channel is not 6Li detector')\n",
    "    logger.error(run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "# print('file open time: ' + str(end-start))            \n",
    "print('saving processed data to ' + AsymSavename)\n",
    "print(\"Channel is \" + str(chan_enab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is La\n"
     ]
    }
   ],
   "source": [
    "# Store the big header for each channel in arrays\n",
    "\n",
    "BoardID = []\n",
    "recordLength = []\n",
    "numSamples = []\n",
    "eventCounter = []\n",
    "decFactor = []\n",
    "chanDec = []\n",
    "postTrig = []\n",
    "groupStart = []\n",
    "groupEnd = []\n",
    "timestamp= []\n",
    "sizeFirstEvent = []\n",
    "TTT = []\n",
    "\n",
    "targetDict = {0: \"La\", 1: \"Tb2O3\", 2: \"Yb2O3\", 3: \"Sm2O3\", 4: \"Er2O3\", 5: \"Ho2O3\", 6: \"other\"}\n",
    "foilDict = {0: \"TBD\", 1: \"TBD\", 2: \"TBD\", 3: \"TBD\", 4: \"TBD\", 5: \"TBD\", 6: \"other\"}\n",
    "\n",
    "target=(read_data[0][5]&0x00F0)>>4\n",
    "foil=read_data[0][5]&0x000F\n",
    "targetFlag = read_data[0][5]>>8&1\n",
    "foilFlag = read_data[0][5]>>9&1\n",
    "spinFiltFlag = read_data[0][5]>>10&1\n",
    "spinFlipFlag = read_data[0][5]>>11&1\n",
    "shutterFlag = read_data[0][5]>>12&1\n",
    "facilityTrigFlag = read_data[0][5]>>13&1\n",
    "\n",
    "if targetFlag:\n",
    "    target=targetDict[(read_data[0][5]&0x00F0)>>4]\n",
    "else:\n",
    "    target = \"empty\"\n",
    "if foilFlag:\n",
    "    foil=foilDict[read_data[0][5]&0x000F]\n",
    "else:\n",
    "    foil = \"empty\"\n",
    "for i in range(0,len(chan_enab)):\n",
    "    BoardID.append(read_data[i][9]>>8)\n",
    "    recordLength.append(((read_data[i][9]&0x00FF)<<16)+read_data[i][8])\n",
    "    numSamples.append(((read_data[i][11]&0x00FF)<<16)+read_data[i][10])\n",
    "    eventCounter.append(read_data[i][6]+(read_data[i][7]<<16))\n",
    "    BoardID.append(read_data[i][9]>>8)  \n",
    "    decFactor.append(read_data[i][11]>>8)\n",
    "    chanDec.append(read_data[i][13]>>8)\n",
    "    postTrig.append(read_data[i][15]>>8)\n",
    "    groupStart.append(((read_data[i][13]&0x00FF)<<16)+read_data[i][12])\n",
    "    groupEnd.append(((read_data[i][15]&0x00FF)<<16)+read_data[i][14])\n",
    "    \n",
    "    timestamp.append(read_data[i][16]+(read_data[i][17]<<16)+(read_data[i][18]<<32)+(read_data[i][19]<<40))  \n",
    "    sizeFirstEvent.append(read_data[i][0]+(read_data[i][1]<<16))\n",
    "    TTT.append(read_data[i][2]+(read_data[i][3]<<16)+(read_data[i][4]<<32))\n",
    "    \n",
    "#     print(\"For channel \" + str(chan_enab[i]) + \", BoardID is \" + str(BoardID[i])\n",
    "#           + \"; record length is \" + str(recordLength[i]) + \"; num Samples is \" \n",
    "#           + str(numSamples[i]) + \"; event counter is \" + str(eventCounter[i]) + \"; dec factor is \" + str(decFactor[i]) + \"; chan dec is \" \n",
    "#           + str(chanDec[i]) + \"; postTrig is \" + str(postTrig[i]) + \"; group start is \" + str(groupStart[i]) + \"; group end is \" + str(groupEnd[i])\n",
    "#           + \"; epoch time is \" + str(timestamp[i]) +  \"; first event size is \" + str(sizeFirstEvent[i]) + \"; and ETTT is \" + str(TTT[i]) + \"\\n\")\n",
    "\n",
    "BoardID = np.asarray(BoardID) \n",
    "recordLength = np.asarray(recordLength)\n",
    "numSamples = np.asarray(numSamples)\n",
    "eventCounter = np.asarray(eventCounter)\n",
    "decFactor = np.asarray(decFactor)\n",
    "chanDec = np.asarray(chanDec)\n",
    "postTrig = np.asarray(postTrig)\n",
    "groupStart = np.asarray(groupStart)\n",
    "groupEnd = np.asarray(groupEnd)\n",
    "timestamp = np.asarray(timestamp)\n",
    "sizeFirstEvent = np.asarray(sizeFirstEvent)\n",
    "TTT = np.asarray(TTT)\n",
    "\n",
    "print(\"Target is \" + target)\n",
    "# print(\"Foil is \" + foil)\n",
    "# print(\"Shutter is open: \" + str(bool(shutterFlag)))\n",
    "# print(\"Facility t0 is on: \" + str(bool(facilityTrigFlag)))\n",
    "# print(\"Spin flipper is on: \" + str(bool(spinFlipFlag)))\n",
    "# print(\"Spin filter is on: \" + str(bool(spinFiltFlag)))\n",
    "# print(\"Target is present: \" + str(bool(targetFlag)))\n",
    "# print(\"Foil is present: \" + str(bool(foilFlag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the time axis for each channel\n",
    "\n",
    "preTime = []\n",
    "startTime = []\n",
    "endTime = []\n",
    "resolution = []\n",
    "xs = [] \n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    preTime.append((100-postTrig[i])*recordLength[i]/100)\n",
    "    startTime.append((-1*preTime[i]*16*decFactor[i] + groupStart[i]*16*decFactor[i]))\n",
    "    endTime.append((-1*preTime[i]*16*decFactor[i] + groupEnd[i]*16*decFactor[i]))\n",
    "    resolution.append(16*chanDec[i]*decFactor[i])\n",
    "#     print(\"Pretime for channel\", chan_enab[i],\"is \" + str(preTime[i]) + \"; start time is \" + str(startTime[i]) + \"; end time is \" + str(endTime[i]) \n",
    "#           + \"; resolution is \" + str(resolution[i]) + \"ns\")\n",
    "    xs.append(np.arange(startTime[i],(numSamples[i])*resolution[i]+startTime[i], resolution[i]))\n",
    "\n",
    "np.asarray(preTime)\n",
    "np.asarray(startTime)\n",
    "np.asarray(endTime)\n",
    "np.asarray(resolution)\n",
    "\n",
    "xs = np.asarray(xs) ## can convert xs to np array here because all detectors same numsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabeo\\anaconda3\\lib\\site-packages\\numba\\core\\ir_utils.py:2152: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'channels' of function 'dataread'.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"C:\\Users\\gabeo\\AppData\\Local\\Temp\\ipykernel_5256\\2559654803.py\", line 4:\u001b[0m\n",
      "\u001b[1m@njit\n",
      "\u001b[1mdef dataread(data, channels, fileLen, numSamps):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataread from binary time: 1.9428257942199707\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "@njit\n",
    "def dataread(data, channels, fileLen, numSamps):\n",
    "    numRuns = int((fileLen[0]-20-numSamps[0])/(numSamps[0]+6)+1)\n",
    "    ys_arr = np.zeros((len(channels), numRuns,numSamps[0]), dtype=np.uint16)\n",
    "    ETTT_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    eventcount_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    for i in range(0,len(channels)):\n",
    "        eventCount = 0\n",
    "        byteCounter = 0\n",
    "            #byte counter is really 2bytecounter, lol\n",
    "        while byteCounter < fileLen[i]:\n",
    "            if byteCounter == 0:\n",
    "                ETTT_arr[i]=TTT[i]\n",
    "                #ETTT_arr[i].append(TTT[i])\n",
    "                eventcount_arr[i]=(eventCounter[i])\n",
    "                byteCounter = 20\n",
    "            else:\n",
    "                ETTT_arr[i]=(data[i][byteCounter]+(data[i][byteCounter+1]<<16)+(data[i][byteCounter+2]<<32))\n",
    "                eventcount_arr[i]=(data[i][byteCounter+4]+(data[i][byteCounter+5]<<16))\n",
    "                byteCounter += 6\n",
    "            for j in range(0, numSamps[i]):\n",
    "                #if j == 0:\n",
    "                    #ys_arr[i].append([])\n",
    "                #print(byteCounter)\n",
    "                ys_arr[i][eventCount][j]=data[i][byteCounter]\n",
    "                byteCounter += 1\n",
    "            eventCount += 1\n",
    "    return ys_arr, ETTT_arr, eventcount_arr\n",
    "\n",
    "start=time.time()\n",
    "ys_arrHe, ETTT_arrHe, eventcount_arrHe  = dataread(read_data, [25], fileLength, numSamples) ##hardcoded channel 25 for He\n",
    "ys_arr, ETTT_arr, eventcount_arr  = dataread(read_data, chan_enab, fileLength, numSamples) ##hardcoded channels for coils\n",
    "\n",
    "end = time.time()\n",
    "print('dataread from binary time: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeDif=[]\n",
    "for i in range(0,len(chan_enab)):\n",
    "    timeDif.append([])\n",
    "    for j in range(len(ETTT_arr[i])-1):\n",
    "        timeDif[i].append((ETTT_arr[i][j+1]-ETTT_arr[i][j])*8)\n",
    "#     print(\"Min time difference for channel\", chan_enab[i], \"is\", min(timeDif[i]), \"ns\")\n",
    "#     print(\"Max time difference for channel\", chan_enab[i], \"is\", max(timeDif[i]), \"ns \\n\")\n",
    "#print(timeDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in SF and He normalization information ##\n",
    "# SFNormFile2 = 'F:/LANL/SF_Norm_files/runs12034-12363/12036.h5' ## change sf norm file here or use default\n",
    "\n",
    "try:\n",
    "    df_SF = pd.read_hdf(SFNormFile + '.h5', key='df_0')\n",
    "#     df_SF = pd.read_hdf(SFNormFile2, key='df_0')\n",
    "    df_HE = pd.read_hdf(SFNormFile + '.h5', key='df_1')\n",
    "#     df_HE = pd.read_hdf(SFNormFile2, key='df_1')\n",
    "except Exception as e:\n",
    "    logger.error(run_num + ' failed during SFNormFile load')\n",
    "    logger.exception(e)\n",
    "\n",
    "SF_Sort_arr = df_SF[['nicknames', 'transition_locations']].to_numpy().T\n",
    "He_Norm_arr = df_HE[['pulse', 'norms']].to_numpy().T\n",
    "\n",
    "NormFactor = 1000000  ## He integrals are huge, this normalizes all of those by a constant value for ease of use\n",
    "HeNorms= (He_Norm_arr[1])/NormFactor\n",
    "\n",
    "# print(SF_Sort_arr)\n",
    "# print(He_Norm_arr[1]/NormFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting and/or base subtraction time: 3.5280280113220215\n"
     ]
    }
   ],
   "source": [
    "# basesub and plotting ##\n",
    "start = time.time()\n",
    "\n",
    "baseL = 0\n",
    "baseR = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])  ##70% before the trigger\n",
    "numRuns = int((fileLength[0]-20-numSamples[0])/(numSamples[0]+6)+1)\n",
    "legend =  ['NaI', 'R']\n",
    "\n",
    "s = 20 ## pulse to look at\n",
    "t=s+1\n",
    "\n",
    "#  dont know why this is so slow ##\n",
    "def plotter(ys, xs, baseR, numpoints):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "    for i in range((len(ys))):\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "        for j in range(s, t): ## plot only interested pulses\n",
    "            plt.plot(xs[i], tempys_basesub[i][j]) #label=legend[i]) #+str(sums[1][j])) ## sums[j] will not work for more than just TR   \n",
    "            plt.axvline(xs[0][baseL], ls = '--')\n",
    "            plt.axvline(xs[0][baseR], ls = '--')\n",
    "            #plt.axvline(xs[0][int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])], ls = '--', c ='m')\n",
    "            plt.axvline(xs[0][baseR+5], ls = '--', c ='r') ## BaseR+5 line marks the beginning of the integral, until the end of samples.\n",
    "#             plt.title('SF state transition' + transitions[p]) \n",
    "#             plt.xlabel(\"time from trigger (ns)\")\n",
    "#             plt.ylabel(\"ADC\")\n",
    "            plt.legend()\n",
    "            \n",
    "# plotter(ys_arr[9:], xs[9:], baseR, numSamples) ##plot coils\n",
    "\n",
    "@njit ## jit is faster for large # channels, slower for small # channels\n",
    "def basesub(ys, baseRight, numpoints): \n",
    "    tempys_basesub = np.zeros((numRuns,numpoints[0]), dtype=np.float64)\n",
    "    for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "        tempys_basesub[pulse]=np.subtract(ys[pulse], np.mean(ys[pulse][baseL:baseRight]))\n",
    "    return tempys_basesub\n",
    "\n",
    "@njit ## jit is faster for large # channels, slower for small # channels\n",
    "def basesub_norm(ys, baseRight, numpoints): \n",
    "    tempys_basesub = np.zeros((numRuns,numpoints[0]), dtype=np.float64)\n",
    "    for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "        tempys_basesub[pulse]=np.subtract(ys[pulse], np.mean(ys[pulse][baseL:baseRight]))\n",
    "        tempys_basesub[pulse]=tempys_basesub[pulse]/HeNorms[pulse] \n",
    "    return tempys_basesub\n",
    "\n",
    "ys_basesub = np.zeros((len(ys_arr), numRuns,numSamples[0]), dtype=np.float64)\n",
    "# ys_basesub_norm = np.zeros((len(ys_arr), numRuns,numSamples[0]), dtype=np.float64)\n",
    "\n",
    "for i in range(len(ys_basesub)): ## feeding y arrays into function 1 channel at  a time is faster than all at once\n",
    "    ys_basesub[i] = basesub(ys_arr[i], baseR, numSamples)\n",
    "# for i in range(len(ys_basesub)): ## feeding y arrays into function 1 channel at  a time is faster than all at once\n",
    "#     ys_basesub[i] = basesub_norm(ys_arr[i], baseR, numSamples)\n",
    "\n",
    "ys_basesub[-1] = ys_basesub[-1]*-1 ## invert 6Li to positive signal. Comment out if not using\n",
    "# ys_basesub_norm[-1] = ys_basesub_norm[-1]*-1 ## invert 6Li to positive signal. Comment out if not using\n",
    "\n",
    "end = time.time()\n",
    "print('plotting and/or base subtraction time: ' + str(end-start))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding offset time: 0.726618766784668\n"
     ]
    }
   ],
   "source": [
    "# use 6Li t0 for all instead of for themselves individually ##\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "NaIthresh=2000\n",
    "Li6thresh=1000\n",
    "threshold_array = (np.full(len(ys_basesub), NaIthresh))\n",
    "threshold_array[-1] = Li6thresh\n",
    "\n",
    "# njit ## numba does not support reversed, but this could be changed if it's slow\n",
    "def find_offset(ys, thresharr):\n",
    "    xCrosses = np.zeros((len(ys), numRuns)) #outer array is crossing arrays for given channel, inner array is crossing for each event\n",
    "    offset = np.zeros((len(ys), numRuns), dtype=np.int32) ##offset in bins for each channel, each pulse\n",
    "    modeCrosses = np.zeros((len(ys)), dtype=np.float64)\n",
    "    for i in reversed(range(len(ys))):\n",
    "        #xValues.append([])\n",
    "        for p in range(len(ys[i])):\n",
    "            xing = np.argmax(ys[i][p] > thresharr[i])\n",
    "            #print(xing)\n",
    "            xCrosses[i][p] = xing\n",
    "        modeCrosses[i] = (st.mode(xCrosses[i])) #find the most typical crossing value for each channel\n",
    "        for p in range(len(xCrosses[i])):\n",
    "            offset[i][p] = (modeCrosses[-1] - xCrosses[i][p]) ## make sure this is the correct sign!!! \n",
    "    if (np.all(xCrosses[-1])) == False:\n",
    "        emessage = ('ERROR: 6Li threshold was not reached for at least one pulse')\n",
    "        logger.error(run_num + emessage)\n",
    "        raise Exception(emessage)\n",
    "    return offset, xCrosses, modeCrosses\n",
    "                           \n",
    "offset, xCrosses, modeCrosses = find_offset(ys_basesub, threshold_array)\n",
    "\n",
    "end = time.time()\n",
    "print('finding offset time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning and cutting time: 22.406511068344116\n"
     ]
    }
   ],
   "source": [
    "# extend all arrays by a value, check that the max number of offset on 6Li is less than that value ##\n",
    "start = time.time()\n",
    "\n",
    "extendedRange = 3 ## must be a positive value which to extend ys_arr\n",
    "if abs(max(offset[-1], key = abs)) > extendedRange: ## if the max offset of 6Li is >extendedRange, something is wrong\n",
    "    emessage = ('ERROR: largest offset greater than extended range')\n",
    "    logger.error(run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "\n",
    "try:\n",
    "    ys_ext = np.zeros((len(ys_basesub), len(ys_basesub[0]), len(ys_basesub[0][0])+extendedRange*2), dtype=np.float64)\n",
    "    ys_cut = np.zeros((len(ys_basesub), len(ys_basesub[0]), (len(ys_ext[0][0])-((extendedRange*2)+1)*2)))\n",
    "    xs_cut = np.zeros((len(ys_cut), len(ys_cut[0][0])))\n",
    "except Exception as e:\n",
    "    logger.error(run_num + ' failed during ys_cut array creation')\n",
    "    logger.exception(e)\n",
    "\n",
    "# cant use jit because np.pad is not supported ##\n",
    "def align_cut(ys, xs_arr, extendedr):\n",
    "    tempys_ext = np.zeros((len(ys), len(ys[0])+extendedr*2), dtype=np.float64)\n",
    "    tempys_cut = np.zeros((len(ys), (len(tempys_ext[0])-((extendedr*2)+1)*2)))\n",
    "    tempxs_cut = np.zeros(len(tempys_cut[0]))\n",
    "    for p in range(len(ys)):\n",
    "        tempys_ext[p] = np.pad(ys[p], extendedr, 'constant', constant_values=(0))\n",
    "        tempys_ext[p] = np.roll(tempys_ext[p],offset[-1][p]) ## assumes 6Li at -1 position\n",
    "        tempys_cut[p] = tempys_ext[p][((extendedr*2)+1):-((extendedr*2)+1)].copy() ## cut by 7 (if extRange == 3)\n",
    "        tempys_cut[p] = tempys_cut[p]/HeNorms[p] ## normalize by 3He integral  ## comment out if using basesub_norm\n",
    "    x_cut_amt = int((len(ys[0]) - len(tempys_cut[0]))/2)\n",
    "    tempxs_cut = xs_arr[x_cut_amt:-x_cut_amt].copy()\n",
    "    return tempys_cut, tempxs_cut\n",
    "\n",
    "# looping every channel through function is 5x faster ##\n",
    "try:\n",
    "    for i in range(len(ys_basesub)):\n",
    "        ys_cut[i], xs_cut[i] = align_cut(ys_basesub[i], xs[i], extendedRange)\n",
    "except Exception as e:\n",
    "    logger.error(run_num + ' failed aligning and cutting')\n",
    "    logger.exception(e)\n",
    "    \n",
    "# checkp = 2053\n",
    "# print(offset[-1][checkp]) ## checking offset for one example checkpulse\n",
    "# print('original index for checkpulse: '+str(np.argmax(ys_basesub[0][checkp]> 2000))) ## we can follow the index as it changes with extension/cut\n",
    "# #print('extended range index for checkpulse: '+str(np.argmax(ys_ext[0][checkp]> 2000)))\n",
    "# print('cut array index for checkpulse: '+str(np.argmax((ys_cut[0][checkp]*HeNorms[checkp])> 2000)))\n",
    "\n",
    "del ys_ext ## might help with memory issues\n",
    "del ys_basesub\n",
    "\n",
    "end = time.time()\n",
    "print('aligning and cutting time: ' + str(end-start))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## begin SF organization ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 sequences with sequence order: [6, 7, 0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "def organize_SF(SFsort_info): ## sometimes pulse 0 has the state switch. In that case, need to account by if clauses below\n",
    "    counter = 0\n",
    "    seq = 0\n",
    "    seq_arr = ([[],[],[]])\n",
    "    smallerseq = []\n",
    "    smallerstateis = []\n",
    "    for i in range(len(SFsort_info[1])-(np.mod((len(SFsort_info[1])), 8))):  ##111 mod 8 = 7, so essentially 111-7 = 104\n",
    "        counter = counter+1\n",
    "        if counter < 8:\n",
    "            if (SF_Sort_arr[1][i]) == 0: ## catches state switches at pulse 0\n",
    "                smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "                smallerseq.append(SFsort_info[0][i+1])\n",
    "                seq = seq+1\n",
    "                continue\n",
    "            smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "            smallerseq.append(SFsort_info[0][i+1])\n",
    "        elif counter == 8:\n",
    "            if ((SF_Sort_arr[1][i])+45) >= 5000: ## breaks for state switches at pulse 0\n",
    "                print(((SF_Sort_arr[1][i])+5))\n",
    "                seq = seq+1\n",
    "                seq_arr[0].append(seq)\n",
    "                seq_arr[1].append(smallerseq)   \n",
    "                seq_arr[2].append(smallerstateis)\n",
    "                seq_arr[0] = [x-1 for x in seq_arr[0]] ## reset so sequences are 1-14 instead of 2-15\n",
    "                break\n",
    "            seq = seq+1 ## otherwise continue regular sorting\n",
    "            smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "            smallerseq.append(SFsort_info[0][i+1])\n",
    "            seq_arr[0].append(seq)\n",
    "            seq_arr[1].append(smallerseq)   \n",
    "            seq_arr[2].append(smallerstateis)\n",
    "            smallerseq = []\n",
    "            smallerstateis = []\n",
    "            counter  = 0\n",
    "    return seq_arr\n",
    "\n",
    "def find_leftover(SFsort_info, seq_arr): ## in case we want to use the other 6 states left over\n",
    "    left = [[seq_arr[0][-1]+1],[],[]]\n",
    "    counter = 0\n",
    "    for i in range((len(SFsort_info[1])-(np.mod((len(SFsort_info[1])), 8))), len(SFsort_info[1])-1):\n",
    "        counter = counter+1\n",
    "        if counter < 8:\n",
    "            left[1].append(SFsort_info[0][i+1])\n",
    "            left[2].append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "    return left\n",
    "\n",
    "try:\n",
    "    sequence = organize_SF(SF_Sort_arr)\n",
    "    if len(sequence[0]) == 14: ## catches state switches at pulse 0, leftovers are at the end of the regular sequence\n",
    "        leftovers = [[sequence[0][-1]],[sequence[1][-1]],[sequence[2][-1]]]\n",
    "        for i in range(len(sequence)):\n",
    "            sequence[i].pop(-1) ## deletes the leftovers sequence for state switches at pulse 0\n",
    "    else:\n",
    "        leftovers = find_leftover(SF_Sort_arr, sequence) ## otherwise can use normal function\n",
    "except Exception as e:\n",
    "    logger.error(run_num + ' failed during sequencing')\n",
    "    logger.exception(e)\n",
    "\n",
    "# print('sequences '+str(sequence[0]))\n",
    "print(str(len(sequence[0]))+' sequences with sequence order: '+str(sequence[1][0]))\n",
    "# print(leftovers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summing pulses into their states time: 1.6401591300964355\n"
     ]
    }
   ],
   "source": [
    "#  add up pulses for their respective state, in each 8 step sequence ##\n",
    "#  turning into a by-channel function 06.13.24 ##\n",
    "\n",
    "start = time.time()\n",
    "sequence = np.asarray(sequence, dtype = object)\n",
    "\n",
    "ON_sums = np.zeros((len(ys_cut), len(sequence[0]), len(ys_cut[0][0])), dtype=np.float64) ## 13 channels, 13 sequences, added pulses for ON\n",
    "OFF_sums = np.zeros((len(ys_cut), len(sequence[0]), len(ys_cut[0][0])), dtype=np.float64) ## 13 channels, 13 sequences, added pulses for OFF\n",
    "\n",
    "# @njit\n",
    "def add_pulse(ys, SFarr):\n",
    "    temp_ON = np.zeros((len(SFarr[0]), len(ys[0])), dtype=np.float64)\n",
    "    temp_OFF = np.zeros((len(SFarr[0]), len(ys[0])), dtype=np.float64)\n",
    "    for seq in range(0, len(SFarr[0])): ## for every sequence\n",
    "    #         print('seq:' +str(SFarr[0][seq]))\n",
    "#         print('seq:' +str(seq))\n",
    "        for state in range(0, len(SFarr[1][0])): ## for every state in the sequence\n",
    "    #         print(\"states loop \" + str(range(0, len(SFarr[1][0]))[0]) + ' - ' +  str(range(0, len(SFarr[1][0]))[-1]))\n",
    "            s = SFarr[1][seq][state] ## try this to condense code. Basically, the state currently at\n",
    "            if s==0 or s==3 or s==5 or s==6: ## these are ON states\n",
    "#                 print('ON \"s\" state '+str(s))\n",
    "#                 print('\"state\" ' +str(state) + ' from ' + str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))))\n",
    "#                 print('sums from '+str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[0]) +\n",
    "#                 ' - ' +str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[-1]) + '\\n')\n",
    "                for p in range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1])): ##From 20-60 for example. SFarr[2] is the array of start to end pulses to sum\n",
    "                    temp_ON[seq] = np.add(temp_ON[seq],ys[p]) ## start with zeros, add to each iteratively\n",
    "            if s==1 or s==2 or s==4 or s==7: ## these are OFF states\n",
    "#                 print('OFF \"s\" state '+str(s))\n",
    "#                 print('\"state\" ' +str(state) + ' from ' + str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))))\n",
    "#                 print('sums from '+str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[0]) +\n",
    "#                 ' - ' +str(range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1]))[-1]) + '\\n')\n",
    "                for p in range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1])):\n",
    "                    temp_OFF[seq] = np.add(temp_OFF[seq],ys[p])\n",
    "    return temp_ON, temp_OFF\n",
    "\n",
    "for i in range(len(ys_cut)):\n",
    "#     print('#################### channel: ' + str(i) + ' ##########################')\n",
    "    ON_sums[i], OFF_sums[i] = add_pulse(ys_cut[i], sequence)\n",
    "    \n",
    "# for i in range(len(ys_basesub)-12):\n",
    "#     print('#################### channel: ' + str(i) + ' ##########################')\n",
    "#     ON_sums[i], OFF_sums[i], ON_minus_sums[i], ON_plus_sums[i] = add_pulse(ys_basesub[i], sequence)\n",
    "\n",
    "end = time.time()\n",
    "print('summing pulses into their states time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BG fitting time: 14.61388349533081\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "BGregion1_beg = 4180  ## 10.28.24 hardcoded for now (maybe forever?). Seems like a good region for BG/Res\n",
    "BGregion1_end = 5450\n",
    "BGregion2_beg = 6250\n",
    "BGregion2_end = 8991\n",
    "BGreg1 = [BGregion1_beg,BGregion1_end]\n",
    "BGreg2 = [BGregion2_beg,BGregion2_end]\n",
    "fullrange = BGreg2[1]-BGreg1[0]\n",
    "# print(BGreg1[0])\n",
    "\n",
    "def BG_fitsubtract(bef_res_reg, aft_res_reg, ys): ## before/after resonance region [start:end] respectively, ys[ch] to fit\n",
    "    binstot = aft_res_reg[1]-bef_res_reg[0]  ## total number of bins in whole region\n",
    "    x1 = np.arange(bef_res_reg[0], bef_res_reg[1],1)\n",
    "    x2 = np.arange(aft_res_reg[0], aft_res_reg[1],1)\n",
    "    x = np.append(x1,x2) ## the x values that will be used to fit\n",
    "    fullx = np.arange(bef_res_reg[0], aft_res_reg[1],1) ## an array of every x bin in entire region\n",
    "    ys_bgsub = []\n",
    "#     seq_bgsub = []\n",
    "    for seq in range(0, len(ys)): ## number of sequences, usually 13\n",
    "        fitdata1 = ys[seq][bef_res_reg[0]: bef_res_reg[1]]\n",
    "        fitdata2 = ys[seq][aft_res_reg[0]: aft_res_reg[1]]\n",
    "        datasplice = np.append(fitdata1, fitdata2)\n",
    "#         x = np.linspace(0, len(datasplice),len(datasplice))\n",
    "        y = datasplice\n",
    "        data = odr.Data(x, y)\n",
    "        poly_model2 = odr.polynomial(2)  # using 2nd order polynomial model (looks to be better than 3...)\n",
    "        odr_obj = odr.ODR(data, poly_model2)\n",
    "        output = odr_obj.run()  # running ODR fitting\n",
    "        poly2 = np.poly1d(output.beta[::-1])\n",
    "        poly_y2 = poly2(x)\n",
    "        fullpoly_y2 = poly2(fullx)  ## extends the fit to fullx within the whole region\n",
    "        bgsubtracted = ys[seq][bef_res_reg[0]:aft_res_reg[1]] - fullpoly_y2  ## subtracts RealData-BackgroundFit\n",
    "#         seq_bgsub.append(bgsubtracted)\n",
    "        ys_bgsub.append(bgsubtracted)\n",
    "#     ys_bgsub.append(seq_bgsub)\n",
    "    return ys_bgsub\n",
    "\n",
    "ON_bgsub = np.zeros((len(ON_sums),len(ON_sums[0]),fullrange), dtype = np.float64) ## channels, sequences, range of BG subtraction\n",
    "OFF_bgsub = np.zeros((len(ON_sums),len(ON_sums[0]),fullrange), dtype = np.float64) ## channels, sequences, range of BG subtraction\n",
    "fullx = np.arange(BGreg1[0], BGreg2[1],1)\n",
    "\n",
    "for i in range(0, len(ON_sums)-1):\n",
    "    if chan_enab[i] == 24:\n",
    "        emessage = ('BG fit does not work for 6Li yet')\n",
    "        logger.error(run_num + emessage)\n",
    "        raise Exception(emessage)\n",
    "#     print(chan_enab[i])\n",
    "    ON_bgsub[i] = BG_fitsubtract(BGreg1,BGreg2, ON_sums[i])\n",
    "    OFF_bgsub[i] = BG_fitsubtract(BGreg1,BGreg2, OFF_sums[i])\n",
    "    \n",
    "# for i in range(len(testfunc)):\n",
    "#     plt.plot(xs_cut[1][BGreg1[0]:BGreg2[1]]*1e-6, testfunc[i], lw = '1.0', label='3rd Order polynomial background subtracted')\n",
    "\n",
    "end = time.time()\n",
    "print('BG fitting time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving all on/off added pulses, mainly for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ONOFF = np.zeros((len(ON_sums),2, len(ON_sums[0][0])), dtype=np.float64) ## all summed ON[0] and OFF[1] pulses for each channel, not each sequence\n",
    "\n",
    "def all_onoff(ON_arr, OFF_arr):\n",
    "    tempallON = np.zeros((len(ON_arr[0])), dtype=np.float64)\n",
    "    tempallOFF = np.zeros((len(ON_arr[0])), dtype=np.float64)\n",
    "    for seq in range(0, len(ON_arr)): ## number of sequences\n",
    "        tempallON = np.add(ON_arr[seq],tempallON)\n",
    "        tempallOFF = np.add(OFF_arr[seq],tempallOFF)\n",
    "    return tempallON, tempallOFF\n",
    "\n",
    "for i in range(len(ON_sums)):\n",
    "    all_ONOFF[i][0], all_ONOFF[i][1] = all_onoff(ON_sums[i], OFF_sums[i]) ## channel, ON[0] or OFF[1], summed wave\n",
    "    # print('ch done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabeo\\AppData\\Local\\Temp\\ipykernel_5256\\3743142974.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  seqasym = ((ON_arr[seq]-OFF_arr[seq]) / (ON_arr[seq]+OFF_arr[seq]))\n"
     ]
    }
   ],
   "source": [
    "asym_ch_bg = np.zeros((len(ON_bgsub), len(ON_bgsub[0][0])), dtype=np.float64) ## 1 Asym for each channel, not for each sequence (can change?)\n",
    "asym_ch_raw = np.zeros((len(ON_sums), len(ON_sums[0][0])), dtype=np.float64) ## 1 Asym for each channel, not for each sequence (can change?)\n",
    "# asym_pm = np.zeros((len(ONOFF_plus_sums),2, len(ONOFF_plus_sums[0][0][0])), dtype=np.float64) ## 1 Asym for each channel, not for each sequence (can change?)\n",
    "\n",
    "def asym2(ON_arr, OFF_arr):\n",
    "    tempasym = np.zeros((len(ON_arr[0])), dtype=np.float64)\n",
    "    for seq in range(0, len(ON_arr)): ## number of sequences\n",
    "        seqasym = ((ON_arr[seq]-OFF_arr[seq]) / (ON_arr[seq]+OFF_arr[seq]))\n",
    "#         if ON_arr[seq]+OFF_arr[seq] == 0: ## add an exception for sum being == 0 that causes div by 0    \n",
    "        tempasym = np.add(seqasym,tempasym)\n",
    "    normedasym = tempasym/len(ON_arr)\n",
    "    return normedasym\n",
    "\n",
    "for i in range(len(ON_bgsub)):\n",
    "    asym_ch_bg[i] = asym2(ON_bgsub[i], OFF_bgsub[i])\n",
    "    asym_ch_raw[i] = asym2(ON_sums[i], OFF_sums[i])\n",
    "#     asym_pm[i][0] = asym2(ONOFF_plus_sums[i][0], ONOFF_plus_sums[i][1])\n",
    "#     asym_pm[i][1] = asym2(ONOFF_minus_sums[i][0], ONOFF_minus_sums[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to create file (unable to open file: name = 'F:\\LANL/processed_data/debug_sample/runs12034-12363/ONOFF_D/12036_ONOFF_D.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5256\\1013525241.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# testch = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mONOFFSavename\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhdf5_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#     hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0], compression=\"gzip\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to create file (unable to open file: name = 'F:\\LANL/processed_data/debug_sample/runs12034-12363/ONOFF_D/12036_ONOFF_D.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# testch = 0\n",
    "\n",
    "with h5py.File(ONOFFSavename+'.h5', 'w') as hdf5_file:\n",
    "#     hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0], compression=\"gzip\")\n",
    "#     hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0])\n",
    "    hdf5_file.create_dataset('xs ', data=xs_cut[0]) ## all xs are the same, even though they are per channel...\n",
    "    hdf5_file.attrs['sequences'] = len(sequence[0])\n",
    "    hdf5_file.attrs['rownames'] = ['ON_Row0', 'OFF_Row1']\n",
    "    for i in range(0,len(ys_cut)):\n",
    "#         with h5py.File('test_allONOFFs'+'.h5', 'a') as hdf5_file:\n",
    "#         hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[i]), 2)), data=all_ONOFF[i], compression=\"gzip\")\n",
    "        hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[i]), 2)), data=all_ONOFF[i])\n",
    "#     a = hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0])\n",
    "#     a.attrs['rownames'] = ['ON_Row0', 'OFF_Row1']\n",
    "#     a.attrs['sequences'] = len(sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to create file (unable to open file: name = 'F:\\LANL/processed_data/debug_sample/runs12034-12363/asym_raw_D/12036_asym_raw_D.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5256\\356198256.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAsymSavename_raw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.h5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhdf5_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#     hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0], compression=\"gzip\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mhdf5_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xs '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxs_cut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to create file (unable to open file: name = 'F:\\LANL/processed_data/debug_sample/runs12034-12363/asym_raw_D/12036_asym_raw_D.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "AsymSavename_raw = AsymSavename\n",
    "with h5py.File(AsymSavename_raw+'.h5', 'w') as hdf5_file:\n",
    "#     hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0], compression=\"gzip\")\n",
    "    hdf5_file.create_dataset('xs ', data=xs_cut[0])\n",
    "    hdf5_file.attrs['sequences'] = len(sequence[0])\n",
    "    for i in range(0,len(ys_cut)):\n",
    "        hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[i]), 2)), data=asym_ch_raw[i])\n",
    "        \n",
    "with h5py.File(AsymSavename_bg+'.h5', 'w') as hdf5_file:\n",
    "#     hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[0]), 2)), data=all_ONOFF[0], compression=\"gzip\")\n",
    "    hdf5_file.create_dataset('xs ', data=fullx) ## different x values for fitted function\n",
    "    hdf5_file.attrs['sequences'] = len(sequence[0])\n",
    "    for i in range(0,len(ys_cut)):\n",
    "        hdf5_file.create_dataset('ch '+str(np.char.zfill(str(chan_enab[i]), 2)), data=asym_ch_bg[i])\n",
    "        \n",
    "# f = gzip.GzipFile(\"testcompressednparr.npy.gz\", \"w\")\n",
    "# np.save(file=f, arr=ys_cut)\n",
    "# f.close()\n",
    "        \n",
    "end = time.time()\n",
    "print('saving hdf5: ' + str(end-start))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing reaad\n",
    "# with h5py.File(ONOFFSavename+'.h5', 'r') as f:\n",
    "#     print(f.attrs.keys())\n",
    "#     print(f.attrs.get('sequences'))\n",
    "#     print(f.attrs.get('rownames'))\n",
    "#     f.close()\n",
    "    \n",
    "# # f = h5py.File('test_allONOFFs'+'.h5', 'r')\n",
    "# # # print(f['ch 00'].attrs.get('sequences'))\n",
    "# # f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## testing reaad\n",
    "# with h5py.File(AsymSavename+'.h5', 'r') as f:\n",
    "#     print(f.attrs.keys())\n",
    "#     print(f.attrs.get('sequences'))\n",
    "#     print(f.attrs.get('rownames'))\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullend = time.time()\n",
    "print('full processing time: ' + str(fullend-fullstart))  \n",
    "print('finished ' + str(datetime.now())) \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end of data processing ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Voigt (unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.special import voigt_profile\n",
    "# from scipy.optimize import curve_fit\n",
    "# voigt_profile(2, 1., 1.)\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# x = np.linspace(-10, 10, 500)\n",
    "# parameters_list = [(1.5, 0., \"solid\"), (1.3, 0.5, \"dashed\"),\n",
    "#                    (0., 1.8, \"dotted\"), (1., 1., \"dashdot\")]\n",
    "# for params in parameters_list:\n",
    "#     sigma, gamma, linestyle = params\n",
    "#     voigt = voigt_profile(x, sigma, gamma)\n",
    "#     ax.plot(x, voigt, label=rf\"$\\sigma={sigma},\\, \\gamma={gamma}$\",\n",
    "#             ls=linestyle)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270\n",
      "2070\n",
      "4811\n",
      "800\n",
      "800\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "callable <ufunc 'voigt_profile'> is not supported by signature",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11372\\4197626884.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mpopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurve_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoigt_profile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;31m# plt.plot(xs_cut[1][5450:6250], ON_sums[1][0][5450:6250], label=\"input data\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# plt.plot(xdata, voigt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minpack_py.py\u001b[0m in \u001b[0;36mcurve_fit\u001b[1;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, full_output, **kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp0\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;31m# determine number of parameters by inspecting the function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[0msig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\_lib\\_util.py\u001b[0m in \u001b[0;36mgetfullargspec_no_self\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \"\"\"\n\u001b[1;32m--> 364\u001b[1;33m     \u001b[0msig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     args = [\n\u001b[0;32m    366\u001b[0m         \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   3111\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3112\u001b[0m     \u001b[1;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3113\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[1;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2860\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2861\u001b[0m         \u001b[1;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2862\u001b[1;33m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[0;32m   2863\u001b[0m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0;32m   2864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2424\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2426\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'callable {!r} is not supported by signature'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: callable <ufunc 'voigt_profile'> is not supported by signature"
     ]
    }
   ],
   "source": [
    "# from scipy.special import voigt_profile\n",
    "# from scipy.optimize import curve_fit\n",
    "# Resregion_beg = 5450\n",
    "# Resregion_end = 6250\n",
    "# Resreg = [Resregion_beg,Resregion_end]\n",
    "# # voigt_profile(2, 1., 1.)\n",
    "# # fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# # x = np.linspace(-10, 10, 500)\n",
    "# # parameters_list = [(1.5, 0., \"solid\"), (1.3, 0.5, \"dashed\"),\n",
    "# #                    (0., 1.8, \"dotted\"), (1., 1., \"dashdot\")]\n",
    "# # for params in parameters_list:\n",
    "# #     sigma, gamma, linestyle = params\n",
    "# #     voigt = voigt_profile(x, sigma, gamma)\n",
    "# #     ax.plot(x, voigt, label=rf\"$\\sigma={sigma},\\, \\gamma={gamma}$\",\n",
    "# #             ls=linestyle)\n",
    "# sigma = 60\n",
    "# gamma = 30\n",
    "# beg = 5800\n",
    "# end = 5900\n",
    "# print(BGreg1[1]-BGreg1[0])\n",
    "# print(BGreg2[0]-BGreg1[0])\n",
    "# print(len(ON_bgsub[1][0]))\n",
    "# # xdata = xs_cut[1][4180:8991]*1e-6\n",
    "# # xdata = np.arange(Resreg[0],Resreg[1],1)\n",
    "# xdata = np.arange(-(Resreg[1]-Resreg[0])/2,(Resreg[1]-Resreg[0])/2,1)\n",
    "# # print(xdata[380:420])\n",
    "# print(len(xdata))\n",
    "# # ydata = ON_sums[1][0][5450:6250]\n",
    "# # xdata = xs_cut[1][beg:end]\n",
    "# # ydata = ON_sums[1][0][beg:end]\n",
    "# ydata = ON_bgsub[1][0][BGreg1[1]-BGreg1[0]:BGreg2[0]-BGreg1[0]]\n",
    "# print(len(ydata))\n",
    "\n",
    "# voigt = voigt_profile(xdata, sigma, gamma)*30000\n",
    "# # print(voigt)\n",
    "# plt.plot(xdata, voigt)\n",
    "# plt.plot(xdata,ydata)\n",
    "# plt.show()\n",
    "# popt, pcov = curve_fit(voigt_profile, xdata, ydata)\n",
    "# # plt.plot(xs_cut[1][5450:6250], ON_sums[1][0][5450:6250], label=\"input data\")\n",
    "# # plt.plot(xdata, voigt)\n",
    "# # popt, pcov = curve_fit(voigt, xdata, ydata)\n",
    "\n",
    "# # popt\n",
    "# # array([2.56274217, 1.37268521, 0.47427475])\n",
    "\n",
    "# # plt.plot(xdata, func(xdata, *popt), 'r-',\n",
    "\n",
    "# #          label='fit: a=%5.3f, b=%5.3f, c=%5.3f' % tuple(popt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
