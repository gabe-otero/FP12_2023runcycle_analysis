{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "319045a4-edf5-4a62-b401-2218c7679be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data: La_sample/run11139\n",
      "Channel is [ 0  1  2  3  4  5  6  7  8  9 10 11 24]\n",
      "saving processed data to processed_data/asym/11139_asym_d\n",
      "1.9716792106628418\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import uproot\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import math\n",
    "import statistics as st\n",
    "import os\n",
    "import PyQt5\n",
    "from numba import njit\n",
    "import time\n",
    "import numba\n",
    "from numba.typed import List\n",
    "from numba import uint16, intc, uint32\n",
    "from array import array\n",
    "\n",
    "# print(os.getcwd())\n",
    "os.chdir('D:/LANL/')\n",
    "datadir = 'sample_data/'\n",
    "folder = 'La_sample/'\n",
    "run_num = \"11139\" \n",
    "# print(os.getcwd() + folder)\n",
    "statefileloc = 'D:\\LANL\\SF_Norm_files\\TR_R_expected_avgs_stds_afterclip.csv'\n",
    "SFNormFile = 'SF_Norm_files/'+folder+run_num\n",
    "processedpulsefolder = 'processed_data/pulses_added/'\n",
    "processedasymfolder = 'processed_data/asym/'\n",
    "AddedPulseSavename = processedpulsefolder+run_num+'_pulsesadded_d'\n",
    "AsymSavename = processedasymfolder+run_num+'_asym_d'\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "start = time.time()\n",
    "fullstart = time.time()\n",
    "\n",
    "## cannot handle all 24 detectors at once, memory issue... can look into np.empty and deleting variables if needed\n",
    "#chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]) ## all\n",
    "chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,24]) ## downstream\n",
    "#chan_enab = np.array([12,13,14,15,16,17,18,19,20,21,22,23,24]) ## upstream\n",
    "#chan_enab = np.array([0,1,2,3,4,5,18,19,20,21,22,23,24])\n",
    "#chan_enab = np.array([1,19,24])\n",
    "\n",
    "\n",
    "#@jit(nopython = True)\n",
    "# read_data = np.array([])\n",
    "# fileLength = np.array([])\n",
    "read_data = []\n",
    "fileLength = []\n",
    "\n",
    "\n",
    "def open_file():\n",
    "    for el in chan_enab:\n",
    "        f = open(datadir + folder + 'run' + run_num + \"_ch\" + str(el) + \".bin\", 'rb')\n",
    "        read_data.append(np.fromfile(file=f, dtype=np.uint16))\n",
    "        f.close()\n",
    "        fileLength.append(len(read_data[-1]))\n",
    "    return read_data, fileLength\n",
    "\n",
    "open_file()\n",
    "\n",
    "fileLength = np.asarray(fileLength)\n",
    "read_data = np.asarray(read_data) ## in detector's case, all are the same size samples, so can do read_data as np array\n",
    "\n",
    "if chan_enab[-1] != 24:\n",
    "    raise Exception('last channel is not 6Li detector')\n",
    "\n",
    "end = time.time()\n",
    "# print('file open time: ' + str(end-start))            \n",
    "\n",
    "print('processing data: ' + folder + 'run' + run_num)\n",
    "print(\"Channel is \" + str(chan_enab))\n",
    "print('saving processed data to ' + AsymSavename)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "# print(read_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff448e-fd59-42e0-b8b2-adb846e9318c",
   "metadata": {},
   "source": [
    "Store the big header for each channel in arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcc0522c-582d-4057-b357-70512dd0fcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is La\n"
     ]
    }
   ],
   "source": [
    "BoardID = []\n",
    "recordLength = []\n",
    "numSamples = []\n",
    "eventCounter = []\n",
    "decFactor = []\n",
    "chanDec = []\n",
    "postTrig = []\n",
    "groupStart = []\n",
    "groupEnd = []\n",
    "timestamp= []\n",
    "sizeFirstEvent = []\n",
    "TTT = []\n",
    "\n",
    "targetDict = {0: \"La\", 1: \"Tb2O3\", 2: \"Yb2O3\", 3: \"Sm2O3\", 4: \"Er2O3\", 5: \"Ho2O3\", 6: \"other\"}\n",
    "foilDict = {0: \"TBD\", 1: \"TBD\", 2: \"TBD\", 3: \"TBD\", 4: \"TBD\", 5: \"TBD\", 6: \"other\"}\n",
    "\n",
    "target=(read_data[0][5]&0x00F0)>>4\n",
    "foil=read_data[0][5]&0x000F\n",
    "targetFlag = read_data[0][5]>>8&1\n",
    "foilFlag = read_data[0][5]>>9&1\n",
    "spinFiltFlag = read_data[0][5]>>10&1\n",
    "spinFlipFlag = read_data[0][5]>>11&1\n",
    "shutterFlag = read_data[0][5]>>12&1\n",
    "facilityTrigFlag = read_data[0][5]>>13&1\n",
    "\n",
    "if targetFlag:\n",
    "    target=targetDict[(read_data[0][5]&0x00F0)>>4]\n",
    "    \n",
    "else:\n",
    "    target = \"empty\"\n",
    "    \n",
    "    \n",
    "if foilFlag:\n",
    "    foil=foilDict[read_data[0][5]&0x000F]\n",
    "else:\n",
    "    foil = \"empty\"\n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    BoardID.append(read_data[i][9]>>8)\n",
    "    recordLength.append(((read_data[i][9]&0x00FF)<<16)+read_data[i][8])\n",
    "    numSamples.append(((read_data[i][11]&0x00FF)<<16)+read_data[i][10])\n",
    "    eventCounter.append(read_data[i][6]+(read_data[i][7]<<16))\n",
    "    BoardID.append(read_data[i][9]>>8)  \n",
    "    decFactor.append(read_data[i][11]>>8)\n",
    "    chanDec.append(read_data[i][13]>>8)\n",
    "    postTrig.append(read_data[i][15]>>8)\n",
    "    groupStart.append(((read_data[i][13]&0x00FF)<<16)+read_data[i][12])\n",
    "    groupEnd.append(((read_data[i][15]&0x00FF)<<16)+read_data[i][14])\n",
    "    \n",
    "    timestamp.append(read_data[i][16]+(read_data[i][17]<<16)+(read_data[i][18]<<32)+(read_data[i][19]<<40))  \n",
    "    sizeFirstEvent.append(read_data[i][0]+(read_data[i][1]<<16))\n",
    "    TTT.append(read_data[i][2]+(read_data[i][3]<<16)+(read_data[i][4]<<32))\n",
    "    \n",
    "#     print(\"For channel \" + str(chan_enab[i]) + \", BoardID is \" + str(BoardID[i])\n",
    "#           + \"; record length is \" + str(recordLength[i]) + \"; num Samples is \" \n",
    "#           + str(numSamples[i]) + \"; event counter is \" + str(eventCounter[i]) + \"; dec factor is \" + str(decFactor[i]) + \"; chan dec is \" \n",
    "#           + str(chanDec[i]) + \"; postTrig is \" + str(postTrig[i]) + \"; group start is \" + str(groupStart[i]) + \"; group end is \" + str(groupEnd[i])\n",
    "#           + \"; epoch time is \" + str(timestamp[i]) +  \"; first event size is \" + str(sizeFirstEvent[i]) + \"; and ETTT is \" + str(TTT[i]) + \"\\n\")\n",
    "\n",
    "BoardID = np.asarray(BoardID) \n",
    "recordLength = np.asarray(recordLength)\n",
    "numSamples = np.asarray(numSamples)\n",
    "eventCounter = np.asarray(eventCounter)\n",
    "decFactor = np.asarray(decFactor)\n",
    "chanDec = np.asarray(chanDec)\n",
    "postTrig = np.asarray(postTrig)\n",
    "groupStart = np.asarray(groupStart)\n",
    "groupEnd = np.asarray(groupEnd)\n",
    "timestamp = np.asarray(timestamp)\n",
    "sizeFirstEvent = np.asarray(sizeFirstEvent)\n",
    "TTT = np.asarray(TTT)\n",
    "\n",
    "print(\"Target is \" + target)\n",
    "# print(\"Foil is \" + foil)\n",
    "# print(\"Shutter is open: \" + str(bool(shutterFlag)))\n",
    "# print(\"Facility t0 is on: \" + str(bool(facilityTrigFlag)))\n",
    "# print(\"Spin flipper is on: \" + str(bool(spinFlipFlag)))\n",
    "# print(\"Spin filter is on: \" + str(bool(spinFiltFlag)))\n",
    "# print(\"Target is present: \" + str(bool(targetFlag)))\n",
    "# print(\"Foil is present: \" + str(bool(foilFlag)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9958e3-eb29-4529-b2bf-eaff422b6419",
   "metadata": {},
   "source": [
    "Determine the time axis for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "762903b1-1b4a-43a9-bd31-137f31cb6168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preTime = []\n",
    "startTime = []\n",
    "endTime = []\n",
    "resolution = []\n",
    "xs = [] \n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    preTime.append((100-postTrig[i])*recordLength[i]/100)\n",
    "    startTime.append((-1*preTime[i]*16*decFactor[i] + groupStart[i]*16*decFactor[i]))\n",
    "    endTime.append((-1*preTime[i]*16*decFactor[i] + groupEnd[i]*16*decFactor[i]))\n",
    "    resolution.append(16*chanDec[i]*decFactor[i])\n",
    "#     print(\"Pretime for channel\", chan_enab[i],\"is \" + str(preTime[i]) + \"; start time is \" + str(startTime[i]) + \"; end time is \" + str(endTime[i]) \n",
    "#           + \"; resolution is \" + str(resolution[i]) + \"ns\")\n",
    "    xs.append(np.arange(startTime[i],(numSamples[i])*resolution[i]+startTime[i], resolution[i]))\n",
    "\n",
    "#np.asarray(preTime)\n",
    "#np.asarray(startTime)\n",
    "#np.asarray(endTime)\n",
    "#np.asarray(resolution)\n",
    "xs = np.asarray(xs) ## can convert xs to np array here because all detectors same numsamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbf040e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataread from binary time: 1.6659696102142334\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "@njit\n",
    "def dataread(data, channels, fileLen, numSamps):\n",
    "    numRuns = int((fileLen[0]-20-numSamps[0])/(numSamps[0]+6)+1)\n",
    "    ys_arr = np.zeros((len(channels), numRuns,numSamps[0]), dtype=np.uint16)\n",
    "    ETTT_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    eventcount_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    for i in range(0,len(channels)):\n",
    "        eventCount = 0\n",
    "        byteCounter = 0\n",
    "            #byte counter is really 2bytecounter, lol\n",
    "        while byteCounter < fileLen[i]:\n",
    "            if byteCounter == 0:\n",
    "                ETTT_arr[i]=TTT[i]\n",
    "                #ETTT_arr[i].append(TTT[i])\n",
    "                eventcount_arr[i]=(eventCounter[i])\n",
    "                byteCounter = 20\n",
    "            else:\n",
    "                ETTT_arr[i]=(data[i][byteCounter]+(data[i][byteCounter+1]<<16)+(data[i][byteCounter+2]<<32))\n",
    "                eventcount_arr[i]=(data[i][byteCounter+4]+(data[i][byteCounter+5]<<16))\n",
    "                byteCounter += 6\n",
    "            for j in range(0, numSamps[i]):\n",
    "                #if j == 0:\n",
    "                    #ys_arr[i].append([])\n",
    "                #print(byteCounter)\n",
    "                ys_arr[i][eventCount][j]=data[i][byteCounter]\n",
    "                byteCounter += 1\n",
    "            eventCount += 1\n",
    "    return ys_arr, ETTT_arr, eventcount_arr\n",
    "\n",
    "#start=time.time()\n",
    "#ys_arrHe, ETTT_arrHe, eventcount_arrHe  = dataread(read_data, [25], fileLength, numSamples) ##hardcoded channel 25 for He\n",
    "ys_arr, ETTT_arr, eventcount_arr  = dataread(read_data, chan_enab, fileLength, numSamples) ##hardcoded channels for coils\n",
    "\n",
    "end = time.time()\n",
    "print('dataread from binary time: ' + str(end-start))            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a24e8d6f-120a-407a-a0dd-f8ae41dc45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeDif=[]\n",
    "for i in range(0,len(chan_enab)):\n",
    "    timeDif.append([])\n",
    "    for j in range(len(ETTT_arr[i])-1):\n",
    "        timeDif[i].append((ETTT_arr[i][j+1]-ETTT_arr[i][j])*8)\n",
    "#     print(\"Min time difference for channel\", chan_enab[i], \"is\", min(timeDif[i]), \"ns\")\n",
    "#     print(\"Max time difference for channel\", chan_enab[i], \"is\", max(timeDif[i]), \"ns \\n\")\n",
    "#print(timeDif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceca14aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting and/or base subtraction time: 4.539802551269531\n"
     ]
    }
   ],
   "source": [
    "## basesub and plotting ##\n",
    "baseL = 0\n",
    "baseR = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])\n",
    "numRuns = int((fileLength[0]-20-numSamples[0])/(numSamples[0]+6)+1)\n",
    "    \n",
    "legend =  ['NaI', 'R']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "s = 20 ## pulse to look at\n",
    "t=s+1\n",
    "\n",
    "## dont know why this is so slow ##\n",
    "def plotter(ys, xs, baseR, numpoints):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "    for i in range((len(ys))):\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "        for j in range(s, t): ## plot only interested pulses\n",
    "            plt.plot(xs[i], tempys_basesub[i][j]) #label=legend[i]) #+str(sums[1][j])) ## sums[j] will not work for more than just TR   \n",
    "            plt.axvline(xs[0][baseL], ls = '--')\n",
    "            plt.axvline(xs[0][baseR], ls = '--')\n",
    "            #plt.axvline(xs[0][int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])], ls = '--', c ='m')\n",
    "            plt.axvline(xs[0][baseR+5], ls = '--', c ='r') ## BaseR+5 line marks the beginning of the integral, until the end of samples.\n",
    "#             plt.title('SF state transition' + transitions[p]) \n",
    "#             plt.xlabel(\"time from trigger (ns)\")\n",
    "#             plt.ylabel(\"ADC\")\n",
    "            plt.legend()\n",
    "            \n",
    "#plotter(ys_arr[9:], xs[9:], baseR, numSamples) ##plot coils\n",
    "\n",
    "ys_basesub = np.zeros((len(ys_arr), numRuns,numSamples[0]), dtype=np.float64)\n",
    "\n",
    "@njit ## jit is faster for large # channels, slower for small # channels\n",
    "def basesub(ys, baseRight, numpoints): \n",
    "    tempys_basesub = np.zeros((numRuns,numpoints[0]), dtype=np.float64)\n",
    "    for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "        tempys_basesub[pulse]=np.subtract(ys[pulse], np.mean(ys[pulse][baseL:baseRight]))\n",
    "    return tempys_basesub\n",
    "\n",
    "## got rid of sums here, should be done after aligning and cutting\n",
    "## got rid of xs in basesub, don't think we need them as an input 06.10.24\n",
    "\n",
    "for i in range(len(ys_basesub)):\n",
    "    ys_basesub[i] = basesub(ys_arr[i], baseR, numSamples)\n",
    "\n",
    "ys_basesub[-1] = ys_basesub[-1]*-1 ## invert 6Li to positive signal. Comment out if not using\n",
    "\n",
    "end = time.time()\n",
    "print('plotting and/or base subtraction time: ' + str(end-start))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3fe8d3",
   "metadata": {},
   "source": [
    "## Load SF Sorting and norm ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "943fb0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in SF and He normalization information \n",
    "df_SF = pd.read_hdf(SFNormFile + '.h5', key='df_0')\n",
    "df_HE = pd.read_hdf(SFNormFile + '.h5', key='df_1')\n",
    "\n",
    "SF_Sort_arr = df_SF[['nicknames', 'transition_locations']].to_numpy().T\n",
    "He_Norm_arr = df_HE[['pulse', 'norms']].to_numpy().T\n",
    "\n",
    "NormFactor = 100000  ## He integrals are huge, this normalizes all of those by a constant value for ease of use\n",
    "HeNorms= (He_Norm_arr[1])/NormFactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee9c9433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[5, 6, 7, 0, 1, 2, 3, 4]\n",
      "[[14], [5, 6, 7, 0, 1, 2], [[4720, 4760], [4765, 4805], [4810, 4850], [4855, 4895], [4900, 4940], [4945, 4985]]]\n"
     ]
    }
   ],
   "source": [
    "# for ind in df.index:\n",
    "#     print('transition: '+ str(df['nicknames'][ind]) + ' location: ' + str(df['transition_locations'][ind]))\n",
    "#print(df['transition_locations'],df['nicknames'] )\n",
    "\n",
    "counter = 0\n",
    "sequence = [[],[],[]]\n",
    "seq = 0\n",
    "smallerseq = []\n",
    "smallerstateis = []\n",
    "\n",
    "for i in range(len(SF_Sort_arr[1])-(np.mod((len(SF_Sort_arr[1])), 8))):  ##111 mod 8 = 7, so essentially 111-7 = 104\n",
    "    counter = counter+1\n",
    "    if counter < 8:\n",
    "        smallerstateis.append([(SF_Sort_arr[1][i])+5,(SF_Sort_arr[1][i+1])])\n",
    "        smallerseq.append(SF_Sort_arr[0][i+1])\n",
    "    elif counter == 8:\n",
    "        seq = seq+1\n",
    "        smallerstateis.append([(SF_Sort_arr[1][i])+5,(SF_Sort_arr[1][i+1])])\n",
    "        smallerseq.append(SF_Sort_arr[0][i+1])\n",
    "        sequence[0].append(seq)\n",
    "        sequence[1].append(smallerseq)   \n",
    "        sequence[2].append(smallerstateis)\n",
    "        smallerseq = []\n",
    "        smallerstateis = []\n",
    "        counter  = 0\n",
    "\n",
    "leftovers = [[sequence[0][-1]+1],[],[]]\n",
    "\n",
    "for i in range((len(SF_Sort_arr[1])-(np.mod((len(SF_Sort_arr[1])), 8))), len(SF_Sort_arr[1])-1):\n",
    "    counter = counter+1\n",
    "    if counter < 8:\n",
    "        leftovers[1].append(SF_Sort_arr[0][i+1])\n",
    "        leftovers[2].append([(SF_Sort_arr[1][i])+5,(SF_Sort_arr[1][i+1])])\n",
    "    elif counter == 8: ## not really needed here, maybe delete\n",
    "        seq = seq+1\n",
    "        leftoversum.append(np.sum(sums_normed[0][(SF_Sort_arr[1][i])+5:(SF_Sort_arr[1][i+1])]))\n",
    "        smallerseq.append(SF_Sort_arr[0][i+1])\n",
    "        sequence[0].append(seq)\n",
    "        sequence[1].append(smallerseq)       \n",
    "        smallerseq = []\n",
    "        counter  = 0\n",
    "\n",
    "print(sequence[0])\n",
    "print(sequence[1][0])\n",
    "print(leftovers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3763f",
   "metadata": {},
   "source": [
    "## t0 aligning ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0766c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding offset time: 1.1737792491912842\n"
     ]
    }
   ],
   "source": [
    "## use 6Li t0 for all instead of for themselves individually\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "NaIthresh=2000\n",
    "Li6thresh=1000\n",
    "\n",
    "threshold_array = (np.full(len(ys_basesub), NaIthresh))\n",
    "threshold_array[-1] = Li6thresh\n",
    "\n",
    "#@njit ## numba does not support reversed, but this could be changed if it's slow\n",
    "def find_offset(ys, thresharr):\n",
    "    xCrosses = np.zeros((len(ys), numRuns)) #outer array is crossing arrays for given channel, inner array is crossing for each event\n",
    "    offset = np.zeros((len(ys), numRuns), dtype=np.int32) ##offset in bins for each channel, each pulse\n",
    "    modeCrosses = np.zeros((len(ys)), dtype=np.float64)\n",
    "    for i in reversed(range(len(ys))):\n",
    "        #xValues.append([])\n",
    "        for p in range(len(ys[i])):\n",
    "            xing = np.argmax(ys[i][p] > thresharr[i])\n",
    "            #print(xing)\n",
    "            xCrosses[i][p] = xing\n",
    "        modeCrosses[i] = (st.mode(xCrosses[i])) #find the most typical crossing value for each channel\n",
    "        for p in range(len(xCrosses[i])):\n",
    "            offset[i][p] = (modeCrosses[-1] - xCrosses[i][p]) ## make sure this is the correct sign!!! \n",
    "    if (np.all(xCrosses[-1])) == False:\n",
    "        raise Exception('ERROR: 6Li threshold was not reached for at least one pulse')\n",
    "    return offset, xCrosses, modeCrosses\n",
    "                           \n",
    "offset, xCrosses, modeCrosses = find_offset(ys_basesub, threshold_array)\n",
    "\n",
    "end = time.time()\n",
    "print('finding offset time: ' + str(end-start))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b2a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligning and cutting time: 8.645994901657104\n"
     ]
    }
   ],
   "source": [
    "## this cell loops through every channel as opposed to inputting all channels at once. 5x faster\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## extend all arrays by a value, check that the max number of offset on 6Li is less than that value ##\n",
    "extendedRange = 3 ## must be a positive value which to extend ys_arr\n",
    "if abs(max(offset[-1], key = abs)) > extendedRange: ## if the max offset of 6Li is >extendedRange, something is wrong\n",
    "    raise Exception('ERROR: largest offset greater than extended range')\n",
    "\n",
    "ys_ext = np.zeros((len(ys_basesub), len(ys_basesub[0]), len(ys_basesub[0][0])+extendedRange*2), dtype=np.float64)\n",
    "ys_cut = np.zeros((len(ys_basesub), len(ys_basesub[0]), (len(ys_ext[0][0])-((extendedRange*2)+1)*2)))\n",
    "xs_cut = np.zeros((len(ys_cut), len(ys_cut[0][0])))\n",
    "\n",
    "# cant use jit because np.pad is not supported\n",
    "def align_cut_norm(ys, xs_arr, extendedr):\n",
    "    tempys_ext = np.zeros((len(ys), len(ys[0])+extendedr*2), dtype=np.float64)\n",
    "    tempys_cut = np.zeros((len(ys), (len(tempys_ext[0])-((extendedr*2)+1)*2)))\n",
    "    tempxs_cut = np.zeros(len(tempys_cut[0]))\n",
    "    for p in range(len(ys)):\n",
    "        tempys_ext[p] = np.pad(ys[p], extendedr, 'constant', constant_values=(0))\n",
    "        tempys_ext[p] = np.roll(tempys_ext[p],offset[-1][p]) ## assumes 6Li at -1 position\n",
    "        tempys_cut[p] = tempys_ext[p][((extendedr*2)+1):-((extendedr*2)+1)].copy() ## cut by 7 (if extRange == 3)\n",
    "        tempys_cut[p] = tempys_cut[p]/HeNorms[p] ## normalize by 3He integral\n",
    "    x_cut_amt = int((len(ys[0]) - len(tempys_cut[0]))/2)\n",
    "    tempxs_cut = xs_arr[x_cut_amt:-x_cut_amt].copy()\n",
    "    return tempys_cut, tempxs_cut\n",
    "\n",
    "for i in range(len(ys_basesub)):\n",
    "    ys_cut[i], xs_cut[i] = align_cut_norm(ys_basesub[i], xs[i], extendedRange)\n",
    "    \n",
    "# checkp = 2053\n",
    "# print(offset[-1][checkp]) ## checking offset for one example checkpulse\n",
    "# print('original index for checkpulse: '+str(np.argmax(ys_basesub[0][checkp]> 2000))) ## we can follow the index as it changes with extension/cut\n",
    "# #print('extended range index for checkpulse: '+str(np.argmax(ys_ext[0][checkp]> 2000)))\n",
    "# print('cut array index for checkpulse: '+str(np.argmax((ys_cut[0][checkp]*HeNorms[checkp])> 2000)))\n",
    "\n",
    "del ys_ext ## might help with memory issues\n",
    "del ys_basesub\n",
    "\n",
    "end = time.time()\n",
    "print('aligning and cutting time: ' + str(end-start))            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075df24a",
   "metadata": {},
   "source": [
    "## add up N number of pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf41a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "summing pulses into their states time: 0.48624300956726074\n"
     ]
    }
   ],
   "source": [
    "## add up pulses for their respective state, in each 8 step sequence\n",
    "## turning into a by-channel function 06.13.24\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "legend = ['NaI5 (downstream)','NaI4R (upstream)','6Li']\n",
    "\n",
    "## t_to_eV = 0.5*(1.6749286*10**(-27))*((27.3/TIME))**2*(6.24151*10**18 [J/eV])\n",
    "\n",
    "added_pulses = np.zeros((len(ys_cut), len(sequence[0]), 8, len(ys_cut[0][0])), dtype=np.float64) ## 13 sequences, 8 stages each works?\n",
    "## i channels, 13 sequences each, 8 states each sequence, 8992 num points\n",
    "\n",
    "ON_OFF_sums = np.zeros((len(ys_cut), len(sequence[0]), 2, len(ys_cut[0][0])), dtype=np.float64) ## 13 sequences, 2 for ON or OFF for each sequence\n",
    "\n",
    "#@njit\n",
    "def add_pulse(ys, SFarr):\n",
    "    tempadded_p = np.zeros((len(SFarr[0]), 8, len(ys[0])), dtype=np.float64)    \n",
    "    temp_ONOFF = np.zeros((len(SFarr[0]), 2, len(ys[0])), dtype=np.float64)\n",
    "    for seq in range(0, len(SFarr[0])): ## for every sequence\n",
    "        for state in range(0, len(SFarr[1][0])): ## for every state in the sequence\n",
    "            for p in range((SFarr[2][seq][state][0]),(SFarr[2][seq][state][1])+1): ##not sure if this works. from 20-60 for example\n",
    "#                 tempadded_pulses[i] = added_pulses[i]+np.array(ys_cut[i][j])\n",
    "                tempadded_p[seq][state] = np.add(tempadded_p[seq][state],(ys[p])) ## start with zeros, add to each iteratively\n",
    "            if state==0 or state==3 or state==5 or state==6: ## these are ON states\n",
    "                temp_ONOFF[seq][0] = np.add(temp_ONOFF[seq][0],(tempadded_p[seq][state])) ## start with zeros, add to each iteratively\n",
    "            if state==1 or state==2 or state==4 or state==7: ## these are OFF states\n",
    "                temp_ONOFF[seq][1] = np.add(temp_ONOFF[seq][1],(tempadded_p[seq][state])) ## start with zeros, add to each iteratively\n",
    "    return tempadded_p, temp_ONOFF\n",
    "                \n",
    "for i in range(len(ys_cut)):\n",
    "    added_pulses[i], ON_OFF_sums[i] = add_pulse(ys_cut[i], sequence)\n",
    "                \n",
    "## plotting examples\n",
    "# plt.plot(xs_cut[i], added_pulses[0][0][0] , label=legend[0] +', sequence 1 state 1, 40 pulses added')\n",
    "# plt.plot(xs_cut[i], added_pulses[0][0][1] , label=legend[0] +', sequence 1 state 2, 40 pulses added')\n",
    "# plt.plot(xs_cut[i], added_pulses[0][1][0] , label=legend[0] +', sequence 2 state 1, 40 pulses added') \n",
    "# plt.plot(xs_cut[i], added_pulses[0][1][1] , label=legend[0] +', sequence 2 state 2, 40 pulses added') \n",
    "    \n",
    "# plt.title('Detector signals') \n",
    "# plt.xlabel(\"time from trigger (ns)\")\n",
    "# plt.ylabel(\"ADC\")\n",
    "\n",
    "# # plt.axvline(xs[0][baseL], ls = '--')\n",
    "# # plt.axvline(xs[0][baseR], ls = '--')\n",
    "# #plt.axvline(xs[1][intgrL], ls = '--', c ='g')\n",
    "# #plt.axvline(xs[1][intgrR], ls = '--', c ='g')\n",
    "# #plt.axvline(xs[2][HeintgrL], ls = '--', c ='r')\n",
    "# #plt.axvline(xs[2][HeintgrR], ls = '--', c ='r')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "print(len(added_pulses[1]))\n",
    "\n",
    "end = time.time()\n",
    "print('summing pulses into their states time: ' + str(end-start))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf62cf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate asymmetry time: 0.0010063648223876953\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "Asym = np.zeros((len(ON_OFF_sums), len(ON_OFF_sums[0][0][0])), dtype=np.float64) ## 1 Asym for each channel, not for each sequence (can change)\n",
    "\n",
    "def asym(ON_OFF_arr):\n",
    "    tempasym = np.zeros((len(ON_OFF_arr[0][0])), dtype=np.float64)\n",
    "    for seq in range(len(ON_OFF_arr[0])): ## number of sequences\n",
    "        asymform = ((ON_OFF_arr[seq][0]-ON_OFF_arr[seq][1]) / (ON_OFF_arr[seq][0]+ON_OFF_arr[seq][1]))\n",
    "        tempasym = np.add(asymform,tempasym)\n",
    "    normedasym = tempasym/len(ON_OFF_sums[0])\n",
    "    return normedasym\n",
    "\n",
    "for i in range(len(ON_OFF_sums)):\n",
    "    Asym[i] = asym(ON_OFF_sums[i])\n",
    "\n",
    "end = time.time()\n",
    "print('calculate asymmetry time: ' + str(end-start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c833d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full processing time: 19.09673523902893\n"
     ]
    }
   ],
   "source": [
    "np.save(AddedPulseSavename, added_pulses)\n",
    "np.save(AsymSavename, Asym)\n",
    "\n",
    "fullend = time.time()\n",
    "print('full processing time: ' + str(fullend-fullstart))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe9698",
   "metadata": {},
   "source": [
    "## end of data processing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f02ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## plotting examples\n",
    "# # Asym = (ON_OFF_sums[-1][0][0]-ON_OFF_sums[-1][0][1]) / (ON_OFF_sums[0][0][0]+ON_OFF_sums[0][0][1])\n",
    "# # plt.plot(xs_cut[i], ON_OFF_sums[0][0][0] , label=legend[0] +', sequence 1 ON pulses')\n",
    "# # plt.plot(xs_cut[i], ON_OFF_sums[0][0][1] , label=legend[0] +', sequence 1 OFF pulses')\n",
    "# # plt.plot(xs_cut[i], ON_OFF_sums[0][1][0] , label=legend[0] +', sequence 2 ON pulses') \n",
    "# # plt.plot(xs_cut[i], ON_OFF_sums[0][1][1] , label=legend[0] +', sequence 2 OFF pulses') \n",
    "# plt.plot(xs_cut[2], Asym[2] , label=legend[0] +'NaI asym') \n",
    "\n",
    "    \n",
    "# #plt.xlim(-50000, 900000)\n",
    "# plt.ylim(-1.5,1.5)\n",
    "# plt.title('Detector signals') \n",
    "# plt.xlabel(\"time from trigger (ns)\")\n",
    "# plt.ylabel(\"ADC\")\n",
    "\n",
    "# # plt.axvline(xs[0][baseL], ls = '--')\n",
    "# # plt.axvline(xs[0][baseR], ls = '--')\n",
    "# #plt.axvline(xs[1][intgrL], ls = '--', c ='g')\n",
    "# #plt.axvline(xs[1][intgrR], ls = '--', c ='g')\n",
    "# #plt.axvline(xs[2][HeintgrL], ls = '--', c ='r')\n",
    "# #plt.axvline(xs[2][HeintgrR], ls = '--', c ='r')\n",
    "\n",
    "# #plt.text(1.5e7, 1200, 'test', fontsize=12)\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
