{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ed8f396-1d0a-4b4c-831f-efe3ad878a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel is [ 0  1  2  3  4  5  6  7  8  9 10 11 24]\n",
      "13.527618169784546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[13]:\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import uproot\n",
    "import pandas as pd\n",
    "import statistics as st\n",
    "import os\n",
    "from numba import njit\n",
    "import time\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "from loguru import logger\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# for arg in sys.argv:\n",
    "#     run_num=str(arg).zfill(5)\n",
    "#     # print(run_num)\n",
    "\n",
    "# chan_enab = int(sys.argv[-1])\n",
    "# run_start=str(sys.argv[1]).zfill(5)\n",
    "# run_end=str(sys.argv[2]).zfill(5)\n",
    "# run_num=str(sys.argv[3]).zfill(5)\n",
    "run_num = \"11164\" \n",
    "\n",
    "# print(os.getcwd())\n",
    "os.chdir('F:/LANL/')\n",
    "datadir = 'D:\\LANSCE_FP12_2023\\data/'\n",
    "folder = 'runs11139-11412/'\n",
    "SFNormFile = 'SF_Norm_files/'+folder+run_num\n",
    "# datadir = 'D:/LANSCE_FP12_2023/data/' ## add directory of hard drive\n",
    "# uniquefolder = \"runs\" + str(run_start) + \"-\" + str(run_end) +\"/\"\n",
    "# SFNormFile = 'SF_Norm_files/'+uniquefolder+run_num\n",
    "\n",
    "statefileloc = 'F:\\LANL\\SF_Norm_files\\TR_R_expected_avgs_stds_afterclip.csv'\n",
    "# processedpulsefolder = '/processed_data/'+uniquefolder+'pulses_added/'\n",
    "# processedasymfolder = '/processed_data/'+uniquefolder+'asym/'\n",
    "# AddedPulseSavename = processedpulsefolder+run_num+'_pulsesadded_d'\n",
    "# AsymSavename = processedasymfolder+run_num+'_asym_d'\n",
    "# logger.add(\"F:/LANL/processed_data/\" + uniquefolder + '0_ErrorLog_'+run_start+'_'+run_end+'.txt', delay = False)\n",
    "\n",
    "# print('processing data: ' + uniquefolder + '/run' + run_num)\n",
    "\n",
    "# AddedPulseSavename = processedpulsefolder+uniquefolder+run_num+'_pulsesadded_d'\n",
    "# AsymSavename = processedasymfolder+uniquefolder+run_num+'_asym_d'\n",
    "# print(os.getcwd()+processedpulsefolder)\n",
    "# if not os.path.exists(os.getcwd()+processedpulsefolder) or not os.path.exists(os.getcwd()+processedasymfolder):\n",
    "#     # Create the directory\n",
    "#     os.makedirs(os.getcwd()+processedpulsefolder)\n",
    "#     os.makedirs(os.getcwd()+processedasymfolder)\n",
    "#     print(\"Directory created successfully\")\n",
    "# else:\n",
    "#     pass\n",
    "\n",
    "# print(os.getcwd() + folder)\n",
    "\n",
    "# get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "start = time.time()\n",
    "fullstart = time.time()\n",
    "\n",
    "## cannot handle all 24 detectors at once, memory issue... can look into np.empty and deleting variables if needed\n",
    "#chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]) ## all\n",
    "chan_enab = np.array([0,1,2,3,4,5,6,7,8,9,10,11,24]) ## downstream\n",
    "#chan_enab = np.array([12,13,14,15,16,17,18,19,20,21,22,23,24]) ## upstream\n",
    "\n",
    "#@jit(nopython = True)\n",
    "# read_data = np.array([])\n",
    "# fileLength = np.array([])\n",
    "read_data = []\n",
    "fileLength = []\n",
    "\n",
    "\n",
    "def open_file():\n",
    "    for el in chan_enab:\n",
    "        f = open(datadir + folder + 'run' + run_num + \"_ch\" + str(el) + \".bin\", 'rb')\n",
    "        # f = open(datadir+uniquefolder + 'run' + str(run_num) + \"_ch\" +str(el) + \".bin\", 'rb')\n",
    "        read_data.append(np.fromfile(file=f, dtype=np.uint16))\n",
    "        f.close()\n",
    "        fileLength.append(len(read_data[-1]))\n",
    "    return read_data, fileLength\n",
    "\n",
    "open_file()\n",
    "\n",
    "fileLength = np.asarray(fileLength)\n",
    "read_data = np.asarray(read_data) ## in detector's case, all are the same size samples, so can do read_data as np array\n",
    "\n",
    "if chan_enab[-1] != 24:\n",
    "    emessage = ('last channel is not 6Li detector')\n",
    "    # logger.error(run_num + emessage)\n",
    "    raise Exception(emessage)\n",
    "\n",
    "end = time.time()\n",
    "# print('file open time: ' + str(end-start))            \n",
    "\n",
    "# print('saving processed data to ' + AsymSavename)\n",
    "print(\"Channel is \" + str(chan_enab))\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "# print(read_data)\n",
    "\n",
    "\n",
    "# Store the big header for each channel in arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af9f97e-08f3-458c-b841-6811a08dec8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is La\n"
     ]
    }
   ],
   "source": [
    "# In[14]:\n",
    "\n",
    "BoardID = []\n",
    "recordLength = []\n",
    "numSamples = []\n",
    "eventCounter = []\n",
    "decFactor = []\n",
    "chanDec = []\n",
    "postTrig = []\n",
    "groupStart = []\n",
    "groupEnd = []\n",
    "timestamp= []\n",
    "sizeFirstEvent = []\n",
    "TTT = []\n",
    "\n",
    "targetDict = {0: \"La\", 1: \"Tb2O3\", 2: \"Yb2O3\", 3: \"Sm2O3\", 4: \"Er2O3\", 5: \"Ho2O3\", 6: \"other\"}\n",
    "foilDict = {0: \"TBD\", 1: \"TBD\", 2: \"TBD\", 3: \"TBD\", 4: \"TBD\", 5: \"TBD\", 6: \"other\"}\n",
    "\n",
    "target=(read_data[0][5]&0x00F0)>>4\n",
    "foil=read_data[0][5]&0x000F\n",
    "targetFlag = read_data[0][5]>>8&1\n",
    "foilFlag = read_data[0][5]>>9&1\n",
    "spinFiltFlag = read_data[0][5]>>10&1\n",
    "spinFlipFlag = read_data[0][5]>>11&1\n",
    "shutterFlag = read_data[0][5]>>12&1\n",
    "facilityTrigFlag = read_data[0][5]>>13&1\n",
    "\n",
    "if targetFlag:\n",
    "    target=targetDict[(read_data[0][5]&0x00F0)>>4]\n",
    "else:\n",
    "    target = \"empty\"\n",
    "if foilFlag:\n",
    "    foil=foilDict[read_data[0][5]&0x000F]\n",
    "else:\n",
    "    foil = \"empty\"\n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    BoardID.append(read_data[i][9]>>8)\n",
    "    recordLength.append(((read_data[i][9]&0x00FF)<<16)+read_data[i][8])\n",
    "    numSamples.append(((read_data[i][11]&0x00FF)<<16)+read_data[i][10])\n",
    "    eventCounter.append(read_data[i][6]+(read_data[i][7]<<16))\n",
    "    BoardID.append(read_data[i][9]>>8)  \n",
    "    decFactor.append(read_data[i][11]>>8)\n",
    "    chanDec.append(read_data[i][13]>>8)\n",
    "    postTrig.append(read_data[i][15]>>8)\n",
    "    groupStart.append(((read_data[i][13]&0x00FF)<<16)+read_data[i][12])\n",
    "    groupEnd.append(((read_data[i][15]&0x00FF)<<16)+read_data[i][14])\n",
    "    \n",
    "    timestamp.append(read_data[i][16]+(read_data[i][17]<<16)+(read_data[i][18]<<32)+(read_data[i][19]<<40))  \n",
    "    sizeFirstEvent.append(read_data[i][0]+(read_data[i][1]<<16))\n",
    "    TTT.append(read_data[i][2]+(read_data[i][3]<<16)+(read_data[i][4]<<32))\n",
    "    \n",
    "#     print(\"For channel \" + str(chan_enab[i]) + \", BoardID is \" + str(BoardID[i])\n",
    "#           + \"; record length is \" + str(recordLength[i]) + \"; num Samples is \" \n",
    "#           + str(numSamples[i]) + \"; event counter is \" + str(eventCounter[i]) + \"; dec factor is \" + str(decFactor[i]) + \"; chan dec is \" \n",
    "#           + str(chanDec[i]) + \"; postTrig is \" + str(postTrig[i]) + \"; group start is \" + str(groupStart[i]) + \"; group end is \" + str(groupEnd[i])\n",
    "#           + \"; epoch time is \" + str(timestamp[i]) +  \"; first event size is \" + str(sizeFirstEvent[i]) + \"; and ETTT is \" + str(TTT[i]) + \"\\n\")\n",
    "\n",
    "BoardID = np.asarray(BoardID) \n",
    "recordLength = np.asarray(recordLength)\n",
    "numSamples = np.asarray(numSamples)\n",
    "eventCounter = np.asarray(eventCounter)\n",
    "decFactor = np.asarray(decFactor)\n",
    "chanDec = np.asarray(chanDec)\n",
    "postTrig = np.asarray(postTrig)\n",
    "groupStart = np.asarray(groupStart)\n",
    "groupEnd = np.asarray(groupEnd)\n",
    "timestamp = np.asarray(timestamp)\n",
    "sizeFirstEvent = np.asarray(sizeFirstEvent)\n",
    "TTT = np.asarray(TTT)\n",
    "\n",
    "print(\"Target is \" + target)\n",
    "# print(\"Foil is \" + foil)\n",
    "# print(\"Shutter is open: \" + str(bool(shutterFlag)))\n",
    "# print(\"Facility t0 is on: \" + str(bool(facilityTrigFlag)))\n",
    "# print(\"Spin flipper is on: \" + str(bool(spinFlipFlag)))\n",
    "# print(\"Spin filter is on: \" + str(bool(spinFiltFlag)))\n",
    "# print(\"Target is present: \" + str(bool(targetFlag)))\n",
    "# print(\"Foil is present: \" + str(bool(foilFlag)))\n",
    "\n",
    "\n",
    "# Determine the time axis for each channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84971117-756c-4294-944b-e0d373b75b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataread from binary time: 4.273078441619873\n"
     ]
    }
   ],
   "source": [
    "# In[15]:\n",
    "\n",
    "preTime = []\n",
    "startTime = []\n",
    "endTime = []\n",
    "resolution = []\n",
    "xs = [] \n",
    "\n",
    "for i in range(0,len(chan_enab)):\n",
    "    preTime.append((100-postTrig[i])*recordLength[i]/100)\n",
    "    startTime.append((-1*preTime[i]*16*decFactor[i] + groupStart[i]*16*decFactor[i]))\n",
    "    endTime.append((-1*preTime[i]*16*decFactor[i] + groupEnd[i]*16*decFactor[i]))\n",
    "    resolution.append(16*chanDec[i]*decFactor[i])\n",
    "#     print(\"Pretime for channel\", chan_enab[i],\"is \" + str(preTime[i]) + \"; start time is \" + str(startTime[i]) + \"; end time is \" + str(endTime[i]) \n",
    "#           + \"; resolution is \" + str(resolution[i]) + \"ns\")\n",
    "    xs.append(np.arange(startTime[i],(numSamples[i])*resolution[i]+startTime[i], resolution[i]))\n",
    "\n",
    "#np.asarray(preTime)\n",
    "#np.asarray(startTime)\n",
    "#np.asarray(endTime)\n",
    "#np.asarray(resolution)\n",
    "xs = np.asarray(xs) ## can convert xs to np array here because all detectors same numsamples\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "@njit\n",
    "def dataread(data, channels, fileLen, numSamps):\n",
    "    numRuns = int((fileLen[0]-20-numSamps[0])/(numSamps[0]+6)+1)\n",
    "    ys_arr = np.zeros((len(channels), numRuns,numSamps[0]), dtype=np.uint16)\n",
    "    ETTT_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    eventcount_arr = np.zeros((len(channels), numRuns), dtype=np.intc)\n",
    "    for i in range(0,len(channels)):\n",
    "        eventCount = 0\n",
    "        byteCounter = 0\n",
    "            #byte counter is really 2bytecounter, lol\n",
    "        while byteCounter < fileLen[i]:\n",
    "            if byteCounter == 0:\n",
    "                ETTT_arr[i]=TTT[i]\n",
    "                #ETTT_arr[i].append(TTT[i])\n",
    "                eventcount_arr[i]=(eventCounter[i])\n",
    "                byteCounter = 20\n",
    "            else:\n",
    "                ETTT_arr[i]=(data[i][byteCounter]+(data[i][byteCounter+1]<<16)+(data[i][byteCounter+2]<<32))\n",
    "                eventcount_arr[i]=(data[i][byteCounter+4]+(data[i][byteCounter+5]<<16))\n",
    "                byteCounter += 6\n",
    "            for j in range(0, numSamps[i]):\n",
    "                #if j == 0:\n",
    "                    #ys_arr[i].append([])\n",
    "                #print(byteCounter)\n",
    "                ys_arr[i][eventCount][j]=data[i][byteCounter]\n",
    "                byteCounter += 1\n",
    "            eventCount += 1\n",
    "    return ys_arr, ETTT_arr, eventcount_arr\n",
    "\n",
    "#start=time.time()\n",
    "#ys_arrHe, ETTT_arrHe, eventcount_arrHe  = dataread(read_data, [25], fileLength, numSamples) ##hardcoded channel 25 for He\n",
    "ys_arr, ETTT_arr, eventcount_arr  = dataread(read_data, chan_enab, fileLength, numSamples) ##hardcoded channels for coils\n",
    "\n",
    "end = time.time()\n",
    "print('dataread from binary time: ' + str(end-start))            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7c0a2f-30dc-4788-8cfa-55bdf9b6172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[17]:\n",
    "timeDif=[]\n",
    "for i in range(0,len(chan_enab)):\n",
    "    timeDif.append([])\n",
    "    for j in range(len(ETTT_arr[i])-1):\n",
    "        timeDif[i].append((ETTT_arr[i][j+1]-ETTT_arr[i][j])*8)\n",
    "#     print(\"Min time difference for channel\", chan_enab[i], \"is\", min(timeDif[i]), \"ns\")\n",
    "#     print(\"Max time difference for channel\", chan_enab[i], \"is\", max(timeDif[i]), \"ns \\n\")\n",
    "#print(timeDif)\n",
    "# In[18]:\n",
    "\n",
    "## basesub and plotting ##\n",
    "baseL = 0\n",
    "baseR = int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])\n",
    "numRuns = int((fileLength[0]-20-numSamples[0])/(numSamples[0]+6)+1)\n",
    "    \n",
    "legend =  ['NaI', 'R']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "s = 0 ## pulse to look at\n",
    "t=s+1\n",
    "\n",
    "## dont know why this is so slow ##\n",
    "def plotter(ys, xs, baseR, numpoints):\n",
    "    tempys_basesub = np.zeros((len(ys), numRuns,numpoints[0]), dtype=float)\n",
    "    for i in range((len(ys))):\n",
    "        for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "            tempys_basesub[i][pulse]=np.subtract(ys[i][pulse], np.mean(ys[i][pulse][baseL:baseR]))\n",
    "        for j in range(s, t): ## plot only interested pulses\n",
    "            plt.plot(xs[i], tempys_basesub[i][j]) #label=legend[i]) #+str(sums[1][j])) ## sums[j] will not work for more than just TR   \n",
    "            plt.axvline(xs[0][baseL], ls = '--')\n",
    "            plt.axvline(xs[0][baseR], ls = '--')\n",
    "            #plt.axvline(xs[0][int(((preTime[0]-groupStart[0])*0.70)/chanDec[0])], ls = '--', c ='m')\n",
    "            plt.axvline(xs[0][baseR+5], ls = '--', c ='r') ## BaseR+5 line marks the beginning of the integral, until the end of samples.\n",
    "#             plt.title('SF state transition' + transitions[p]) \n",
    "#             plt.xlabel(\"time from trigger (ns)\")\n",
    "#             plt.ylabel(\"ADC\")\n",
    "            plt.legend()\n",
    "            \n",
    "#plotter(ys_arr[9:], xs[9:], baseR, numSamples) ##plot coils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f91569-76f3-4556-8880-76cb3866f58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting and/or base subtraction time: 72.3760290145874\n",
      "[[5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0\n",
      "  1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4\n",
      "  5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0 1 2 3 4 5 6 7 0\n",
      "  1 2 3 4]\n",
      " [0 45 90 135 180 225 270 315 360 405 450 495 540 585 630 675 720 765 810\n",
      "  855 900 945 990 1035 1080 1125 1170 1215 1260 1305 1350 1395 1440 1485\n",
      "  1530 1575 1620 1665 1710 1755 1800 1845 1890 1935 1980 2025 2070 2115\n",
      "  2160 2205 2250 2295 2340 2385 2430 2475 2520 2565 2610 2655 2700 2745\n",
      "  2790 2835 2880 2925 2970 3015 3060 3105 3150 3195 3240 3285 3330 3375\n",
      "  3420 3465 3510 3555 3600 3645 3690 3735 3780 3825 3870 3915 3960 4005\n",
      "  4050 4095 4140 4185 4230 4275 4320 4365 4410 4455 4500 4545 4590 4635\n",
      "  4680 4725 4770 4815 4860 4905 4950 4995]]\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "ys_basesub = np.zeros((len(ys_arr), numRuns,numSamples[0]), dtype=np.float64)\n",
    "\n",
    "@njit ## jit is faster for large # channels, slower for small # channels\n",
    "def basesub(ys, baseRight, numpoints): \n",
    "    tempys_basesub = np.zeros((numRuns,numpoints[0]), dtype=np.float64)\n",
    "    for pulse in range((len(eventcount_arr[0]))): ## all have 5000 pulses\n",
    "        tempys_basesub[pulse]=np.subtract(ys[pulse], np.mean(ys[pulse][baseL:baseRight]))\n",
    "    return tempys_basesub\n",
    "\n",
    "## got rid of sums here, should be done after aligning and cutting\n",
    "## got rid of xs in basesub, don't think we need them as an input 06.10.24\n",
    "\n",
    "for i in range(len(ys_basesub)):\n",
    "    ys_basesub[i] = basesub(ys_arr[i], baseR, numSamples)\n",
    "\n",
    "ys_basesub[-1] = ys_basesub[-1]*-1 ## invert 6Li to positive signal. Comment out if not using\n",
    "\n",
    "end = time.time()\n",
    "print('plotting and/or base subtraction time: ' + str(end-start))            \n",
    "\n",
    "# ## Load SF Sorting and norm ##\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "## Load in SF and He normalization information \n",
    "df_SF = pd.read_hdf(SFNormFile + '.h5', key='df_0')\n",
    "df_HE = pd.read_hdf(SFNormFile + '.h5', key='df_1')\n",
    "\n",
    "SF_Sort_arr = df_SF[['nicknames', 'transition_locations']].to_numpy().T\n",
    "He_Norm_arr = df_HE[['pulse', 'norms']].to_numpy().T\n",
    "\n",
    "print((SF_Sort_arr))\n",
    "print(len(SF_Sort_arr[1]))\n",
    "\n",
    "NormFactor = 100000  ## He integrals are huge, this normalizes all of those by a constant value for ease of use\n",
    "HeNorms= (He_Norm_arr[1])/NormFactor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2768605-26a3-49e0-871b-827ff997f5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "sequence order: [6, 7, 0, 1, 2, 3, 4, 5]\n",
      "leftovers sequence#/order/pulses: [[14], [[6, 7, 0, 1, 2, 3, 4]], [[[4685, 4725], [4730, 4770], [4775, 4815], [4820, 4860], [4865, 4905], [4910, 4950], [4955, 4995]]]]\n"
     ]
    }
   ],
   "source": [
    "# In[20]:\n",
    "\n",
    "# for ind in df.index:\n",
    "#     print('transition: '+ str(df['nicknames'][ind]) + ' location: ' + str(df['transition_locations'][ind]))\n",
    "#print(df['transition_locations'],df['nicknames'] )\n",
    "\n",
    "# try:\n",
    "## this could probably be prettier, but it seems to work...\n",
    "def organize_SF(SFsort_info): ## sometimes pulse 0 has the state switch. In that case, need to account by if clauses below\n",
    "    counter = 0\n",
    "    seq = 0\n",
    "    seq_arr = ([[],[],[]])\n",
    "    smallerseq = []\n",
    "    smallerstateis = []\n",
    "    for i in range(len(SFsort_info[1])-(np.mod((len(SFsort_info[1])), 8))):  ##111 mod 8 = 7, so essentially 111-7 = 104\n",
    "        counter = counter+1\n",
    "        if counter < 8:\n",
    "            if (SF_Sort_arr[1][i]) == 0:\n",
    "                smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "                smallerseq.append(SFsort_info[0][i+1])\n",
    "                seq = seq+1\n",
    "                continue\n",
    "            smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "            smallerseq.append(SFsort_info[0][i+1])\n",
    "            # print(SF_Sort_arr[0][i+1])\n",
    "            # print(smallerseq)\n",
    "        elif counter == 8:\n",
    "            if ((SF_Sort_arr[1][i])+5) == 5000:\n",
    "                # print(((SF_Sort_arr[1][i])+5))\n",
    "                seq = seq+1\n",
    "                seq_arr[0].append(seq)\n",
    "                seq_arr[1].append(smallerseq)   \n",
    "                seq_arr[2].append(smallerstateis)\n",
    "                seq_arr[0] = [x-1 for x in seq_arr[0]] ## reset to sequences are 1-14 instead of 2-15\n",
    "                break\n",
    "            seq = seq+1\n",
    "            smallerstateis.append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "            smallerseq.append(SFsort_info[0][i+1])\n",
    "            seq_arr[0].append(seq)\n",
    "            seq_arr[1].append(smallerseq)   \n",
    "            seq_arr[2].append(smallerstateis)\n",
    "            smallerseq = []\n",
    "            smallerstateis = []\n",
    "            counter  = 0\n",
    "    return seq_arr\n",
    "\n",
    "def find_leftover(SFsort_info, seq_arr):\n",
    "    left = [[seq_arr[0][-1]+1],[],[]]\n",
    "    counter = 0\n",
    "    for i in range((len(SFsort_info[1])-(np.mod((len(SFsort_info[1])), 8))), len(SFsort_info[1])-1):\n",
    "        counter = counter+1\n",
    "        if counter < 8:\n",
    "            left[1].append(SFsort_info[0][i+1])\n",
    "            left[2].append([(SFsort_info[1][i])+5,(SFsort_info[1][i+1])])\n",
    "    return left\n",
    "\n",
    "#try:\n",
    "sequence = organize_SF(SF_Sort_arr)\n",
    "if len(sequence[0]) == 14:\n",
    "    leftovers = [[sequence[0][-1]],[sequence[1][-1]],[sequence[2][-1]]]\n",
    "    for i in range(len(sequence)):\n",
    "        sequence[i].pop(-1)\n",
    "else:\n",
    "    leftovers = find_leftover(SF_Sort_arr, sequence)\n",
    "\n",
    "# except Exception as e:\n",
    "#     logger.error(run_num + ' failed during sequencing')\n",
    "#     logger.exception(e)\n",
    "\n",
    "# print((sequence[0]))\n",
    "# print(len(sequence))\n",
    "# print((sequence[1]))\n",
    "    \n",
    "        # sequence[i] = sequence[i].pop(-1)\n",
    "# leftovers = [[sequence[0][-1]+1],[],[]]\n",
    "\n",
    "# except Exception as e:\n",
    "#     logger.error(run_num + ' failed during leftovers sequencing')\n",
    "#     logger.exception(e)\n",
    "# leftovers = find_leftover(SF_Sort_arr)\n",
    "\n",
    "print('sequences '+str(sequence[0]))\n",
    "print('sequence order: '+str(sequence[1][0]))\n",
    "print('leftovers sequence#/order/pulses: ' + str(leftovers))\n",
    "# print(leftovers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eec1d945-1459-4326-8ce9-8ac2ecdb0e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "[[6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5], [6, 7, 0, 1, 2, 3, 4, 5]]\n",
      "13\n",
      "13\n",
      "13\n",
      "[[5, 45], [50, 90], [95, 135], [140, 180], [185, 225], [230, 270], [275, 315], [320, 360]]\n",
      "[[4325, 4365], [4370, 4410], [4415, 4455], [4460, 4500], [4505, 4545], [4550, 4590], [4595, 4635], [4640, 4680]]\n",
      "5\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "print(sequence[0])\n",
    "print(sequence[1])\n",
    "print(len(sequence[0]))\n",
    "print(len(sequence[1]))\n",
    "print(len(sequence[2]))\n",
    "print((sequence[2][0]))\n",
    "print((sequence[2][-1]))\n",
    "print((SF_Sort_arr[1][0])+5)\n",
    "print(SF_Sort_arr[1][0+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca8398d-4b3c-4022-820f-d4dd8a5238c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
